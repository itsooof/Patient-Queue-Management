{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "\n",
        "data = pd.read_csv(\"/content/PQM_FACTORS.csv\")\n",
        "\n",
        "features = data.columns.difference(['Seriousness'])\n",
        "X = data[features]\n",
        "Y = pd.get_dummies(data[\"Seriousness\"])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(1024, input_dim=X_train.shape[1], activation='relu'))\n",
        "model.add(Dropout(0.45))\n",
        "\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.45))\n",
        "\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(4, activation='relu'))\n",
        "\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=1000, batch_size=64, validation_data=(X_test, y_test), verbose = True)\n",
        "\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "true_labels = np.argmax(np.array(y_test), axis=1)\n",
        "\n",
        "accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8L_l8rRdiI-",
        "outputId": "22313f55-f5a8-473e-d9cf-3c14b17d4943"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "38/38 [==============================] - 3s 28ms/step - loss: 2.3031 - accuracy: 0.0925 - val_loss: 2.3033 - val_accuracy: 0.0983\n",
            "Epoch 2/1000\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 2.3033 - accuracy: 0.1013 - val_loss: 2.3022 - val_accuracy: 0.1000\n",
            "Epoch 3/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 2.3022 - accuracy: 0.0983 - val_loss: 2.3023 - val_accuracy: 0.0950\n",
            "Epoch 4/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 2.3016 - accuracy: 0.1017 - val_loss: 2.3020 - val_accuracy: 0.1117\n",
            "Epoch 5/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 2.3009 - accuracy: 0.1021 - val_loss: 2.2997 - val_accuracy: 0.0833\n",
            "Epoch 6/1000\n",
            "38/38 [==============================] - 1s 32ms/step - loss: 2.3011 - accuracy: 0.1117 - val_loss: 2.3017 - val_accuracy: 0.1000\n",
            "Epoch 7/1000\n",
            "38/38 [==============================] - 1s 33ms/step - loss: 2.2978 - accuracy: 0.1075 - val_loss: 2.2976 - val_accuracy: 0.1100\n",
            "Epoch 8/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 2.2916 - accuracy: 0.1163 - val_loss: 2.3009 - val_accuracy: 0.1117\n",
            "Epoch 9/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 2.2864 - accuracy: 0.1187 - val_loss: 2.2914 - val_accuracy: 0.1233\n",
            "Epoch 10/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 2.2857 - accuracy: 0.1192 - val_loss: 2.2837 - val_accuracy: 0.1267\n",
            "Epoch 11/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 2.2745 - accuracy: 0.1325 - val_loss: 2.2792 - val_accuracy: 0.1333\n",
            "Epoch 12/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 2.2738 - accuracy: 0.1292 - val_loss: 2.2786 - val_accuracy: 0.1350\n",
            "Epoch 13/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 2.2688 - accuracy: 0.1300 - val_loss: 2.2728 - val_accuracy: 0.1317\n",
            "Epoch 14/1000\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 2.2642 - accuracy: 0.1329 - val_loss: 2.2655 - val_accuracy: 0.1367\n",
            "Epoch 15/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 2.2603 - accuracy: 0.1329 - val_loss: 2.2692 - val_accuracy: 0.1367\n",
            "Epoch 16/1000\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 2.2454 - accuracy: 0.1429 - val_loss: 2.2662 - val_accuracy: 0.1583\n",
            "Epoch 17/1000\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 2.2463 - accuracy: 0.1467 - val_loss: 2.2630 - val_accuracy: 0.1333\n",
            "Epoch 18/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 2.2348 - accuracy: 0.1471 - val_loss: 2.2664 - val_accuracy: 0.1533\n",
            "Epoch 19/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 2.2356 - accuracy: 0.1533 - val_loss: 2.2696 - val_accuracy: 0.1450\n",
            "Epoch 20/1000\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 2.2326 - accuracy: 0.1504 - val_loss: 2.2508 - val_accuracy: 0.1300\n",
            "Epoch 21/1000\n",
            "38/38 [==============================] - 2s 42ms/step - loss: 2.2149 - accuracy: 0.1567 - val_loss: 2.2371 - val_accuracy: 0.1567\n",
            "Epoch 22/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 2.2069 - accuracy: 0.1562 - val_loss: 2.2481 - val_accuracy: 0.1350\n",
            "Epoch 23/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 2.1968 - accuracy: 0.1538 - val_loss: 2.2203 - val_accuracy: 0.1483\n",
            "Epoch 24/1000\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 2.2037 - accuracy: 0.1517 - val_loss: 2.2231 - val_accuracy: 0.1450\n",
            "Epoch 25/1000\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 2.1791 - accuracy: 0.1654 - val_loss: 2.2091 - val_accuracy: 0.1467\n",
            "Epoch 26/1000\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 2.1798 - accuracy: 0.1658 - val_loss: 2.2184 - val_accuracy: 0.1533\n",
            "Epoch 27/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 2.1678 - accuracy: 0.1838 - val_loss: 2.2005 - val_accuracy: 0.1583\n",
            "Epoch 28/1000\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 2.1642 - accuracy: 0.1879 - val_loss: 2.2032 - val_accuracy: 0.1517\n",
            "Epoch 29/1000\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 2.1611 - accuracy: 0.1779 - val_loss: 2.2135 - val_accuracy: 0.1550\n",
            "Epoch 30/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 2.1401 - accuracy: 0.1800 - val_loss: 2.1847 - val_accuracy: 0.1833\n",
            "Epoch 31/1000\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 2.1200 - accuracy: 0.1896 - val_loss: 2.1837 - val_accuracy: 0.1667\n",
            "Epoch 32/1000\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 2.1181 - accuracy: 0.1896 - val_loss: 2.2013 - val_accuracy: 0.1517\n",
            "Epoch 33/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 2.1263 - accuracy: 0.1954 - val_loss: 2.1731 - val_accuracy: 0.1883\n",
            "Epoch 34/1000\n",
            "38/38 [==============================] - 1s 34ms/step - loss: 2.0985 - accuracy: 0.1921 - val_loss: 2.1626 - val_accuracy: 0.1683\n",
            "Epoch 35/1000\n",
            "38/38 [==============================] - 1s 30ms/step - loss: 2.0926 - accuracy: 0.2046 - val_loss: 2.1329 - val_accuracy: 0.1867\n",
            "Epoch 36/1000\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 2.0699 - accuracy: 0.2096 - val_loss: 2.1228 - val_accuracy: 0.1800\n",
            "Epoch 37/1000\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 2.0686 - accuracy: 0.2150 - val_loss: 2.1736 - val_accuracy: 0.1917\n",
            "Epoch 38/1000\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 2.0593 - accuracy: 0.2167 - val_loss: 2.1084 - val_accuracy: 0.1967\n",
            "Epoch 39/1000\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 2.0573 - accuracy: 0.2304 - val_loss: 2.1235 - val_accuracy: 0.1850\n",
            "Epoch 40/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 2.0404 - accuracy: 0.2354 - val_loss: 2.0835 - val_accuracy: 0.2100\n",
            "Epoch 41/1000\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 2.0049 - accuracy: 0.2288 - val_loss: 2.1180 - val_accuracy: 0.2083\n",
            "Epoch 42/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 1.9933 - accuracy: 0.2587 - val_loss: 2.0738 - val_accuracy: 0.2317\n",
            "Epoch 43/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 1.9726 - accuracy: 0.2542 - val_loss: 2.0599 - val_accuracy: 0.2200\n",
            "Epoch 44/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 1.9612 - accuracy: 0.2587 - val_loss: 2.0681 - val_accuracy: 0.2267\n",
            "Epoch 45/1000\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 1.9466 - accuracy: 0.2654 - val_loss: 2.0251 - val_accuracy: 0.2450\n",
            "Epoch 46/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 1.9396 - accuracy: 0.2642 - val_loss: 2.0501 - val_accuracy: 0.2633\n",
            "Epoch 47/1000\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 1.9361 - accuracy: 0.2667 - val_loss: 2.0388 - val_accuracy: 0.2583\n",
            "Epoch 48/1000\n",
            "38/38 [==============================] - 1s 31ms/step - loss: 1.9166 - accuracy: 0.2775 - val_loss: 2.1035 - val_accuracy: 0.2850\n",
            "Epoch 49/1000\n",
            "38/38 [==============================] - 1s 32ms/step - loss: 1.9165 - accuracy: 0.2808 - val_loss: 2.0293 - val_accuracy: 0.2933\n",
            "Epoch 50/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 1.9078 - accuracy: 0.2779 - val_loss: 2.0409 - val_accuracy: 0.2750\n",
            "Epoch 51/1000\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 1.8888 - accuracy: 0.2921 - val_loss: 1.9733 - val_accuracy: 0.2883\n",
            "Epoch 52/1000\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 1.8827 - accuracy: 0.2929 - val_loss: 1.9357 - val_accuracy: 0.3067\n",
            "Epoch 53/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 1.8464 - accuracy: 0.3133 - val_loss: 1.9434 - val_accuracy: 0.3117\n",
            "Epoch 54/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 1.8351 - accuracy: 0.3054 - val_loss: 1.9213 - val_accuracy: 0.3167\n",
            "Epoch 55/1000\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 1.8269 - accuracy: 0.3096 - val_loss: 1.9311 - val_accuracy: 0.3167\n",
            "Epoch 56/1000\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 1.7987 - accuracy: 0.3204 - val_loss: 1.9396 - val_accuracy: 0.3383\n",
            "Epoch 57/1000\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 1.7980 - accuracy: 0.3146 - val_loss: 1.8846 - val_accuracy: 0.3367\n",
            "Epoch 58/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 1.7746 - accuracy: 0.3242 - val_loss: 1.8813 - val_accuracy: 0.3200\n",
            "Epoch 59/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 1.7635 - accuracy: 0.3321 - val_loss: 1.7998 - val_accuracy: 0.3500\n",
            "Epoch 60/1000\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 1.7543 - accuracy: 0.3354 - val_loss: 1.8667 - val_accuracy: 0.3467\n",
            "Epoch 61/1000\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 1.7508 - accuracy: 0.3462 - val_loss: 1.8660 - val_accuracy: 0.3583\n",
            "Epoch 62/1000\n",
            "38/38 [==============================] - 1s 27ms/step - loss: 1.7301 - accuracy: 0.3379 - val_loss: 1.8010 - val_accuracy: 0.3583\n",
            "Epoch 63/1000\n",
            "38/38 [==============================] - 1s 32ms/step - loss: 1.7050 - accuracy: 0.3587 - val_loss: 1.7590 - val_accuracy: 0.3967\n",
            "Epoch 64/1000\n",
            "38/38 [==============================] - 1s 29ms/step - loss: 1.7008 - accuracy: 0.3554 - val_loss: 1.7759 - val_accuracy: 0.3917\n",
            "Epoch 65/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 1.6658 - accuracy: 0.3708 - val_loss: 1.7421 - val_accuracy: 0.4183\n",
            "Epoch 66/1000\n",
            "38/38 [==============================] - 1s 20ms/step - loss: 1.6500 - accuracy: 0.3775 - val_loss: 1.6625 - val_accuracy: 0.4083\n",
            "Epoch 67/1000\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 1.6448 - accuracy: 0.3750 - val_loss: 1.6702 - val_accuracy: 0.4317\n",
            "Epoch 68/1000\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 1.6309 - accuracy: 0.3767 - val_loss: 1.6773 - val_accuracy: 0.4333\n",
            "Epoch 69/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 1.6321 - accuracy: 0.3875 - val_loss: 1.6634 - val_accuracy: 0.4100\n",
            "Epoch 70/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 1.6266 - accuracy: 0.3896 - val_loss: 1.6585 - val_accuracy: 0.4233\n",
            "Epoch 71/1000\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 1.5968 - accuracy: 0.3938 - val_loss: 1.6349 - val_accuracy: 0.4267\n",
            "Epoch 72/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 1.5739 - accuracy: 0.4054 - val_loss: 1.6300 - val_accuracy: 0.4283\n",
            "Epoch 73/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 1.5972 - accuracy: 0.4058 - val_loss: 1.5855 - val_accuracy: 0.4633\n",
            "Epoch 74/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 1.5708 - accuracy: 0.4121 - val_loss: 1.6310 - val_accuracy: 0.4317\n",
            "Epoch 75/1000\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 1.5733 - accuracy: 0.4112 - val_loss: 1.5859 - val_accuracy: 0.4667\n",
            "Epoch 76/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 1.5494 - accuracy: 0.4229 - val_loss: 1.5148 - val_accuracy: 0.4733\n",
            "Epoch 77/1000\n",
            "38/38 [==============================] - 1s 34ms/step - loss: 1.5201 - accuracy: 0.4221 - val_loss: 1.5416 - val_accuracy: 0.4717\n",
            "Epoch 78/1000\n",
            "38/38 [==============================] - 1s 31ms/step - loss: 1.5310 - accuracy: 0.4062 - val_loss: 1.5036 - val_accuracy: 0.4800\n",
            "Epoch 79/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 1.4905 - accuracy: 0.4338 - val_loss: 1.5013 - val_accuracy: 0.4833\n",
            "Epoch 80/1000\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 1.4896 - accuracy: 0.4329 - val_loss: 1.4949 - val_accuracy: 0.4933\n",
            "Epoch 81/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 1.4616 - accuracy: 0.4525 - val_loss: 1.4347 - val_accuracy: 0.4933\n",
            "Epoch 82/1000\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 1.4713 - accuracy: 0.4496 - val_loss: 1.4746 - val_accuracy: 0.4917\n",
            "Epoch 83/1000\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 1.4465 - accuracy: 0.4512 - val_loss: 1.4426 - val_accuracy: 0.4967\n",
            "Epoch 84/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 1.4437 - accuracy: 0.4404 - val_loss: 1.4274 - val_accuracy: 0.5017\n",
            "Epoch 85/1000\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 1.4118 - accuracy: 0.4642 - val_loss: 1.3629 - val_accuracy: 0.5350\n",
            "Epoch 86/1000\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 1.4349 - accuracy: 0.4679 - val_loss: 1.3656 - val_accuracy: 0.5367\n",
            "Epoch 87/1000\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 1.3791 - accuracy: 0.4725 - val_loss: 1.3363 - val_accuracy: 0.5550\n",
            "Epoch 88/1000\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 1.4105 - accuracy: 0.4663 - val_loss: 1.3540 - val_accuracy: 0.5383\n",
            "Epoch 89/1000\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 1.3661 - accuracy: 0.4875 - val_loss: 1.3126 - val_accuracy: 0.5650\n",
            "Epoch 90/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 1.3267 - accuracy: 0.4929 - val_loss: 1.3685 - val_accuracy: 0.5367\n",
            "Epoch 91/1000\n",
            "38/38 [==============================] - 1s 32ms/step - loss: 1.3264 - accuracy: 0.4938 - val_loss: 1.2940 - val_accuracy: 0.5750\n",
            "Epoch 92/1000\n",
            "38/38 [==============================] - 1s 34ms/step - loss: 1.3193 - accuracy: 0.5033 - val_loss: 1.3653 - val_accuracy: 0.5467\n",
            "Epoch 93/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 1.3417 - accuracy: 0.4925 - val_loss: 1.3803 - val_accuracy: 0.5617\n",
            "Epoch 94/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 1.2976 - accuracy: 0.5100 - val_loss: 1.2979 - val_accuracy: 0.5900\n",
            "Epoch 95/1000\n",
            "38/38 [==============================] - 1s 28ms/step - loss: 1.3104 - accuracy: 0.5058 - val_loss: 1.3486 - val_accuracy: 0.5633\n",
            "Epoch 96/1000\n",
            "38/38 [==============================] - 1s 27ms/step - loss: 1.2919 - accuracy: 0.5092 - val_loss: 1.2535 - val_accuracy: 0.5600\n",
            "Epoch 97/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 1.2817 - accuracy: 0.5154 - val_loss: 1.2247 - val_accuracy: 0.5900\n",
            "Epoch 98/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 1.2684 - accuracy: 0.5058 - val_loss: 1.2382 - val_accuracy: 0.5933\n",
            "Epoch 99/1000\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 1.2234 - accuracy: 0.5358 - val_loss: 1.2365 - val_accuracy: 0.6033\n",
            "Epoch 100/1000\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 1.2499 - accuracy: 0.5250 - val_loss: 1.2128 - val_accuracy: 0.5933\n",
            "Epoch 101/1000\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 1.2655 - accuracy: 0.5308 - val_loss: 1.1368 - val_accuracy: 0.6033\n",
            "Epoch 102/1000\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 1.2055 - accuracy: 0.5504 - val_loss: 1.1121 - val_accuracy: 0.6333\n",
            "Epoch 103/1000\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 1.2004 - accuracy: 0.5496 - val_loss: 1.1194 - val_accuracy: 0.6167\n",
            "Epoch 104/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 1.2057 - accuracy: 0.5479 - val_loss: 1.1192 - val_accuracy: 0.6367\n",
            "Epoch 105/1000\n",
            "38/38 [==============================] - 1s 33ms/step - loss: 1.1996 - accuracy: 0.5421 - val_loss: 1.1802 - val_accuracy: 0.6400\n",
            "Epoch 106/1000\n",
            "38/38 [==============================] - 1s 34ms/step - loss: 1.1795 - accuracy: 0.5646 - val_loss: 1.1722 - val_accuracy: 0.6367\n",
            "Epoch 107/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 1.1744 - accuracy: 0.5587 - val_loss: 1.1962 - val_accuracy: 0.6183\n",
            "Epoch 108/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 1.2001 - accuracy: 0.5612 - val_loss: 1.1111 - val_accuracy: 0.6383\n",
            "Epoch 109/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 1.1564 - accuracy: 0.5629 - val_loss: 1.0799 - val_accuracy: 0.6383\n",
            "Epoch 110/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 1.1226 - accuracy: 0.5813 - val_loss: 1.1110 - val_accuracy: 0.6567\n",
            "Epoch 111/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 1.1614 - accuracy: 0.5696 - val_loss: 1.1805 - val_accuracy: 0.6600\n",
            "Epoch 112/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 1.0982 - accuracy: 0.5921 - val_loss: 1.0091 - val_accuracy: 0.6667\n",
            "Epoch 113/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 1.1114 - accuracy: 0.5854 - val_loss: 0.9775 - val_accuracy: 0.6883\n",
            "Epoch 114/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 1.0978 - accuracy: 0.5904 - val_loss: 1.0084 - val_accuracy: 0.7000\n",
            "Epoch 115/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 1.0715 - accuracy: 0.6146 - val_loss: 0.9657 - val_accuracy: 0.7250\n",
            "Epoch 116/1000\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 1.0863 - accuracy: 0.6058 - val_loss: 0.9519 - val_accuracy: 0.6967\n",
            "Epoch 117/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 1.0569 - accuracy: 0.6146 - val_loss: 0.9624 - val_accuracy: 0.6850\n",
            "Epoch 118/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 1.0757 - accuracy: 0.6112 - val_loss: 0.9356 - val_accuracy: 0.6833\n",
            "Epoch 119/1000\n",
            "38/38 [==============================] - 1s 32ms/step - loss: 1.0341 - accuracy: 0.5958 - val_loss: 0.9636 - val_accuracy: 0.7000\n",
            "Epoch 120/1000\n",
            "38/38 [==============================] - 1s 33ms/step - loss: 1.0463 - accuracy: 0.6317 - val_loss: 0.9291 - val_accuracy: 0.7117\n",
            "Epoch 121/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 1.0309 - accuracy: 0.6204 - val_loss: 0.9160 - val_accuracy: 0.7233\n",
            "Epoch 122/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 1.0408 - accuracy: 0.6142 - val_loss: 1.0084 - val_accuracy: 0.7050\n",
            "Epoch 123/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 1.0165 - accuracy: 0.6250 - val_loss: 0.9580 - val_accuracy: 0.7100\n",
            "Epoch 124/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 1.0240 - accuracy: 0.6358 - val_loss: 0.9293 - val_accuracy: 0.7500\n",
            "Epoch 125/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.9890 - accuracy: 0.6433 - val_loss: 0.9519 - val_accuracy: 0.7117\n",
            "Epoch 126/1000\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 1.0010 - accuracy: 0.6296 - val_loss: 0.8837 - val_accuracy: 0.7450\n",
            "Epoch 127/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.9804 - accuracy: 0.6388 - val_loss: 0.8982 - val_accuracy: 0.7233\n",
            "Epoch 128/1000\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 1.0121 - accuracy: 0.6375 - val_loss: 0.9293 - val_accuracy: 0.7150\n",
            "Epoch 129/1000\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 0.9803 - accuracy: 0.6450 - val_loss: 0.9031 - val_accuracy: 0.7400\n",
            "Epoch 130/1000\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 0.9420 - accuracy: 0.6612 - val_loss: 0.8428 - val_accuracy: 0.7333\n",
            "Epoch 131/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.9241 - accuracy: 0.6617 - val_loss: 0.8644 - val_accuracy: 0.7500\n",
            "Epoch 132/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.9236 - accuracy: 0.6729 - val_loss: 0.8423 - val_accuracy: 0.7483\n",
            "Epoch 133/1000\n",
            "38/38 [==============================] - 1s 33ms/step - loss: 0.9187 - accuracy: 0.6754 - val_loss: 0.9118 - val_accuracy: 0.7450\n",
            "Epoch 134/1000\n",
            "38/38 [==============================] - 1s 33ms/step - loss: 0.9212 - accuracy: 0.6683 - val_loss: 0.8697 - val_accuracy: 0.7417\n",
            "Epoch 135/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.9524 - accuracy: 0.6608 - val_loss: 0.9020 - val_accuracy: 0.7633\n",
            "Epoch 136/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.8907 - accuracy: 0.6750 - val_loss: 0.8469 - val_accuracy: 0.7683\n",
            "Epoch 137/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.9086 - accuracy: 0.6771 - val_loss: 0.8311 - val_accuracy: 0.7917\n",
            "Epoch 138/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.9068 - accuracy: 0.6725 - val_loss: 0.8199 - val_accuracy: 0.7750\n",
            "Epoch 139/1000\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 0.8766 - accuracy: 0.6967 - val_loss: 0.8005 - val_accuracy: 0.7950\n",
            "Epoch 140/1000\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 0.8780 - accuracy: 0.6883 - val_loss: 0.8529 - val_accuracy: 0.7867\n",
            "Epoch 141/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.8754 - accuracy: 0.6842 - val_loss: 0.8244 - val_accuracy: 0.8000\n",
            "Epoch 142/1000\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 0.8275 - accuracy: 0.7083 - val_loss: 0.7594 - val_accuracy: 0.8217\n",
            "Epoch 143/1000\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 0.8672 - accuracy: 0.6992 - val_loss: 0.7909 - val_accuracy: 0.7933\n",
            "Epoch 144/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.8487 - accuracy: 0.7025 - val_loss: 0.7955 - val_accuracy: 0.7933\n",
            "Epoch 145/1000\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 0.8450 - accuracy: 0.7125 - val_loss: 0.7760 - val_accuracy: 0.7933\n",
            "Epoch 146/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.8191 - accuracy: 0.7217 - val_loss: 0.6939 - val_accuracy: 0.8217\n",
            "Epoch 147/1000\n",
            "38/38 [==============================] - 1s 31ms/step - loss: 0.8339 - accuracy: 0.7096 - val_loss: 0.6809 - val_accuracy: 0.8100\n",
            "Epoch 148/1000\n",
            "38/38 [==============================] - 1s 35ms/step - loss: 0.8151 - accuracy: 0.7212 - val_loss: 0.7356 - val_accuracy: 0.8483\n",
            "Epoch 149/1000\n",
            "38/38 [==============================] - 1s 27ms/step - loss: 0.8000 - accuracy: 0.7192 - val_loss: 0.7346 - val_accuracy: 0.8283\n",
            "Epoch 150/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.8179 - accuracy: 0.7183 - val_loss: 0.7708 - val_accuracy: 0.8150\n",
            "Epoch 151/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.8075 - accuracy: 0.7179 - val_loss: 0.6901 - val_accuracy: 0.8200\n",
            "Epoch 152/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.7725 - accuracy: 0.7208 - val_loss: 0.6675 - val_accuracy: 0.8283\n",
            "Epoch 153/1000\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 0.7601 - accuracy: 0.7325 - val_loss: 0.6701 - val_accuracy: 0.8333\n",
            "Epoch 154/1000\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 0.7826 - accuracy: 0.7333 - val_loss: 0.6430 - val_accuracy: 0.8450\n",
            "Epoch 155/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.7640 - accuracy: 0.7362 - val_loss: 0.6315 - val_accuracy: 0.8433\n",
            "Epoch 156/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.8108 - accuracy: 0.7258 - val_loss: 0.6618 - val_accuracy: 0.8567\n",
            "Epoch 157/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.7761 - accuracy: 0.7350 - val_loss: 0.6759 - val_accuracy: 0.8467\n",
            "Epoch 158/1000\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 0.7915 - accuracy: 0.7346 - val_loss: 0.6661 - val_accuracy: 0.8467\n",
            "Epoch 159/1000\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 0.7360 - accuracy: 0.7546 - val_loss: 0.6458 - val_accuracy: 0.8467\n",
            "Epoch 160/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.7516 - accuracy: 0.7592 - val_loss: 0.6415 - val_accuracy: 0.8683\n",
            "Epoch 161/1000\n",
            "38/38 [==============================] - 1s 28ms/step - loss: 0.7665 - accuracy: 0.7483 - val_loss: 0.5683 - val_accuracy: 0.8500\n",
            "Epoch 162/1000\n",
            "38/38 [==============================] - 1s 34ms/step - loss: 0.7469 - accuracy: 0.7479 - val_loss: 0.5921 - val_accuracy: 0.8433\n",
            "Epoch 163/1000\n",
            "38/38 [==============================] - 1s 30ms/step - loss: 0.7023 - accuracy: 0.7650 - val_loss: 0.6508 - val_accuracy: 0.8517\n",
            "Epoch 164/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.7118 - accuracy: 0.7679 - val_loss: 0.6567 - val_accuracy: 0.8717\n",
            "Epoch 165/1000\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 0.7079 - accuracy: 0.7683 - val_loss: 0.5652 - val_accuracy: 0.8600\n",
            "Epoch 166/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.7251 - accuracy: 0.7638 - val_loss: 0.6015 - val_accuracy: 0.8633\n",
            "Epoch 167/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.7201 - accuracy: 0.7475 - val_loss: 0.5594 - val_accuracy: 0.8650\n",
            "Epoch 168/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.7226 - accuracy: 0.7546 - val_loss: 0.6139 - val_accuracy: 0.8700\n",
            "Epoch 169/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.7176 - accuracy: 0.7625 - val_loss: 0.5944 - val_accuracy: 0.8600\n",
            "Epoch 170/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.6839 - accuracy: 0.7708 - val_loss: 0.6131 - val_accuracy: 0.8617\n",
            "Epoch 171/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.6999 - accuracy: 0.7658 - val_loss: 0.5919 - val_accuracy: 0.8700\n",
            "Epoch 172/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.7148 - accuracy: 0.7613 - val_loss: 0.5845 - val_accuracy: 0.8717\n",
            "Epoch 173/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.6654 - accuracy: 0.7833 - val_loss: 0.5693 - val_accuracy: 0.8833\n",
            "Epoch 174/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.6593 - accuracy: 0.7800 - val_loss: 0.5713 - val_accuracy: 0.8817\n",
            "Epoch 175/1000\n",
            "38/38 [==============================] - 2s 57ms/step - loss: 0.6700 - accuracy: 0.7708 - val_loss: 0.5880 - val_accuracy: 0.8800\n",
            "Epoch 176/1000\n",
            "38/38 [==============================] - 2s 40ms/step - loss: 0.6428 - accuracy: 0.7850 - val_loss: 0.5814 - val_accuracy: 0.8833\n",
            "Epoch 177/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.6809 - accuracy: 0.7738 - val_loss: 0.5659 - val_accuracy: 0.8817\n",
            "Epoch 178/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.6362 - accuracy: 0.7954 - val_loss: 0.5423 - val_accuracy: 0.8783\n",
            "Epoch 179/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.6294 - accuracy: 0.7950 - val_loss: 0.5663 - val_accuracy: 0.8883\n",
            "Epoch 180/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.6239 - accuracy: 0.7967 - val_loss: 0.5518 - val_accuracy: 0.8917\n",
            "Epoch 181/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.6297 - accuracy: 0.7979 - val_loss: 0.5451 - val_accuracy: 0.8817\n",
            "Epoch 182/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.6148 - accuracy: 0.8067 - val_loss: 0.5843 - val_accuracy: 0.8817\n",
            "Epoch 183/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.6138 - accuracy: 0.8046 - val_loss: 0.6002 - val_accuracy: 0.8783\n",
            "Epoch 184/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.5947 - accuracy: 0.8050 - val_loss: 0.5605 - val_accuracy: 0.9083\n",
            "Epoch 185/1000\n",
            "38/38 [==============================] - 1s 32ms/step - loss: 0.5945 - accuracy: 0.8000 - val_loss: 0.5198 - val_accuracy: 0.9000\n",
            "Epoch 186/1000\n",
            "38/38 [==============================] - 1s 33ms/step - loss: 0.5725 - accuracy: 0.8163 - val_loss: 0.5010 - val_accuracy: 0.8967\n",
            "Epoch 187/1000\n",
            "38/38 [==============================] - 1s 30ms/step - loss: 0.6362 - accuracy: 0.8004 - val_loss: 0.5419 - val_accuracy: 0.9133\n",
            "Epoch 188/1000\n",
            "38/38 [==============================] - 1s 34ms/step - loss: 0.5731 - accuracy: 0.8079 - val_loss: 0.5404 - val_accuracy: 0.9000\n",
            "Epoch 189/1000\n",
            "38/38 [==============================] - 1s 30ms/step - loss: 0.5711 - accuracy: 0.8171 - val_loss: 0.4900 - val_accuracy: 0.9050\n",
            "Epoch 190/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.5803 - accuracy: 0.8167 - val_loss: 0.4764 - val_accuracy: 0.9183\n",
            "Epoch 191/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.5918 - accuracy: 0.8112 - val_loss: 0.4402 - val_accuracy: 0.9217\n",
            "Epoch 192/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.5687 - accuracy: 0.8225 - val_loss: 0.5083 - val_accuracy: 0.9200\n",
            "Epoch 193/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.5474 - accuracy: 0.8238 - val_loss: 0.5069 - val_accuracy: 0.9183\n",
            "Epoch 194/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.5216 - accuracy: 0.8263 - val_loss: 0.4845 - val_accuracy: 0.9117\n",
            "Epoch 195/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.5762 - accuracy: 0.8192 - val_loss: 0.5220 - val_accuracy: 0.9167\n",
            "Epoch 196/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.5745 - accuracy: 0.8125 - val_loss: 0.5329 - val_accuracy: 0.9100\n",
            "Epoch 197/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.5759 - accuracy: 0.8250 - val_loss: 0.4794 - val_accuracy: 0.9050\n",
            "Epoch 198/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.5868 - accuracy: 0.8154 - val_loss: 0.4646 - val_accuracy: 0.9067\n",
            "Epoch 199/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.5608 - accuracy: 0.8175 - val_loss: 0.4072 - val_accuracy: 0.9117\n",
            "Epoch 200/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.5839 - accuracy: 0.8208 - val_loss: 0.4337 - val_accuracy: 0.9117\n",
            "Epoch 201/1000\n",
            "38/38 [==============================] - 1s 29ms/step - loss: 0.5568 - accuracy: 0.8146 - val_loss: 0.4787 - val_accuracy: 0.9250\n",
            "Epoch 202/1000\n",
            "38/38 [==============================] - 1s 34ms/step - loss: 0.5243 - accuracy: 0.8279 - val_loss: 0.5166 - val_accuracy: 0.9150\n",
            "Epoch 203/1000\n",
            "38/38 [==============================] - 1s 30ms/step - loss: 0.5376 - accuracy: 0.8300 - val_loss: 0.4551 - val_accuracy: 0.9033\n",
            "Epoch 204/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.5441 - accuracy: 0.8254 - val_loss: 0.4667 - val_accuracy: 0.9033\n",
            "Epoch 205/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.5451 - accuracy: 0.8246 - val_loss: 0.4130 - val_accuracy: 0.9133\n",
            "Epoch 206/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.5145 - accuracy: 0.8400 - val_loss: 0.4159 - val_accuracy: 0.9050\n",
            "Epoch 207/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.5127 - accuracy: 0.8296 - val_loss: 0.4324 - val_accuracy: 0.9150\n",
            "Epoch 208/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.5153 - accuracy: 0.8421 - val_loss: 0.4599 - val_accuracy: 0.9217\n",
            "Epoch 209/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.4947 - accuracy: 0.8425 - val_loss: 0.4962 - val_accuracy: 0.9183\n",
            "Epoch 210/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.5259 - accuracy: 0.8346 - val_loss: 0.4678 - val_accuracy: 0.9217\n",
            "Epoch 211/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.5108 - accuracy: 0.8417 - val_loss: 0.4361 - val_accuracy: 0.9267\n",
            "Epoch 212/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.4662 - accuracy: 0.8533 - val_loss: 0.4101 - val_accuracy: 0.9317\n",
            "Epoch 213/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.5129 - accuracy: 0.8408 - val_loss: 0.5224 - val_accuracy: 0.9100\n",
            "Epoch 214/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.5737 - accuracy: 0.8238 - val_loss: 0.4662 - val_accuracy: 0.9250\n",
            "Epoch 215/1000\n",
            "38/38 [==============================] - 1s 31ms/step - loss: 0.5000 - accuracy: 0.8417 - val_loss: 0.4581 - val_accuracy: 0.9317\n",
            "Epoch 216/1000\n",
            "38/38 [==============================] - 1s 32ms/step - loss: 0.5044 - accuracy: 0.8388 - val_loss: 0.4895 - val_accuracy: 0.9350\n",
            "Epoch 217/1000\n",
            "38/38 [==============================] - 1s 30ms/step - loss: 0.4983 - accuracy: 0.8492 - val_loss: 0.4334 - val_accuracy: 0.9133\n",
            "Epoch 218/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.4754 - accuracy: 0.8471 - val_loss: 0.4531 - val_accuracy: 0.9150\n",
            "Epoch 219/1000\n",
            "38/38 [==============================] - 1s 30ms/step - loss: 0.4656 - accuracy: 0.8442 - val_loss: 0.4040 - val_accuracy: 0.9233\n",
            "Epoch 220/1000\n",
            "38/38 [==============================] - 1s 29ms/step - loss: 0.5413 - accuracy: 0.8371 - val_loss: 0.4181 - val_accuracy: 0.9300\n",
            "Epoch 221/1000\n",
            "38/38 [==============================] - 1s 29ms/step - loss: 0.5073 - accuracy: 0.8379 - val_loss: 0.4090 - val_accuracy: 0.9367\n",
            "Epoch 222/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.4859 - accuracy: 0.8450 - val_loss: 0.4091 - val_accuracy: 0.9417\n",
            "Epoch 223/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.4676 - accuracy: 0.8600 - val_loss: 0.3737 - val_accuracy: 0.9333\n",
            "Epoch 224/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.4650 - accuracy: 0.8567 - val_loss: 0.4429 - val_accuracy: 0.9267\n",
            "Epoch 225/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.4733 - accuracy: 0.8612 - val_loss: 0.4370 - val_accuracy: 0.9350\n",
            "Epoch 226/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.4970 - accuracy: 0.8504 - val_loss: 0.4098 - val_accuracy: 0.9333\n",
            "Epoch 227/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.4277 - accuracy: 0.8629 - val_loss: 0.4371 - val_accuracy: 0.9317\n",
            "Epoch 228/1000\n",
            "38/38 [==============================] - 1s 30ms/step - loss: 0.4552 - accuracy: 0.8629 - val_loss: 0.3926 - val_accuracy: 0.9333\n",
            "Epoch 229/1000\n",
            "38/38 [==============================] - 1s 33ms/step - loss: 0.4659 - accuracy: 0.8542 - val_loss: 0.4352 - val_accuracy: 0.9483\n",
            "Epoch 230/1000\n",
            "38/38 [==============================] - 1s 29ms/step - loss: 0.4761 - accuracy: 0.8500 - val_loss: 0.3515 - val_accuracy: 0.9367\n",
            "Epoch 231/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.4213 - accuracy: 0.8675 - val_loss: 0.3399 - val_accuracy: 0.9300\n",
            "Epoch 232/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.4666 - accuracy: 0.8542 - val_loss: 0.4232 - val_accuracy: 0.9367\n",
            "Epoch 233/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.4641 - accuracy: 0.8604 - val_loss: 0.3981 - val_accuracy: 0.9367\n",
            "Epoch 234/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.4533 - accuracy: 0.8567 - val_loss: 0.3860 - val_accuracy: 0.9417\n",
            "Epoch 235/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.4208 - accuracy: 0.8708 - val_loss: 0.4049 - val_accuracy: 0.9467\n",
            "Epoch 236/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.4386 - accuracy: 0.8612 - val_loss: 0.3803 - val_accuracy: 0.9417\n",
            "Epoch 237/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.4310 - accuracy: 0.8583 - val_loss: 0.4451 - val_accuracy: 0.9417\n",
            "Epoch 238/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.4216 - accuracy: 0.8662 - val_loss: 0.4110 - val_accuracy: 0.9350\n",
            "Epoch 239/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.4539 - accuracy: 0.8667 - val_loss: 0.3745 - val_accuracy: 0.9417\n",
            "Epoch 240/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.4004 - accuracy: 0.8742 - val_loss: 0.3514 - val_accuracy: 0.9500\n",
            "Epoch 241/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.3835 - accuracy: 0.8850 - val_loss: 0.3331 - val_accuracy: 0.9417\n",
            "Epoch 242/1000\n",
            "38/38 [==============================] - 1s 33ms/step - loss: 0.3970 - accuracy: 0.8788 - val_loss: 0.3631 - val_accuracy: 0.9433\n",
            "Epoch 243/1000\n",
            "38/38 [==============================] - 1s 35ms/step - loss: 0.4486 - accuracy: 0.8617 - val_loss: 0.3834 - val_accuracy: 0.9417\n",
            "Epoch 244/1000\n",
            "38/38 [==============================] - 1s 27ms/step - loss: 0.4604 - accuracy: 0.8654 - val_loss: 0.3482 - val_accuracy: 0.9517\n",
            "Epoch 245/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.4186 - accuracy: 0.8704 - val_loss: 0.3676 - val_accuracy: 0.9433\n",
            "Epoch 246/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.4305 - accuracy: 0.8642 - val_loss: 0.3385 - val_accuracy: 0.9433\n",
            "Epoch 247/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.4315 - accuracy: 0.8629 - val_loss: 0.3133 - val_accuracy: 0.9517\n",
            "Epoch 248/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.4212 - accuracy: 0.8721 - val_loss: 0.3196 - val_accuracy: 0.9533\n",
            "Epoch 249/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.4285 - accuracy: 0.8692 - val_loss: 0.3259 - val_accuracy: 0.9517\n",
            "Epoch 250/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.3845 - accuracy: 0.8788 - val_loss: 0.3154 - val_accuracy: 0.9617\n",
            "Epoch 251/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.3969 - accuracy: 0.8800 - val_loss: 0.3369 - val_accuracy: 0.9600\n",
            "Epoch 252/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.4329 - accuracy: 0.8692 - val_loss: 0.3072 - val_accuracy: 0.9583\n",
            "Epoch 253/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.3922 - accuracy: 0.8804 - val_loss: 0.3178 - val_accuracy: 0.9600\n",
            "Epoch 254/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.3745 - accuracy: 0.8796 - val_loss: 0.3787 - val_accuracy: 0.9533\n",
            "Epoch 255/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.3895 - accuracy: 0.8754 - val_loss: 0.3657 - val_accuracy: 0.9617\n",
            "Epoch 256/1000\n",
            "38/38 [==============================] - 1s 33ms/step - loss: 0.3895 - accuracy: 0.8888 - val_loss: 0.2926 - val_accuracy: 0.9583\n",
            "Epoch 257/1000\n",
            "38/38 [==============================] - 1s 35ms/step - loss: 0.4135 - accuracy: 0.8842 - val_loss: 0.2908 - val_accuracy: 0.9583\n",
            "Epoch 258/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.3819 - accuracy: 0.8833 - val_loss: 0.3207 - val_accuracy: 0.9567\n",
            "Epoch 259/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.3909 - accuracy: 0.8854 - val_loss: 0.3446 - val_accuracy: 0.9567\n",
            "Epoch 260/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.3964 - accuracy: 0.8879 - val_loss: 0.3023 - val_accuracy: 0.9600\n",
            "Epoch 261/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.3774 - accuracy: 0.8783 - val_loss: 0.2913 - val_accuracy: 0.9517\n",
            "Epoch 262/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.4000 - accuracy: 0.8800 - val_loss: 0.3113 - val_accuracy: 0.9517\n",
            "Epoch 263/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.3689 - accuracy: 0.8875 - val_loss: 0.3154 - val_accuracy: 0.9533\n",
            "Epoch 264/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.3803 - accuracy: 0.8825 - val_loss: 0.3350 - val_accuracy: 0.9533\n",
            "Epoch 265/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.3626 - accuracy: 0.8863 - val_loss: 0.3324 - val_accuracy: 0.9583\n",
            "Epoch 266/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.4020 - accuracy: 0.8808 - val_loss: 0.3446 - val_accuracy: 0.9650\n",
            "Epoch 267/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.4218 - accuracy: 0.8750 - val_loss: 0.3630 - val_accuracy: 0.9583\n",
            "Epoch 268/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.4235 - accuracy: 0.8788 - val_loss: 0.3619 - val_accuracy: 0.9583\n",
            "Epoch 269/1000\n",
            "38/38 [==============================] - 1s 28ms/step - loss: 0.3896 - accuracy: 0.8817 - val_loss: 0.3646 - val_accuracy: 0.9617\n",
            "Epoch 270/1000\n",
            "38/38 [==============================] - 1s 34ms/step - loss: 0.3800 - accuracy: 0.8896 - val_loss: 0.3313 - val_accuracy: 0.9700\n",
            "Epoch 271/1000\n",
            "38/38 [==============================] - 1s 32ms/step - loss: 0.4012 - accuracy: 0.8771 - val_loss: 0.3357 - val_accuracy: 0.9633\n",
            "Epoch 272/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.4090 - accuracy: 0.8792 - val_loss: 0.2843 - val_accuracy: 0.9600\n",
            "Epoch 273/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.3657 - accuracy: 0.8908 - val_loss: 0.2717 - val_accuracy: 0.9650\n",
            "Epoch 274/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.3649 - accuracy: 0.8904 - val_loss: 0.2874 - val_accuracy: 0.9517\n",
            "Epoch 275/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.3750 - accuracy: 0.8850 - val_loss: 0.2735 - val_accuracy: 0.9550\n",
            "Epoch 276/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.3518 - accuracy: 0.8883 - val_loss: 0.2434 - val_accuracy: 0.9633\n",
            "Epoch 277/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.3496 - accuracy: 0.8983 - val_loss: 0.2546 - val_accuracy: 0.9600\n",
            "Epoch 278/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.3127 - accuracy: 0.9025 - val_loss: 0.2305 - val_accuracy: 0.9667\n",
            "Epoch 279/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.3564 - accuracy: 0.8925 - val_loss: 0.2519 - val_accuracy: 0.9633\n",
            "Epoch 280/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.3594 - accuracy: 0.8908 - val_loss: 0.2809 - val_accuracy: 0.9667\n",
            "Epoch 281/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.3660 - accuracy: 0.8904 - val_loss: 0.3009 - val_accuracy: 0.9683\n",
            "Epoch 282/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.3419 - accuracy: 0.8988 - val_loss: 0.2751 - val_accuracy: 0.9633\n",
            "Epoch 283/1000\n",
            "38/38 [==============================] - 1s 34ms/step - loss: 0.3522 - accuracy: 0.8917 - val_loss: 0.2921 - val_accuracy: 0.9650\n",
            "Epoch 284/1000\n",
            "38/38 [==============================] - 1s 34ms/step - loss: 0.3657 - accuracy: 0.8933 - val_loss: 0.2273 - val_accuracy: 0.9683\n",
            "Epoch 285/1000\n",
            "38/38 [==============================] - 1s 29ms/step - loss: 0.3311 - accuracy: 0.8913 - val_loss: 0.2548 - val_accuracy: 0.9650\n",
            "Epoch 286/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.3467 - accuracy: 0.8958 - val_loss: 0.3226 - val_accuracy: 0.9667\n",
            "Epoch 287/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.3481 - accuracy: 0.8942 - val_loss: 0.2958 - val_accuracy: 0.9683\n",
            "Epoch 288/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.3160 - accuracy: 0.9008 - val_loss: 0.3332 - val_accuracy: 0.9667\n",
            "Epoch 289/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.3475 - accuracy: 0.8938 - val_loss: 0.2820 - val_accuracy: 0.9683\n",
            "Epoch 290/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.3414 - accuracy: 0.8950 - val_loss: 0.2742 - val_accuracy: 0.9700\n",
            "Epoch 291/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.3780 - accuracy: 0.8913 - val_loss: 0.2961 - val_accuracy: 0.9617\n",
            "Epoch 292/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.3309 - accuracy: 0.9025 - val_loss: 0.3035 - val_accuracy: 0.9633\n",
            "Epoch 293/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.3686 - accuracy: 0.8917 - val_loss: 0.2798 - val_accuracy: 0.9667\n",
            "Epoch 294/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.3387 - accuracy: 0.9004 - val_loss: 0.2722 - val_accuracy: 0.9633\n",
            "Epoch 295/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.3891 - accuracy: 0.8829 - val_loss: 0.2420 - val_accuracy: 0.9600\n",
            "Epoch 296/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.3518 - accuracy: 0.8892 - val_loss: 0.2738 - val_accuracy: 0.9650\n",
            "Epoch 297/1000\n",
            "38/38 [==============================] - 1s 35ms/step - loss: 0.3221 - accuracy: 0.9108 - val_loss: 0.2985 - val_accuracy: 0.9650\n",
            "Epoch 298/1000\n",
            "38/38 [==============================] - 1s 34ms/step - loss: 0.3466 - accuracy: 0.8979 - val_loss: 0.2902 - val_accuracy: 0.9633\n",
            "Epoch 299/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.2966 - accuracy: 0.9050 - val_loss: 0.2849 - val_accuracy: 0.9633\n",
            "Epoch 300/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.3346 - accuracy: 0.9038 - val_loss: 0.2983 - val_accuracy: 0.9633\n",
            "Epoch 301/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.2942 - accuracy: 0.9071 - val_loss: 0.2443 - val_accuracy: 0.9667\n",
            "Epoch 302/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.3601 - accuracy: 0.8896 - val_loss: 0.2929 - val_accuracy: 0.9700\n",
            "Epoch 303/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.2916 - accuracy: 0.9187 - val_loss: 0.2676 - val_accuracy: 0.9700\n",
            "Epoch 304/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.3100 - accuracy: 0.9071 - val_loss: 0.2909 - val_accuracy: 0.9700\n",
            "Epoch 305/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.3091 - accuracy: 0.9087 - val_loss: 0.3041 - val_accuracy: 0.9683\n",
            "Epoch 306/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.2999 - accuracy: 0.9104 - val_loss: 0.2934 - val_accuracy: 0.9583\n",
            "Epoch 307/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.3139 - accuracy: 0.9067 - val_loss: 0.2541 - val_accuracy: 0.9667\n",
            "Epoch 308/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.2996 - accuracy: 0.9092 - val_loss: 0.2809 - val_accuracy: 0.9617\n",
            "Epoch 309/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.3112 - accuracy: 0.9096 - val_loss: 0.2646 - val_accuracy: 0.9683\n",
            "Epoch 310/1000\n",
            "38/38 [==============================] - 1s 31ms/step - loss: 0.3196 - accuracy: 0.9075 - val_loss: 0.3134 - val_accuracy: 0.9683\n",
            "Epoch 311/1000\n",
            "38/38 [==============================] - 1s 35ms/step - loss: 0.3009 - accuracy: 0.9071 - val_loss: 0.3410 - val_accuracy: 0.9683\n",
            "Epoch 312/1000\n",
            "38/38 [==============================] - 1s 30ms/step - loss: 0.3428 - accuracy: 0.8979 - val_loss: 0.2591 - val_accuracy: 0.9783\n",
            "Epoch 313/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.3364 - accuracy: 0.9058 - val_loss: 0.2692 - val_accuracy: 0.9683\n",
            "Epoch 314/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.2993 - accuracy: 0.9071 - val_loss: 0.2622 - val_accuracy: 0.9650\n",
            "Epoch 315/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.3291 - accuracy: 0.9058 - val_loss: 0.2572 - val_accuracy: 0.9600\n",
            "Epoch 316/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.3436 - accuracy: 0.8983 - val_loss: 0.3026 - val_accuracy: 0.9600\n",
            "Epoch 317/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.3283 - accuracy: 0.8988 - val_loss: 0.3052 - val_accuracy: 0.9650\n",
            "Epoch 318/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.2991 - accuracy: 0.9142 - val_loss: 0.3426 - val_accuracy: 0.9567\n",
            "Epoch 319/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.3330 - accuracy: 0.9025 - val_loss: 0.2992 - val_accuracy: 0.9600\n",
            "Epoch 320/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.3261 - accuracy: 0.9100 - val_loss: 0.3104 - val_accuracy: 0.9633\n",
            "Epoch 321/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.3513 - accuracy: 0.8983 - val_loss: 0.2638 - val_accuracy: 0.9567\n",
            "Epoch 322/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.2956 - accuracy: 0.9087 - val_loss: 0.2627 - val_accuracy: 0.9667\n",
            "Epoch 323/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.2982 - accuracy: 0.9079 - val_loss: 0.3095 - val_accuracy: 0.9567\n",
            "Epoch 324/1000\n",
            "38/38 [==============================] - 1s 33ms/step - loss: 0.2973 - accuracy: 0.9125 - val_loss: 0.2726 - val_accuracy: 0.9650\n",
            "Epoch 325/1000\n",
            "38/38 [==============================] - 1s 32ms/step - loss: 0.3118 - accuracy: 0.9067 - val_loss: 0.2317 - val_accuracy: 0.9733\n",
            "Epoch 326/1000\n",
            "38/38 [==============================] - 1s 28ms/step - loss: 0.2806 - accuracy: 0.9208 - val_loss: 0.2578 - val_accuracy: 0.9550\n",
            "Epoch 327/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.2805 - accuracy: 0.9237 - val_loss: 0.2800 - val_accuracy: 0.9667\n",
            "Epoch 328/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.2530 - accuracy: 0.9154 - val_loss: 0.2710 - val_accuracy: 0.9650\n",
            "Epoch 329/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.2810 - accuracy: 0.9142 - val_loss: 0.2618 - val_accuracy: 0.9717\n",
            "Epoch 330/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.3155 - accuracy: 0.9125 - val_loss: 0.2291 - val_accuracy: 0.9650\n",
            "Epoch 331/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.3139 - accuracy: 0.9067 - val_loss: 0.2050 - val_accuracy: 0.9683\n",
            "Epoch 332/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.2883 - accuracy: 0.9192 - val_loss: 0.2534 - val_accuracy: 0.9600\n",
            "Epoch 333/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.3013 - accuracy: 0.9179 - val_loss: 0.2290 - val_accuracy: 0.9633\n",
            "Epoch 334/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.3031 - accuracy: 0.9121 - val_loss: 0.2684 - val_accuracy: 0.9667\n",
            "Epoch 335/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.3027 - accuracy: 0.9129 - val_loss: 0.2942 - val_accuracy: 0.9650\n",
            "Epoch 336/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.2805 - accuracy: 0.9150 - val_loss: 0.2710 - val_accuracy: 0.9633\n",
            "Epoch 337/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.2862 - accuracy: 0.9154 - val_loss: 0.2587 - val_accuracy: 0.9583\n",
            "Epoch 338/1000\n",
            "38/38 [==============================] - 1s 35ms/step - loss: 0.3109 - accuracy: 0.9083 - val_loss: 0.2685 - val_accuracy: 0.9600\n",
            "Epoch 339/1000\n",
            "38/38 [==============================] - 1s 36ms/step - loss: 0.3206 - accuracy: 0.9121 - val_loss: 0.2519 - val_accuracy: 0.9717\n",
            "Epoch 340/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.2836 - accuracy: 0.9187 - val_loss: 0.3140 - val_accuracy: 0.9617\n",
            "Epoch 341/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.2891 - accuracy: 0.9175 - val_loss: 0.2558 - val_accuracy: 0.9633\n",
            "Epoch 342/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.2948 - accuracy: 0.9104 - val_loss: 0.2636 - val_accuracy: 0.9600\n",
            "Epoch 343/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.3080 - accuracy: 0.9038 - val_loss: 0.2884 - val_accuracy: 0.9600\n",
            "Epoch 344/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.2774 - accuracy: 0.9204 - val_loss: 0.3308 - val_accuracy: 0.9633\n",
            "Epoch 345/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.2959 - accuracy: 0.9179 - val_loss: 0.2717 - val_accuracy: 0.9650\n",
            "Epoch 346/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.2944 - accuracy: 0.9117 - val_loss: 0.2008 - val_accuracy: 0.9650\n",
            "Epoch 347/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.3078 - accuracy: 0.9150 - val_loss: 0.2388 - val_accuracy: 0.9650\n",
            "Epoch 348/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.2784 - accuracy: 0.9233 - val_loss: 0.2716 - val_accuracy: 0.9650\n",
            "Epoch 349/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.2964 - accuracy: 0.9196 - val_loss: 0.2768 - val_accuracy: 0.9683\n",
            "Epoch 350/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.2547 - accuracy: 0.9254 - val_loss: 0.3129 - val_accuracy: 0.9633\n",
            "Epoch 351/1000\n",
            "38/38 [==============================] - 1s 31ms/step - loss: 0.3280 - accuracy: 0.9117 - val_loss: 0.2783 - val_accuracy: 0.9683\n",
            "Epoch 352/1000\n",
            "38/38 [==============================] - 1s 34ms/step - loss: 0.3176 - accuracy: 0.9021 - val_loss: 0.2463 - val_accuracy: 0.9733\n",
            "Epoch 353/1000\n",
            "38/38 [==============================] - 1s 31ms/step - loss: 0.2834 - accuracy: 0.9167 - val_loss: 0.2532 - val_accuracy: 0.9683\n",
            "Epoch 354/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.2360 - accuracy: 0.9292 - val_loss: 0.2344 - val_accuracy: 0.9667\n",
            "Epoch 355/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.2617 - accuracy: 0.9162 - val_loss: 0.2011 - val_accuracy: 0.9717\n",
            "Epoch 356/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.2884 - accuracy: 0.9212 - val_loss: 0.2118 - val_accuracy: 0.9733\n",
            "Epoch 357/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.2760 - accuracy: 0.9167 - val_loss: 0.2447 - val_accuracy: 0.9717\n",
            "Epoch 358/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.2801 - accuracy: 0.9242 - val_loss: 0.2538 - val_accuracy: 0.9733\n",
            "Epoch 359/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.3024 - accuracy: 0.9167 - val_loss: 0.2706 - val_accuracy: 0.9717\n",
            "Epoch 360/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.2757 - accuracy: 0.9187 - val_loss: 0.2650 - val_accuracy: 0.9750\n",
            "Epoch 361/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.3101 - accuracy: 0.9087 - val_loss: 0.2242 - val_accuracy: 0.9733\n",
            "Epoch 362/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.2638 - accuracy: 0.9229 - val_loss: 0.2095 - val_accuracy: 0.9717\n",
            "Epoch 363/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.2675 - accuracy: 0.9233 - val_loss: 0.2256 - val_accuracy: 0.9733\n",
            "Epoch 364/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.2789 - accuracy: 0.9192 - val_loss: 0.2230 - val_accuracy: 0.9767\n",
            "Epoch 365/1000\n",
            "38/38 [==============================] - 1s 35ms/step - loss: 0.2797 - accuracy: 0.9204 - val_loss: 0.1987 - val_accuracy: 0.9733\n",
            "Epoch 366/1000\n",
            "38/38 [==============================] - 1s 34ms/step - loss: 0.2707 - accuracy: 0.9217 - val_loss: 0.1859 - val_accuracy: 0.9750\n",
            "Epoch 367/1000\n",
            "38/38 [==============================] - 1s 29ms/step - loss: 0.2764 - accuracy: 0.9208 - val_loss: 0.1579 - val_accuracy: 0.9817\n",
            "Epoch 368/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.2502 - accuracy: 0.9229 - val_loss: 0.1526 - val_accuracy: 0.9767\n",
            "Epoch 369/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.2753 - accuracy: 0.9171 - val_loss: 0.2189 - val_accuracy: 0.9700\n",
            "Epoch 370/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.2670 - accuracy: 0.9158 - val_loss: 0.2327 - val_accuracy: 0.9733\n",
            "Epoch 371/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.2578 - accuracy: 0.9233 - val_loss: 0.2028 - val_accuracy: 0.9717\n",
            "Epoch 372/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.2624 - accuracy: 0.9254 - val_loss: 0.2004 - val_accuracy: 0.9717\n",
            "Epoch 373/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.2550 - accuracy: 0.9262 - val_loss: 0.1931 - val_accuracy: 0.9750\n",
            "Epoch 374/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.2775 - accuracy: 0.9250 - val_loss: 0.1844 - val_accuracy: 0.9750\n",
            "Epoch 375/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.2860 - accuracy: 0.9187 - val_loss: 0.1905 - val_accuracy: 0.9817\n",
            "Epoch 376/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.2557 - accuracy: 0.9283 - val_loss: 0.1931 - val_accuracy: 0.9733\n",
            "Epoch 377/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.2295 - accuracy: 0.9333 - val_loss: 0.1860 - val_accuracy: 0.9717\n",
            "Epoch 378/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.2666 - accuracy: 0.9204 - val_loss: 0.1710 - val_accuracy: 0.9783\n",
            "Epoch 379/1000\n",
            "38/38 [==============================] - 1s 34ms/step - loss: 0.2576 - accuracy: 0.9171 - val_loss: 0.1390 - val_accuracy: 0.9733\n",
            "Epoch 380/1000\n",
            "38/38 [==============================] - 1s 36ms/step - loss: 0.2884 - accuracy: 0.9162 - val_loss: 0.1626 - val_accuracy: 0.9717\n",
            "Epoch 381/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.2535 - accuracy: 0.9225 - val_loss: 0.2196 - val_accuracy: 0.9700\n",
            "Epoch 382/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.2763 - accuracy: 0.9212 - val_loss: 0.2354 - val_accuracy: 0.9783\n",
            "Epoch 383/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.2436 - accuracy: 0.9346 - val_loss: 0.2444 - val_accuracy: 0.9733\n",
            "Epoch 384/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.2592 - accuracy: 0.9254 - val_loss: 0.2396 - val_accuracy: 0.9733\n",
            "Epoch 385/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.2128 - accuracy: 0.9392 - val_loss: 0.2658 - val_accuracy: 0.9767\n",
            "Epoch 386/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.2705 - accuracy: 0.9237 - val_loss: 0.2457 - val_accuracy: 0.9800\n",
            "Epoch 387/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.2350 - accuracy: 0.9275 - val_loss: 0.2429 - val_accuracy: 0.9767\n",
            "Epoch 388/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.2287 - accuracy: 0.9312 - val_loss: 0.2505 - val_accuracy: 0.9767\n",
            "Epoch 389/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.2483 - accuracy: 0.9267 - val_loss: 0.2550 - val_accuracy: 0.9733\n",
            "Epoch 390/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.2567 - accuracy: 0.9233 - val_loss: 0.2741 - val_accuracy: 0.9733\n",
            "Epoch 391/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.2671 - accuracy: 0.9262 - val_loss: 0.2447 - val_accuracy: 0.9733\n",
            "Epoch 392/1000\n",
            "38/38 [==============================] - 1s 30ms/step - loss: 0.2355 - accuracy: 0.9267 - val_loss: 0.2307 - val_accuracy: 0.9733\n",
            "Epoch 393/1000\n",
            "38/38 [==============================] - 1s 33ms/step - loss: 0.2465 - accuracy: 0.9287 - val_loss: 0.2434 - val_accuracy: 0.9733\n",
            "Epoch 394/1000\n",
            "38/38 [==============================] - 1s 33ms/step - loss: 0.2772 - accuracy: 0.9233 - val_loss: 0.2034 - val_accuracy: 0.9733\n",
            "Epoch 395/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.2337 - accuracy: 0.9317 - val_loss: 0.2081 - val_accuracy: 0.9700\n",
            "Epoch 396/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.2233 - accuracy: 0.9325 - val_loss: 0.2181 - val_accuracy: 0.9700\n",
            "Epoch 397/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.2566 - accuracy: 0.9300 - val_loss: 0.2113 - val_accuracy: 0.9767\n",
            "Epoch 398/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.2326 - accuracy: 0.9342 - val_loss: 0.2249 - val_accuracy: 0.9733\n",
            "Epoch 399/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.2137 - accuracy: 0.9358 - val_loss: 0.2801 - val_accuracy: 0.9733\n",
            "Epoch 400/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.2300 - accuracy: 0.9371 - val_loss: 0.2454 - val_accuracy: 0.9750\n",
            "Epoch 401/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.2738 - accuracy: 0.9171 - val_loss: 0.2163 - val_accuracy: 0.9750\n",
            "Epoch 402/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.2442 - accuracy: 0.9292 - val_loss: 0.1971 - val_accuracy: 0.9733\n",
            "Epoch 403/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.2430 - accuracy: 0.9237 - val_loss: 0.1921 - val_accuracy: 0.9767\n",
            "Epoch 404/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.2469 - accuracy: 0.9246 - val_loss: 0.2417 - val_accuracy: 0.9717\n",
            "Epoch 405/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.2238 - accuracy: 0.9292 - val_loss: 0.2760 - val_accuracy: 0.9733\n",
            "Epoch 406/1000\n",
            "38/38 [==============================] - 1s 35ms/step - loss: 0.2771 - accuracy: 0.9233 - val_loss: 0.2637 - val_accuracy: 0.9767\n",
            "Epoch 407/1000\n",
            "38/38 [==============================] - 1s 35ms/step - loss: 0.2509 - accuracy: 0.9283 - val_loss: 0.2469 - val_accuracy: 0.9733\n",
            "Epoch 408/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.2619 - accuracy: 0.9212 - val_loss: 0.2611 - val_accuracy: 0.9733\n",
            "Epoch 409/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.2114 - accuracy: 0.9333 - val_loss: 0.2238 - val_accuracy: 0.9783\n",
            "Epoch 410/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.2358 - accuracy: 0.9317 - val_loss: 0.2146 - val_accuracy: 0.9783\n",
            "Epoch 411/1000\n",
            "38/38 [==============================] - 1s 32ms/step - loss: 0.2462 - accuracy: 0.9337 - val_loss: 0.2138 - val_accuracy: 0.9767\n",
            "Epoch 412/1000\n",
            "38/38 [==============================] - 2s 56ms/step - loss: 0.2388 - accuracy: 0.9304 - val_loss: 0.2874 - val_accuracy: 0.9767\n",
            "Epoch 413/1000\n",
            "38/38 [==============================] - 2s 41ms/step - loss: 0.2214 - accuracy: 0.9367 - val_loss: 0.2760 - val_accuracy: 0.9733\n",
            "Epoch 414/1000\n",
            "38/38 [==============================] - 2s 44ms/step - loss: 0.2455 - accuracy: 0.9279 - val_loss: 0.1425 - val_accuracy: 0.9733\n",
            "Epoch 415/1000\n",
            "38/38 [==============================] - 2s 41ms/step - loss: 0.2343 - accuracy: 0.9317 - val_loss: 0.1582 - val_accuracy: 0.9733\n",
            "Epoch 416/1000\n",
            "38/38 [==============================] - 1s 35ms/step - loss: 0.2573 - accuracy: 0.9283 - val_loss: 0.1375 - val_accuracy: 0.9733\n",
            "Epoch 417/1000\n",
            "38/38 [==============================] - 1s 35ms/step - loss: 0.2349 - accuracy: 0.9329 - val_loss: 0.1405 - val_accuracy: 0.9733\n",
            "Epoch 418/1000\n",
            "38/38 [==============================] - 1s 27ms/step - loss: 0.2376 - accuracy: 0.9312 - val_loss: 0.1491 - val_accuracy: 0.9767\n",
            "Epoch 419/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.2406 - accuracy: 0.9312 - val_loss: 0.1483 - val_accuracy: 0.9783\n",
            "Epoch 420/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.2352 - accuracy: 0.9333 - val_loss: 0.1806 - val_accuracy: 0.9700\n",
            "Epoch 421/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1996 - accuracy: 0.9446 - val_loss: 0.1894 - val_accuracy: 0.9767\n",
            "Epoch 422/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.2190 - accuracy: 0.9342 - val_loss: 0.1702 - val_accuracy: 0.9750\n",
            "Epoch 423/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.2453 - accuracy: 0.9300 - val_loss: 0.1791 - val_accuracy: 0.9750\n",
            "Epoch 424/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.2287 - accuracy: 0.9317 - val_loss: 0.1711 - val_accuracy: 0.9750\n",
            "Epoch 425/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.2299 - accuracy: 0.9350 - val_loss: 0.1684 - val_accuracy: 0.9767\n",
            "Epoch 426/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.2234 - accuracy: 0.9417 - val_loss: 0.1658 - val_accuracy: 0.9767\n",
            "Epoch 427/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.2272 - accuracy: 0.9317 - val_loss: 0.1079 - val_accuracy: 0.9767\n",
            "Epoch 428/1000\n",
            "38/38 [==============================] - 1s 30ms/step - loss: 0.2314 - accuracy: 0.9300 - val_loss: 0.1331 - val_accuracy: 0.9733\n",
            "Epoch 429/1000\n",
            "38/38 [==============================] - 1s 36ms/step - loss: 0.2187 - accuracy: 0.9388 - val_loss: 0.1512 - val_accuracy: 0.9767\n",
            "Epoch 430/1000\n",
            "38/38 [==============================] - 1s 37ms/step - loss: 0.2609 - accuracy: 0.9292 - val_loss: 0.1497 - val_accuracy: 0.9767\n",
            "Epoch 431/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.2050 - accuracy: 0.9362 - val_loss: 0.1715 - val_accuracy: 0.9767\n",
            "Epoch 432/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.2130 - accuracy: 0.9317 - val_loss: 0.1801 - val_accuracy: 0.9717\n",
            "Epoch 433/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.2772 - accuracy: 0.9221 - val_loss: 0.1736 - val_accuracy: 0.9767\n",
            "Epoch 434/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.2463 - accuracy: 0.9262 - val_loss: 0.2049 - val_accuracy: 0.9717\n",
            "Epoch 435/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1953 - accuracy: 0.9425 - val_loss: 0.2508 - val_accuracy: 0.9717\n",
            "Epoch 436/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.2663 - accuracy: 0.9279 - val_loss: 0.2321 - val_accuracy: 0.9683\n",
            "Epoch 437/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.2294 - accuracy: 0.9375 - val_loss: 0.1893 - val_accuracy: 0.9683\n",
            "Epoch 438/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.2126 - accuracy: 0.9396 - val_loss: 0.2523 - val_accuracy: 0.9717\n",
            "Epoch 439/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1982 - accuracy: 0.9442 - val_loss: 0.2534 - val_accuracy: 0.9683\n",
            "Epoch 440/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.2611 - accuracy: 0.9312 - val_loss: 0.2372 - val_accuracy: 0.9683\n",
            "Epoch 441/1000\n",
            "38/38 [==============================] - 1s 31ms/step - loss: 0.2226 - accuracy: 0.9388 - val_loss: 0.2531 - val_accuracy: 0.9750\n",
            "Epoch 442/1000\n",
            "38/38 [==============================] - 1s 32ms/step - loss: 0.2057 - accuracy: 0.9396 - val_loss: 0.2325 - val_accuracy: 0.9717\n",
            "Epoch 443/1000\n",
            "38/38 [==============================] - 1s 37ms/step - loss: 0.2182 - accuracy: 0.9292 - val_loss: 0.2172 - val_accuracy: 0.9750\n",
            "Epoch 444/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.2321 - accuracy: 0.9342 - val_loss: 0.2064 - val_accuracy: 0.9683\n",
            "Epoch 445/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.2236 - accuracy: 0.9333 - val_loss: 0.2217 - val_accuracy: 0.9700\n",
            "Epoch 446/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.2222 - accuracy: 0.9358 - val_loss: 0.2659 - val_accuracy: 0.9700\n",
            "Epoch 447/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.2490 - accuracy: 0.9300 - val_loss: 0.2546 - val_accuracy: 0.9700\n",
            "Epoch 448/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.2277 - accuracy: 0.9308 - val_loss: 0.2134 - val_accuracy: 0.9733\n",
            "Epoch 449/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.2247 - accuracy: 0.9346 - val_loss: 0.2223 - val_accuracy: 0.9733\n",
            "Epoch 450/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.2299 - accuracy: 0.9413 - val_loss: 0.2513 - val_accuracy: 0.9733\n",
            "Epoch 451/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1964 - accuracy: 0.9442 - val_loss: 0.2069 - val_accuracy: 0.9733\n",
            "Epoch 452/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.2291 - accuracy: 0.9321 - val_loss: 0.2345 - val_accuracy: 0.9650\n",
            "Epoch 453/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.2405 - accuracy: 0.9350 - val_loss: 0.2168 - val_accuracy: 0.9650\n",
            "Epoch 454/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.2257 - accuracy: 0.9329 - val_loss: 0.1937 - val_accuracy: 0.9700\n",
            "Epoch 455/1000\n",
            "38/38 [==============================] - 1s 34ms/step - loss: 0.2017 - accuracy: 0.9408 - val_loss: 0.2475 - val_accuracy: 0.9733\n",
            "Epoch 456/1000\n",
            "38/38 [==============================] - 1s 34ms/step - loss: 0.2331 - accuracy: 0.9300 - val_loss: 0.2334 - val_accuracy: 0.9767\n",
            "Epoch 457/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1846 - accuracy: 0.9463 - val_loss: 0.2595 - val_accuracy: 0.9767\n",
            "Epoch 458/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1937 - accuracy: 0.9454 - val_loss: 0.2624 - val_accuracy: 0.9733\n",
            "Epoch 459/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.2273 - accuracy: 0.9400 - val_loss: 0.2637 - val_accuracy: 0.9733\n",
            "Epoch 460/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.2229 - accuracy: 0.9413 - val_loss: 0.2042 - val_accuracy: 0.9733\n",
            "Epoch 461/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.2106 - accuracy: 0.9392 - val_loss: 0.1841 - val_accuracy: 0.9733\n",
            "Epoch 462/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.2346 - accuracy: 0.9350 - val_loss: 0.2003 - val_accuracy: 0.9733\n",
            "Epoch 463/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.2121 - accuracy: 0.9358 - val_loss: 0.2256 - val_accuracy: 0.9733\n",
            "Epoch 464/1000\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.2415 - accuracy: 0.9362 - val_loss: 0.2392 - val_accuracy: 0.9733\n",
            "Epoch 465/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.2405 - accuracy: 0.9388 - val_loss: 0.2412 - val_accuracy: 0.9733\n",
            "Epoch 466/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.2115 - accuracy: 0.9383 - val_loss: 0.2147 - val_accuracy: 0.9733\n",
            "Epoch 467/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.2014 - accuracy: 0.9483 - val_loss: 0.2298 - val_accuracy: 0.9733\n",
            "Epoch 468/1000\n",
            "38/38 [==============================] - 1s 32ms/step - loss: 0.2611 - accuracy: 0.9275 - val_loss: 0.1713 - val_accuracy: 0.9767\n",
            "Epoch 469/1000\n",
            "38/38 [==============================] - 1s 32ms/step - loss: 0.2109 - accuracy: 0.9442 - val_loss: 0.1722 - val_accuracy: 0.9767\n",
            "Epoch 470/1000\n",
            "38/38 [==============================] - 1s 35ms/step - loss: 0.2335 - accuracy: 0.9400 - val_loss: 0.1785 - val_accuracy: 0.9733\n",
            "Epoch 471/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.2065 - accuracy: 0.9429 - val_loss: 0.2057 - val_accuracy: 0.9683\n",
            "Epoch 472/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.2165 - accuracy: 0.9396 - val_loss: 0.1765 - val_accuracy: 0.9733\n",
            "Epoch 473/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.1935 - accuracy: 0.9450 - val_loss: 0.1817 - val_accuracy: 0.9767\n",
            "Epoch 474/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.2162 - accuracy: 0.9383 - val_loss: 0.2113 - val_accuracy: 0.9767\n",
            "Epoch 475/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.2240 - accuracy: 0.9346 - val_loss: 0.2063 - val_accuracy: 0.9733\n",
            "Epoch 476/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1870 - accuracy: 0.9421 - val_loss: 0.2140 - val_accuracy: 0.9767\n",
            "Epoch 477/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.2009 - accuracy: 0.9425 - val_loss: 0.1759 - val_accuracy: 0.9767\n",
            "Epoch 478/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.2239 - accuracy: 0.9367 - val_loss: 0.1430 - val_accuracy: 0.9783\n",
            "Epoch 479/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.1956 - accuracy: 0.9463 - val_loss: 0.1651 - val_accuracy: 0.9767\n",
            "Epoch 480/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1993 - accuracy: 0.9450 - val_loss: 0.1699 - val_accuracy: 0.9767\n",
            "Epoch 481/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.2192 - accuracy: 0.9362 - val_loss: 0.1840 - val_accuracy: 0.9783\n",
            "Epoch 482/1000\n",
            "38/38 [==============================] - 1s 33ms/step - loss: 0.2058 - accuracy: 0.9454 - val_loss: 0.2192 - val_accuracy: 0.9717\n",
            "Epoch 483/1000\n",
            "38/38 [==============================] - 1s 37ms/step - loss: 0.1857 - accuracy: 0.9458 - val_loss: 0.2676 - val_accuracy: 0.9717\n",
            "Epoch 484/1000\n",
            "38/38 [==============================] - 1s 30ms/step - loss: 0.2190 - accuracy: 0.9371 - val_loss: 0.2103 - val_accuracy: 0.9733\n",
            "Epoch 485/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.2043 - accuracy: 0.9379 - val_loss: 0.2149 - val_accuracy: 0.9767\n",
            "Epoch 486/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.2311 - accuracy: 0.9362 - val_loss: 0.1932 - val_accuracy: 0.9733\n",
            "Epoch 487/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.2018 - accuracy: 0.9392 - val_loss: 0.1690 - val_accuracy: 0.9700\n",
            "Epoch 488/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.2277 - accuracy: 0.9413 - val_loss: 0.1630 - val_accuracy: 0.9733\n",
            "Epoch 489/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.2071 - accuracy: 0.9429 - val_loss: 0.2038 - val_accuracy: 0.9733\n",
            "Epoch 490/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.2059 - accuracy: 0.9433 - val_loss: 0.1732 - val_accuracy: 0.9767\n",
            "Epoch 491/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1874 - accuracy: 0.9546 - val_loss: 0.1693 - val_accuracy: 0.9767\n",
            "Epoch 492/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1914 - accuracy: 0.9454 - val_loss: 0.1734 - val_accuracy: 0.9733\n",
            "Epoch 493/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.2172 - accuracy: 0.9404 - val_loss: 0.1494 - val_accuracy: 0.9767\n",
            "Epoch 494/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1928 - accuracy: 0.9400 - val_loss: 0.1556 - val_accuracy: 0.9733\n",
            "Epoch 495/1000\n",
            "38/38 [==============================] - 1s 29ms/step - loss: 0.2105 - accuracy: 0.9362 - val_loss: 0.1500 - val_accuracy: 0.9800\n",
            "Epoch 496/1000\n",
            "38/38 [==============================] - 1s 36ms/step - loss: 0.2138 - accuracy: 0.9371 - val_loss: 0.1290 - val_accuracy: 0.9717\n",
            "Epoch 497/1000\n",
            "38/38 [==============================] - 1s 33ms/step - loss: 0.1940 - accuracy: 0.9446 - val_loss: 0.1258 - val_accuracy: 0.9767\n",
            "Epoch 498/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.1696 - accuracy: 0.9479 - val_loss: 0.1190 - val_accuracy: 0.9783\n",
            "Epoch 499/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1872 - accuracy: 0.9438 - val_loss: 0.1332 - val_accuracy: 0.9767\n",
            "Epoch 500/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.2036 - accuracy: 0.9450 - val_loss: 0.1130 - val_accuracy: 0.9800\n",
            "Epoch 501/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1947 - accuracy: 0.9508 - val_loss: 0.0992 - val_accuracy: 0.9800\n",
            "Epoch 502/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.1628 - accuracy: 0.9529 - val_loss: 0.1347 - val_accuracy: 0.9800\n",
            "Epoch 503/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.2000 - accuracy: 0.9446 - val_loss: 0.1547 - val_accuracy: 0.9767\n",
            "Epoch 504/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.2029 - accuracy: 0.9450 - val_loss: 0.1539 - val_accuracy: 0.9767\n",
            "Epoch 505/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.2042 - accuracy: 0.9467 - val_loss: 0.1344 - val_accuracy: 0.9767\n",
            "Epoch 506/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1950 - accuracy: 0.9463 - val_loss: 0.1101 - val_accuracy: 0.9767\n",
            "Epoch 507/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.2075 - accuracy: 0.9371 - val_loss: 0.1389 - val_accuracy: 0.9767\n",
            "Epoch 508/1000\n",
            "38/38 [==============================] - 1s 28ms/step - loss: 0.1676 - accuracy: 0.9525 - val_loss: 0.1678 - val_accuracy: 0.9767\n",
            "Epoch 509/1000\n",
            "38/38 [==============================] - 1s 33ms/step - loss: 0.1952 - accuracy: 0.9396 - val_loss: 0.1620 - val_accuracy: 0.9733\n",
            "Epoch 510/1000\n",
            "38/38 [==============================] - 1s 34ms/step - loss: 0.1775 - accuracy: 0.9513 - val_loss: 0.1800 - val_accuracy: 0.9733\n",
            "Epoch 511/1000\n",
            "38/38 [==============================] - 1s 27ms/step - loss: 0.2308 - accuracy: 0.9342 - val_loss: 0.1888 - val_accuracy: 0.9733\n",
            "Epoch 512/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.2064 - accuracy: 0.9475 - val_loss: 0.2083 - val_accuracy: 0.9767\n",
            "Epoch 513/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.2003 - accuracy: 0.9504 - val_loss: 0.1722 - val_accuracy: 0.9767\n",
            "Epoch 514/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1955 - accuracy: 0.9429 - val_loss: 0.1923 - val_accuracy: 0.9767\n",
            "Epoch 515/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.2200 - accuracy: 0.9333 - val_loss: 0.2041 - val_accuracy: 0.9733\n",
            "Epoch 516/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.2293 - accuracy: 0.9367 - val_loss: 0.1954 - val_accuracy: 0.9767\n",
            "Epoch 517/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.1975 - accuracy: 0.9392 - val_loss: 0.1645 - val_accuracy: 0.9767\n",
            "Epoch 518/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.2043 - accuracy: 0.9417 - val_loss: 0.2159 - val_accuracy: 0.9767\n",
            "Epoch 519/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.1969 - accuracy: 0.9425 - val_loss: 0.1834 - val_accuracy: 0.9767\n",
            "Epoch 520/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.2105 - accuracy: 0.9433 - val_loss: 0.1931 - val_accuracy: 0.9767\n",
            "Epoch 521/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.1552 - accuracy: 0.9563 - val_loss: 0.1964 - val_accuracy: 0.9800\n",
            "Epoch 522/1000\n",
            "38/38 [==============================] - 1s 33ms/step - loss: 0.1942 - accuracy: 0.9400 - val_loss: 0.2105 - val_accuracy: 0.9767\n",
            "Epoch 523/1000\n",
            "38/38 [==============================] - 1s 36ms/step - loss: 0.2148 - accuracy: 0.9408 - val_loss: 0.2136 - val_accuracy: 0.9767\n",
            "Epoch 524/1000\n",
            "38/38 [==============================] - 1s 32ms/step - loss: 0.1647 - accuracy: 0.9538 - val_loss: 0.2142 - val_accuracy: 0.9767\n",
            "Epoch 525/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.1725 - accuracy: 0.9475 - val_loss: 0.2274 - val_accuracy: 0.9750\n",
            "Epoch 526/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.1768 - accuracy: 0.9500 - val_loss: 0.1560 - val_accuracy: 0.9800\n",
            "Epoch 527/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.2307 - accuracy: 0.9342 - val_loss: 0.1716 - val_accuracy: 0.9767\n",
            "Epoch 528/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1672 - accuracy: 0.9542 - val_loss: 0.1962 - val_accuracy: 0.9717\n",
            "Epoch 529/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1844 - accuracy: 0.9488 - val_loss: 0.1414 - val_accuracy: 0.9767\n",
            "Epoch 530/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.2027 - accuracy: 0.9433 - val_loss: 0.1632 - val_accuracy: 0.9767\n",
            "Epoch 531/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1763 - accuracy: 0.9496 - val_loss: 0.2150 - val_accuracy: 0.9767\n",
            "Epoch 532/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1663 - accuracy: 0.9479 - val_loss: 0.2285 - val_accuracy: 0.9767\n",
            "Epoch 533/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.1793 - accuracy: 0.9538 - val_loss: 0.2442 - val_accuracy: 0.9767\n",
            "Epoch 534/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.1971 - accuracy: 0.9458 - val_loss: 0.2018 - val_accuracy: 0.9767\n",
            "Epoch 535/1000\n",
            "38/38 [==============================] - 1s 30ms/step - loss: 0.1865 - accuracy: 0.9475 - val_loss: 0.1558 - val_accuracy: 0.9767\n",
            "Epoch 536/1000\n",
            "38/38 [==============================] - 1s 36ms/step - loss: 0.2067 - accuracy: 0.9438 - val_loss: 0.1578 - val_accuracy: 0.9767\n",
            "Epoch 537/1000\n",
            "38/38 [==============================] - 1s 36ms/step - loss: 0.2112 - accuracy: 0.9483 - val_loss: 0.1818 - val_accuracy: 0.9767\n",
            "Epoch 538/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1689 - accuracy: 0.9517 - val_loss: 0.1746 - val_accuracy: 0.9767\n",
            "Epoch 539/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.1845 - accuracy: 0.9492 - val_loss: 0.1903 - val_accuracy: 0.9767\n",
            "Epoch 540/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.1817 - accuracy: 0.9492 - val_loss: 0.1925 - val_accuracy: 0.9717\n",
            "Epoch 541/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1796 - accuracy: 0.9438 - val_loss: 0.2205 - val_accuracy: 0.9767\n",
            "Epoch 542/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1810 - accuracy: 0.9496 - val_loss: 0.2049 - val_accuracy: 0.9767\n",
            "Epoch 543/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1974 - accuracy: 0.9404 - val_loss: 0.1990 - val_accuracy: 0.9800\n",
            "Epoch 544/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1897 - accuracy: 0.9479 - val_loss: 0.1796 - val_accuracy: 0.9800\n",
            "Epoch 545/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1899 - accuracy: 0.9513 - val_loss: 0.1589 - val_accuracy: 0.9800\n",
            "Epoch 546/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1981 - accuracy: 0.9504 - val_loss: 0.1601 - val_accuracy: 0.9767\n",
            "Epoch 547/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1698 - accuracy: 0.9513 - val_loss: 0.1790 - val_accuracy: 0.9767\n",
            "Epoch 548/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1467 - accuracy: 0.9546 - val_loss: 0.1789 - val_accuracy: 0.9767\n",
            "Epoch 549/1000\n",
            "38/38 [==============================] - 1s 37ms/step - loss: 0.1674 - accuracy: 0.9458 - val_loss: 0.1821 - val_accuracy: 0.9767\n",
            "Epoch 550/1000\n",
            "38/38 [==============================] - 1s 35ms/step - loss: 0.1714 - accuracy: 0.9554 - val_loss: 0.1761 - val_accuracy: 0.9767\n",
            "Epoch 551/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1746 - accuracy: 0.9500 - val_loss: 0.2037 - val_accuracy: 0.9767\n",
            "Epoch 552/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1585 - accuracy: 0.9529 - val_loss: 0.2388 - val_accuracy: 0.9767\n",
            "Epoch 553/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1829 - accuracy: 0.9475 - val_loss: 0.2391 - val_accuracy: 0.9767\n",
            "Epoch 554/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1842 - accuracy: 0.9417 - val_loss: 0.2229 - val_accuracy: 0.9767\n",
            "Epoch 555/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1721 - accuracy: 0.9496 - val_loss: 0.1897 - val_accuracy: 0.9767\n",
            "Epoch 556/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.2071 - accuracy: 0.9508 - val_loss: 0.2034 - val_accuracy: 0.9800\n",
            "Epoch 557/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1867 - accuracy: 0.9463 - val_loss: 0.1663 - val_accuracy: 0.9800\n",
            "Epoch 558/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1509 - accuracy: 0.9600 - val_loss: 0.1985 - val_accuracy: 0.9767\n",
            "Epoch 559/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.1993 - accuracy: 0.9471 - val_loss: 0.2058 - val_accuracy: 0.9800\n",
            "Epoch 560/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1857 - accuracy: 0.9492 - val_loss: 0.2019 - val_accuracy: 0.9800\n",
            "Epoch 561/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1808 - accuracy: 0.9496 - val_loss: 0.1900 - val_accuracy: 0.9767\n",
            "Epoch 562/1000\n",
            "38/38 [==============================] - 1s 34ms/step - loss: 0.2013 - accuracy: 0.9450 - val_loss: 0.2190 - val_accuracy: 0.9800\n",
            "Epoch 563/1000\n",
            "38/38 [==============================] - 1s 35ms/step - loss: 0.2146 - accuracy: 0.9433 - val_loss: 0.2637 - val_accuracy: 0.9767\n",
            "Epoch 564/1000\n",
            "38/38 [==============================] - 1s 31ms/step - loss: 0.1590 - accuracy: 0.9533 - val_loss: 0.2493 - val_accuracy: 0.9767\n",
            "Epoch 565/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1796 - accuracy: 0.9538 - val_loss: 0.2332 - val_accuracy: 0.9800\n",
            "Epoch 566/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.1559 - accuracy: 0.9521 - val_loss: 0.2573 - val_accuracy: 0.9800\n",
            "Epoch 567/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1735 - accuracy: 0.9488 - val_loss: 0.3300 - val_accuracy: 0.9800\n",
            "Epoch 568/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1688 - accuracy: 0.9538 - val_loss: 0.3499 - val_accuracy: 0.9800\n",
            "Epoch 569/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1612 - accuracy: 0.9558 - val_loss: 0.3119 - val_accuracy: 0.9800\n",
            "Epoch 570/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.1681 - accuracy: 0.9554 - val_loss: 0.2415 - val_accuracy: 0.9800\n",
            "Epoch 571/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1493 - accuracy: 0.9563 - val_loss: 0.2076 - val_accuracy: 0.9767\n",
            "Epoch 572/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1796 - accuracy: 0.9525 - val_loss: 0.1860 - val_accuracy: 0.9717\n",
            "Epoch 573/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1662 - accuracy: 0.9521 - val_loss: 0.1492 - val_accuracy: 0.9717\n",
            "Epoch 574/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.2059 - accuracy: 0.9413 - val_loss: 0.1693 - val_accuracy: 0.9717\n",
            "Epoch 575/1000\n",
            "38/38 [==============================] - 1s 27ms/step - loss: 0.1783 - accuracy: 0.9488 - val_loss: 0.1477 - val_accuracy: 0.9767\n",
            "Epoch 576/1000\n",
            "38/38 [==============================] - 1s 35ms/step - loss: 0.1996 - accuracy: 0.9492 - val_loss: 0.1139 - val_accuracy: 0.9800\n",
            "Epoch 577/1000\n",
            "38/38 [==============================] - 1s 36ms/step - loss: 0.1778 - accuracy: 0.9517 - val_loss: 0.1222 - val_accuracy: 0.9800\n",
            "Epoch 578/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.2281 - accuracy: 0.9450 - val_loss: 0.0953 - val_accuracy: 0.9800\n",
            "Epoch 579/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1636 - accuracy: 0.9513 - val_loss: 0.1188 - val_accuracy: 0.9767\n",
            "Epoch 580/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1692 - accuracy: 0.9529 - val_loss: 0.2506 - val_accuracy: 0.9767\n",
            "Epoch 581/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1779 - accuracy: 0.9479 - val_loss: 0.2464 - val_accuracy: 0.9767\n",
            "Epoch 582/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1871 - accuracy: 0.9479 - val_loss: 0.2269 - val_accuracy: 0.9800\n",
            "Epoch 583/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.1814 - accuracy: 0.9429 - val_loss: 0.2742 - val_accuracy: 0.9767\n",
            "Epoch 584/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1728 - accuracy: 0.9500 - val_loss: 0.2814 - val_accuracy: 0.9767\n",
            "Epoch 585/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1898 - accuracy: 0.9463 - val_loss: 0.2865 - val_accuracy: 0.9767\n",
            "Epoch 586/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1748 - accuracy: 0.9521 - val_loss: 0.2331 - val_accuracy: 0.9767\n",
            "Epoch 587/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.2234 - accuracy: 0.9454 - val_loss: 0.2526 - val_accuracy: 0.9800\n",
            "Epoch 588/1000\n",
            "38/38 [==============================] - 1s 28ms/step - loss: 0.1756 - accuracy: 0.9508 - val_loss: 0.2641 - val_accuracy: 0.9767\n",
            "Epoch 589/1000\n",
            "38/38 [==============================] - 1s 37ms/step - loss: 0.1710 - accuracy: 0.9567 - val_loss: 0.2747 - val_accuracy: 0.9767\n",
            "Epoch 590/1000\n",
            "38/38 [==============================] - 1s 36ms/step - loss: 0.1606 - accuracy: 0.9579 - val_loss: 0.2808 - val_accuracy: 0.9800\n",
            "Epoch 591/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.1864 - accuracy: 0.9504 - val_loss: 0.2361 - val_accuracy: 0.9800\n",
            "Epoch 592/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.1820 - accuracy: 0.9500 - val_loss: 0.2520 - val_accuracy: 0.9767\n",
            "Epoch 593/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.1834 - accuracy: 0.9558 - val_loss: 0.2622 - val_accuracy: 0.9800\n",
            "Epoch 594/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1879 - accuracy: 0.9517 - val_loss: 0.2433 - val_accuracy: 0.9800\n",
            "Epoch 595/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1881 - accuracy: 0.9496 - val_loss: 0.2340 - val_accuracy: 0.9767\n",
            "Epoch 596/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1895 - accuracy: 0.9438 - val_loss: 0.2483 - val_accuracy: 0.9733\n",
            "Epoch 597/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1828 - accuracy: 0.9479 - val_loss: 0.2522 - val_accuracy: 0.9767\n",
            "Epoch 598/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1693 - accuracy: 0.9533 - val_loss: 0.2254 - val_accuracy: 0.9800\n",
            "Epoch 599/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1918 - accuracy: 0.9467 - val_loss: 0.2114 - val_accuracy: 0.9767\n",
            "Epoch 600/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1967 - accuracy: 0.9529 - val_loss: 0.1848 - val_accuracy: 0.9767\n",
            "Epoch 601/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1670 - accuracy: 0.9533 - val_loss: 0.1836 - val_accuracy: 0.9767\n",
            "Epoch 602/1000\n",
            "38/38 [==============================] - 1s 35ms/step - loss: 0.1724 - accuracy: 0.9492 - val_loss: 0.1600 - val_accuracy: 0.9767\n",
            "Epoch 603/1000\n",
            "38/38 [==============================] - 1s 33ms/step - loss: 0.1711 - accuracy: 0.9504 - val_loss: 0.1636 - val_accuracy: 0.9800\n",
            "Epoch 604/1000\n",
            "38/38 [==============================] - 1s 32ms/step - loss: 0.1574 - accuracy: 0.9533 - val_loss: 0.2054 - val_accuracy: 0.9800\n",
            "Epoch 605/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1559 - accuracy: 0.9567 - val_loss: 0.2261 - val_accuracy: 0.9767\n",
            "Epoch 606/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1528 - accuracy: 0.9571 - val_loss: 0.2412 - val_accuracy: 0.9800\n",
            "Epoch 607/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1544 - accuracy: 0.9558 - val_loss: 0.2224 - val_accuracy: 0.9800\n",
            "Epoch 608/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1708 - accuracy: 0.9504 - val_loss: 0.2084 - val_accuracy: 0.9800\n",
            "Epoch 609/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1906 - accuracy: 0.9496 - val_loss: 0.1838 - val_accuracy: 0.9800\n",
            "Epoch 610/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1574 - accuracy: 0.9579 - val_loss: 0.1774 - val_accuracy: 0.9850\n",
            "Epoch 611/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1705 - accuracy: 0.9513 - val_loss: 0.1696 - val_accuracy: 0.9800\n",
            "Epoch 612/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1753 - accuracy: 0.9538 - val_loss: 0.1781 - val_accuracy: 0.9767\n",
            "Epoch 613/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1901 - accuracy: 0.9475 - val_loss: 0.1908 - val_accuracy: 0.9800\n",
            "Epoch 614/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1705 - accuracy: 0.9529 - val_loss: 0.1804 - val_accuracy: 0.9800\n",
            "Epoch 615/1000\n",
            "38/38 [==============================] - 1s 33ms/step - loss: 0.1540 - accuracy: 0.9571 - val_loss: 0.1756 - val_accuracy: 0.9800\n",
            "Epoch 616/1000\n",
            "38/38 [==============================] - 1s 34ms/step - loss: 0.1771 - accuracy: 0.9525 - val_loss: 0.1973 - val_accuracy: 0.9767\n",
            "Epoch 617/1000\n",
            "38/38 [==============================] - 1s 34ms/step - loss: 0.1665 - accuracy: 0.9533 - val_loss: 0.1575 - val_accuracy: 0.9800\n",
            "Epoch 618/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1600 - accuracy: 0.9533 - val_loss: 0.1536 - val_accuracy: 0.9800\n",
            "Epoch 619/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1487 - accuracy: 0.9571 - val_loss: 0.1709 - val_accuracy: 0.9800\n",
            "Epoch 620/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1502 - accuracy: 0.9554 - val_loss: 0.1388 - val_accuracy: 0.9800\n",
            "Epoch 621/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1850 - accuracy: 0.9533 - val_loss: 0.1631 - val_accuracy: 0.9800\n",
            "Epoch 622/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1877 - accuracy: 0.9450 - val_loss: 0.1383 - val_accuracy: 0.9800\n",
            "Epoch 623/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1451 - accuracy: 0.9604 - val_loss: 0.1566 - val_accuracy: 0.9800\n",
            "Epoch 624/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1565 - accuracy: 0.9550 - val_loss: 0.1474 - val_accuracy: 0.9800\n",
            "Epoch 625/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1680 - accuracy: 0.9496 - val_loss: 0.1601 - val_accuracy: 0.9800\n",
            "Epoch 626/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.1583 - accuracy: 0.9571 - val_loss: 0.1301 - val_accuracy: 0.9800\n",
            "Epoch 627/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.1661 - accuracy: 0.9488 - val_loss: 0.1452 - val_accuracy: 0.9800\n",
            "Epoch 628/1000\n",
            "38/38 [==============================] - 1s 27ms/step - loss: 0.1416 - accuracy: 0.9550 - val_loss: 0.1764 - val_accuracy: 0.9800\n",
            "Epoch 629/1000\n",
            "38/38 [==============================] - 1s 33ms/step - loss: 0.1464 - accuracy: 0.9604 - val_loss: 0.2091 - val_accuracy: 0.9800\n",
            "Epoch 630/1000\n",
            "38/38 [==============================] - 1s 36ms/step - loss: 0.1696 - accuracy: 0.9575 - val_loss: 0.2157 - val_accuracy: 0.9800\n",
            "Epoch 631/1000\n",
            "38/38 [==============================] - 1s 29ms/step - loss: 0.2053 - accuracy: 0.9508 - val_loss: 0.2269 - val_accuracy: 0.9800\n",
            "Epoch 632/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1856 - accuracy: 0.9492 - val_loss: 0.1970 - val_accuracy: 0.9767\n",
            "Epoch 633/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1593 - accuracy: 0.9496 - val_loss: 0.1999 - val_accuracy: 0.9767\n",
            "Epoch 634/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1518 - accuracy: 0.9604 - val_loss: 0.1732 - val_accuracy: 0.9800\n",
            "Epoch 635/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.1500 - accuracy: 0.9600 - val_loss: 0.1883 - val_accuracy: 0.9800\n",
            "Epoch 636/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1678 - accuracy: 0.9533 - val_loss: 0.1829 - val_accuracy: 0.9800\n",
            "Epoch 637/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1750 - accuracy: 0.9492 - val_loss: 0.1862 - val_accuracy: 0.9800\n",
            "Epoch 638/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1771 - accuracy: 0.9550 - val_loss: 0.1965 - val_accuracy: 0.9800\n",
            "Epoch 639/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1499 - accuracy: 0.9558 - val_loss: 0.2262 - val_accuracy: 0.9800\n",
            "Epoch 640/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1849 - accuracy: 0.9525 - val_loss: 0.2007 - val_accuracy: 0.9800\n",
            "Epoch 641/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1566 - accuracy: 0.9567 - val_loss: 0.2417 - val_accuracy: 0.9800\n",
            "Epoch 642/1000\n",
            "38/38 [==============================] - 1s 33ms/step - loss: 0.1792 - accuracy: 0.9542 - val_loss: 0.2326 - val_accuracy: 0.9800\n",
            "Epoch 643/1000\n",
            "38/38 [==============================] - 1s 34ms/step - loss: 0.1495 - accuracy: 0.9575 - val_loss: 0.2615 - val_accuracy: 0.9800\n",
            "Epoch 644/1000\n",
            "38/38 [==============================] - 1s 34ms/step - loss: 0.1874 - accuracy: 0.9538 - val_loss: 0.2593 - val_accuracy: 0.9800\n",
            "Epoch 645/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1714 - accuracy: 0.9554 - val_loss: 0.2686 - val_accuracy: 0.9800\n",
            "Epoch 646/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1355 - accuracy: 0.9625 - val_loss: 0.2669 - val_accuracy: 0.9800\n",
            "Epoch 647/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1572 - accuracy: 0.9554 - val_loss: 0.2648 - val_accuracy: 0.9800\n",
            "Epoch 648/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1709 - accuracy: 0.9617 - val_loss: 0.2326 - val_accuracy: 0.9767\n",
            "Epoch 649/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1592 - accuracy: 0.9613 - val_loss: 0.2313 - val_accuracy: 0.9800\n",
            "Epoch 650/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1663 - accuracy: 0.9567 - val_loss: 0.2371 - val_accuracy: 0.9800\n",
            "Epoch 651/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1575 - accuracy: 0.9563 - val_loss: 0.2515 - val_accuracy: 0.9800\n",
            "Epoch 652/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1826 - accuracy: 0.9538 - val_loss: 0.2436 - val_accuracy: 0.9800\n",
            "Epoch 653/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1884 - accuracy: 0.9542 - val_loss: 0.2343 - val_accuracy: 0.9800\n",
            "Epoch 654/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.1667 - accuracy: 0.9488 - val_loss: 0.2660 - val_accuracy: 0.9800\n",
            "Epoch 655/1000\n",
            "38/38 [==============================] - 1s 28ms/step - loss: 0.1664 - accuracy: 0.9563 - val_loss: 0.2567 - val_accuracy: 0.9800\n",
            "Epoch 656/1000\n",
            "38/38 [==============================] - 1s 33ms/step - loss: 0.1458 - accuracy: 0.9579 - val_loss: 0.2510 - val_accuracy: 0.9767\n",
            "Epoch 657/1000\n",
            "38/38 [==============================] - 1s 37ms/step - loss: 0.1889 - accuracy: 0.9475 - val_loss: 0.2676 - val_accuracy: 0.9767\n",
            "Epoch 658/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1523 - accuracy: 0.9567 - val_loss: 0.3157 - val_accuracy: 0.9733\n",
            "Epoch 659/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.1332 - accuracy: 0.9596 - val_loss: 0.2940 - val_accuracy: 0.9767\n",
            "Epoch 660/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1446 - accuracy: 0.9579 - val_loss: 0.2956 - val_accuracy: 0.9800\n",
            "Epoch 661/1000\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.1567 - accuracy: 0.9558 - val_loss: 0.2871 - val_accuracy: 0.9800\n",
            "Epoch 662/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1608 - accuracy: 0.9521 - val_loss: 0.2606 - val_accuracy: 0.9800\n",
            "Epoch 663/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1773 - accuracy: 0.9550 - val_loss: 0.2012 - val_accuracy: 0.9800\n",
            "Epoch 664/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1728 - accuracy: 0.9483 - val_loss: 0.1903 - val_accuracy: 0.9800\n",
            "Epoch 665/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1508 - accuracy: 0.9629 - val_loss: 0.2085 - val_accuracy: 0.9800\n",
            "Epoch 666/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1589 - accuracy: 0.9546 - val_loss: 0.2606 - val_accuracy: 0.9800\n",
            "Epoch 667/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1423 - accuracy: 0.9600 - val_loss: 0.2397 - val_accuracy: 0.9800\n",
            "Epoch 668/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1528 - accuracy: 0.9617 - val_loss: 0.2139 - val_accuracy: 0.9800\n",
            "Epoch 669/1000\n",
            "38/38 [==============================] - 1s 36ms/step - loss: 0.1450 - accuracy: 0.9538 - val_loss: 0.2085 - val_accuracy: 0.9850\n",
            "Epoch 670/1000\n",
            "38/38 [==============================] - 1s 34ms/step - loss: 0.1745 - accuracy: 0.9546 - val_loss: 0.1866 - val_accuracy: 0.9850\n",
            "Epoch 671/1000\n",
            "38/38 [==============================] - 1s 31ms/step - loss: 0.1669 - accuracy: 0.9608 - val_loss: 0.1688 - val_accuracy: 0.9850\n",
            "Epoch 672/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1635 - accuracy: 0.9571 - val_loss: 0.1773 - val_accuracy: 0.9850\n",
            "Epoch 673/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1514 - accuracy: 0.9621 - val_loss: 0.1977 - val_accuracy: 0.9850\n",
            "Epoch 674/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1731 - accuracy: 0.9504 - val_loss: 0.1939 - val_accuracy: 0.9800\n",
            "Epoch 675/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1690 - accuracy: 0.9592 - val_loss: 0.1888 - val_accuracy: 0.9800\n",
            "Epoch 676/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1559 - accuracy: 0.9583 - val_loss: 0.2036 - val_accuracy: 0.9800\n",
            "Epoch 677/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1772 - accuracy: 0.9533 - val_loss: 0.2106 - val_accuracy: 0.9850\n",
            "Epoch 678/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1579 - accuracy: 0.9550 - val_loss: 0.2249 - val_accuracy: 0.9850\n",
            "Epoch 679/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1455 - accuracy: 0.9613 - val_loss: 0.2055 - val_accuracy: 0.9800\n",
            "Epoch 680/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1228 - accuracy: 0.9625 - val_loss: 0.2206 - val_accuracy: 0.9800\n",
            "Epoch 681/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1503 - accuracy: 0.9558 - val_loss: 0.2400 - val_accuracy: 0.9750\n",
            "Epoch 682/1000\n",
            "38/38 [==============================] - 1s 35ms/step - loss: 0.1422 - accuracy: 0.9629 - val_loss: 0.2180 - val_accuracy: 0.9800\n",
            "Epoch 683/1000\n",
            "38/38 [==============================] - 1s 34ms/step - loss: 0.1681 - accuracy: 0.9571 - val_loss: 0.2111 - val_accuracy: 0.9800\n",
            "Epoch 684/1000\n",
            "38/38 [==============================] - 1s 34ms/step - loss: 0.1451 - accuracy: 0.9579 - val_loss: 0.2497 - val_accuracy: 0.9800\n",
            "Epoch 685/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1453 - accuracy: 0.9629 - val_loss: 0.2304 - val_accuracy: 0.9800\n",
            "Epoch 686/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1477 - accuracy: 0.9604 - val_loss: 0.2043 - val_accuracy: 0.9800\n",
            "Epoch 687/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1254 - accuracy: 0.9638 - val_loss: 0.2058 - val_accuracy: 0.9800\n",
            "Epoch 688/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1311 - accuracy: 0.9617 - val_loss: 0.1973 - val_accuracy: 0.9800\n",
            "Epoch 689/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1548 - accuracy: 0.9558 - val_loss: 0.1713 - val_accuracy: 0.9800\n",
            "Epoch 690/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1623 - accuracy: 0.9567 - val_loss: 0.1742 - val_accuracy: 0.9800\n",
            "Epoch 691/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1456 - accuracy: 0.9583 - val_loss: 0.1639 - val_accuracy: 0.9800\n",
            "Epoch 692/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1380 - accuracy: 0.9621 - val_loss: 0.1900 - val_accuracy: 0.9800\n",
            "Epoch 693/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1428 - accuracy: 0.9642 - val_loss: 0.2133 - val_accuracy: 0.9800\n",
            "Epoch 694/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1477 - accuracy: 0.9563 - val_loss: 0.2116 - val_accuracy: 0.9800\n",
            "Epoch 695/1000\n",
            "38/38 [==============================] - 1s 31ms/step - loss: 0.1286 - accuracy: 0.9638 - val_loss: 0.2182 - val_accuracy: 0.9800\n",
            "Epoch 696/1000\n",
            "38/38 [==============================] - 1s 34ms/step - loss: 0.1516 - accuracy: 0.9600 - val_loss: 0.1732 - val_accuracy: 0.9800\n",
            "Epoch 697/1000\n",
            "38/38 [==============================] - 1s 35ms/step - loss: 0.1383 - accuracy: 0.9629 - val_loss: 0.1485 - val_accuracy: 0.9800\n",
            "Epoch 698/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1405 - accuracy: 0.9596 - val_loss: 0.1533 - val_accuracy: 0.9800\n",
            "Epoch 699/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1244 - accuracy: 0.9629 - val_loss: 0.1668 - val_accuracy: 0.9800\n",
            "Epoch 700/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1712 - accuracy: 0.9533 - val_loss: 0.1686 - val_accuracy: 0.9800\n",
            "Epoch 701/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1537 - accuracy: 0.9567 - val_loss: 0.1478 - val_accuracy: 0.9800\n",
            "Epoch 702/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1268 - accuracy: 0.9663 - val_loss: 0.1704 - val_accuracy: 0.9800\n",
            "Epoch 703/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1623 - accuracy: 0.9575 - val_loss: 0.1593 - val_accuracy: 0.9800\n",
            "Epoch 704/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1674 - accuracy: 0.9558 - val_loss: 0.1930 - val_accuracy: 0.9800\n",
            "Epoch 705/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1648 - accuracy: 0.9558 - val_loss: 0.2069 - val_accuracy: 0.9800\n",
            "Epoch 706/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1584 - accuracy: 0.9575 - val_loss: 0.2051 - val_accuracy: 0.9800\n",
            "Epoch 707/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1627 - accuracy: 0.9633 - val_loss: 0.2388 - val_accuracy: 0.9800\n",
            "Epoch 708/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1682 - accuracy: 0.9596 - val_loss: 0.2369 - val_accuracy: 0.9800\n",
            "Epoch 709/1000\n",
            "38/38 [==============================] - 1s 32ms/step - loss: 0.1532 - accuracy: 0.9604 - val_loss: 0.2112 - val_accuracy: 0.9800\n",
            "Epoch 710/1000\n",
            "38/38 [==============================] - 1s 34ms/step - loss: 0.1459 - accuracy: 0.9558 - val_loss: 0.2356 - val_accuracy: 0.9800\n",
            "Epoch 711/1000\n",
            "38/38 [==============================] - 1s 32ms/step - loss: 0.1545 - accuracy: 0.9571 - val_loss: 0.2369 - val_accuracy: 0.9800\n",
            "Epoch 712/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1714 - accuracy: 0.9533 - val_loss: 0.2384 - val_accuracy: 0.9800\n",
            "Epoch 713/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1327 - accuracy: 0.9650 - val_loss: 0.2181 - val_accuracy: 0.9800\n",
            "Epoch 714/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1233 - accuracy: 0.9663 - val_loss: 0.2285 - val_accuracy: 0.9800\n",
            "Epoch 715/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1283 - accuracy: 0.9625 - val_loss: 0.2453 - val_accuracy: 0.9800\n",
            "Epoch 716/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1769 - accuracy: 0.9546 - val_loss: 0.2058 - val_accuracy: 0.9800\n",
            "Epoch 717/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1669 - accuracy: 0.9554 - val_loss: 0.1976 - val_accuracy: 0.9800\n",
            "Epoch 718/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1341 - accuracy: 0.9617 - val_loss: 0.1999 - val_accuracy: 0.9800\n",
            "Epoch 719/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1442 - accuracy: 0.9596 - val_loss: 0.2215 - val_accuracy: 0.9800\n",
            "Epoch 720/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1568 - accuracy: 0.9604 - val_loss: 0.1868 - val_accuracy: 0.9800\n",
            "Epoch 721/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1554 - accuracy: 0.9575 - val_loss: 0.2210 - val_accuracy: 0.9800\n",
            "Epoch 722/1000\n",
            "38/38 [==============================] - 1s 32ms/step - loss: 0.1563 - accuracy: 0.9579 - val_loss: 0.2308 - val_accuracy: 0.9800\n",
            "Epoch 723/1000\n",
            "38/38 [==============================] - 1s 34ms/step - loss: 0.1942 - accuracy: 0.9479 - val_loss: 0.2076 - val_accuracy: 0.9800\n",
            "Epoch 724/1000\n",
            "38/38 [==============================] - 1s 37ms/step - loss: 0.1568 - accuracy: 0.9608 - val_loss: 0.1362 - val_accuracy: 0.9800\n",
            "Epoch 725/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1679 - accuracy: 0.9558 - val_loss: 0.1423 - val_accuracy: 0.9800\n",
            "Epoch 726/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1516 - accuracy: 0.9633 - val_loss: 0.1594 - val_accuracy: 0.9800\n",
            "Epoch 727/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1581 - accuracy: 0.9575 - val_loss: 0.1721 - val_accuracy: 0.9800\n",
            "Epoch 728/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1708 - accuracy: 0.9558 - val_loss: 0.1961 - val_accuracy: 0.9767\n",
            "Epoch 729/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1318 - accuracy: 0.9629 - val_loss: 0.1753 - val_accuracy: 0.9767\n",
            "Epoch 730/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1424 - accuracy: 0.9542 - val_loss: 0.1733 - val_accuracy: 0.9767\n",
            "Epoch 731/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1560 - accuracy: 0.9563 - val_loss: 0.2001 - val_accuracy: 0.9767\n",
            "Epoch 732/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1452 - accuracy: 0.9550 - val_loss: 0.2559 - val_accuracy: 0.9767\n",
            "Epoch 733/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1590 - accuracy: 0.9575 - val_loss: 0.2507 - val_accuracy: 0.9800\n",
            "Epoch 734/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1514 - accuracy: 0.9588 - val_loss: 0.2355 - val_accuracy: 0.9800\n",
            "Epoch 735/1000\n",
            "38/38 [==============================] - 1s 33ms/step - loss: 0.1581 - accuracy: 0.9592 - val_loss: 0.1952 - val_accuracy: 0.9800\n",
            "Epoch 736/1000\n",
            "38/38 [==============================] - 1s 34ms/step - loss: 0.1400 - accuracy: 0.9583 - val_loss: 0.1736 - val_accuracy: 0.9800\n",
            "Epoch 737/1000\n",
            "38/38 [==============================] - 1s 35ms/step - loss: 0.1456 - accuracy: 0.9633 - val_loss: 0.2145 - val_accuracy: 0.9800\n",
            "Epoch 738/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1502 - accuracy: 0.9563 - val_loss: 0.2010 - val_accuracy: 0.9800\n",
            "Epoch 739/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1232 - accuracy: 0.9658 - val_loss: 0.2060 - val_accuracy: 0.9800\n",
            "Epoch 740/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1595 - accuracy: 0.9563 - val_loss: 0.1511 - val_accuracy: 0.9800\n",
            "Epoch 741/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1249 - accuracy: 0.9629 - val_loss: 0.1456 - val_accuracy: 0.9800\n",
            "Epoch 742/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1419 - accuracy: 0.9613 - val_loss: 0.1345 - val_accuracy: 0.9800\n",
            "Epoch 743/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1667 - accuracy: 0.9538 - val_loss: 0.1362 - val_accuracy: 0.9800\n",
            "Epoch 744/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1443 - accuracy: 0.9625 - val_loss: 0.1346 - val_accuracy: 0.9800\n",
            "Epoch 745/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1393 - accuracy: 0.9621 - val_loss: 0.1365 - val_accuracy: 0.9800\n",
            "Epoch 746/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1203 - accuracy: 0.9658 - val_loss: 0.1731 - val_accuracy: 0.9800\n",
            "Epoch 747/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1460 - accuracy: 0.9592 - val_loss: 0.1886 - val_accuracy: 0.9800\n",
            "Epoch 748/1000\n",
            "38/38 [==============================] - 1s 32ms/step - loss: 0.1504 - accuracy: 0.9575 - val_loss: 0.1971 - val_accuracy: 0.9800\n",
            "Epoch 749/1000\n",
            "38/38 [==============================] - 1s 36ms/step - loss: 0.1405 - accuracy: 0.9638 - val_loss: 0.1673 - val_accuracy: 0.9800\n",
            "Epoch 750/1000\n",
            "38/38 [==============================] - 1s 37ms/step - loss: 0.1160 - accuracy: 0.9708 - val_loss: 0.2006 - val_accuracy: 0.9800\n",
            "Epoch 751/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1407 - accuracy: 0.9633 - val_loss: 0.1988 - val_accuracy: 0.9800\n",
            "Epoch 752/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1384 - accuracy: 0.9617 - val_loss: 0.2288 - val_accuracy: 0.9800\n",
            "Epoch 753/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1602 - accuracy: 0.9608 - val_loss: 0.2057 - val_accuracy: 0.9800\n",
            "Epoch 754/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1365 - accuracy: 0.9625 - val_loss: 0.1713 - val_accuracy: 0.9800\n",
            "Epoch 755/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1525 - accuracy: 0.9633 - val_loss: 0.1910 - val_accuracy: 0.9750\n",
            "Epoch 756/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1672 - accuracy: 0.9525 - val_loss: 0.2029 - val_accuracy: 0.9800\n",
            "Epoch 757/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1483 - accuracy: 0.9617 - val_loss: 0.2090 - val_accuracy: 0.9800\n",
            "Epoch 758/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1514 - accuracy: 0.9608 - val_loss: 0.2080 - val_accuracy: 0.9800\n",
            "Epoch 759/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1417 - accuracy: 0.9633 - val_loss: 0.2071 - val_accuracy: 0.9800\n",
            "Epoch 760/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1402 - accuracy: 0.9592 - val_loss: 0.2259 - val_accuracy: 0.9800\n",
            "Epoch 761/1000\n",
            "38/38 [==============================] - 1s 33ms/step - loss: 0.1532 - accuracy: 0.9600 - val_loss: 0.1982 - val_accuracy: 0.9750\n",
            "Epoch 762/1000\n",
            "38/38 [==============================] - 1s 34ms/step - loss: 0.1534 - accuracy: 0.9633 - val_loss: 0.1717 - val_accuracy: 0.9750\n",
            "Epoch 763/1000\n",
            "38/38 [==============================] - 1s 37ms/step - loss: 0.1565 - accuracy: 0.9583 - val_loss: 0.1986 - val_accuracy: 0.9750\n",
            "Epoch 764/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1578 - accuracy: 0.9629 - val_loss: 0.2134 - val_accuracy: 0.9750\n",
            "Epoch 765/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1416 - accuracy: 0.9604 - val_loss: 0.2042 - val_accuracy: 0.9750\n",
            "Epoch 766/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1149 - accuracy: 0.9650 - val_loss: 0.1958 - val_accuracy: 0.9750\n",
            "Epoch 767/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1281 - accuracy: 0.9642 - val_loss: 0.1753 - val_accuracy: 0.9750\n",
            "Epoch 768/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1456 - accuracy: 0.9633 - val_loss: 0.1853 - val_accuracy: 0.9750\n",
            "Epoch 769/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1550 - accuracy: 0.9613 - val_loss: 0.1390 - val_accuracy: 0.9750\n",
            "Epoch 770/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1260 - accuracy: 0.9638 - val_loss: 0.1509 - val_accuracy: 0.9750\n",
            "Epoch 771/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1308 - accuracy: 0.9654 - val_loss: 0.1637 - val_accuracy: 0.9750\n",
            "Epoch 772/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1554 - accuracy: 0.9650 - val_loss: 0.1579 - val_accuracy: 0.9750\n",
            "Epoch 773/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1188 - accuracy: 0.9717 - val_loss: 0.1620 - val_accuracy: 0.9800\n",
            "Epoch 774/1000\n",
            "38/38 [==============================] - 1s 30ms/step - loss: 0.1445 - accuracy: 0.9642 - val_loss: 0.1251 - val_accuracy: 0.9800\n",
            "Epoch 775/1000\n",
            "38/38 [==============================] - 1s 37ms/step - loss: 0.1550 - accuracy: 0.9604 - val_loss: 0.1593 - val_accuracy: 0.9750\n",
            "Epoch 776/1000\n",
            "38/38 [==============================] - 1s 36ms/step - loss: 0.1501 - accuracy: 0.9596 - val_loss: 0.1697 - val_accuracy: 0.9800\n",
            "Epoch 777/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1305 - accuracy: 0.9629 - val_loss: 0.1890 - val_accuracy: 0.9750\n",
            "Epoch 778/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1526 - accuracy: 0.9567 - val_loss: 0.2076 - val_accuracy: 0.9800\n",
            "Epoch 779/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1352 - accuracy: 0.9642 - val_loss: 0.2045 - val_accuracy: 0.9800\n",
            "Epoch 780/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1326 - accuracy: 0.9633 - val_loss: 0.2248 - val_accuracy: 0.9800\n",
            "Epoch 781/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1316 - accuracy: 0.9633 - val_loss: 0.1643 - val_accuracy: 0.9800\n",
            "Epoch 782/1000\n",
            "38/38 [==============================] - 1s 27ms/step - loss: 0.1510 - accuracy: 0.9579 - val_loss: 0.1523 - val_accuracy: 0.9800\n",
            "Epoch 783/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1423 - accuracy: 0.9629 - val_loss: 0.1562 - val_accuracy: 0.9800\n",
            "Epoch 784/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1325 - accuracy: 0.9608 - val_loss: 0.1619 - val_accuracy: 0.9800\n",
            "Epoch 785/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1262 - accuracy: 0.9617 - val_loss: 0.1794 - val_accuracy: 0.9800\n",
            "Epoch 786/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1139 - accuracy: 0.9708 - val_loss: 0.2277 - val_accuracy: 0.9800\n",
            "Epoch 787/1000\n",
            "38/38 [==============================] - 1s 33ms/step - loss: 0.1220 - accuracy: 0.9650 - val_loss: 0.1872 - val_accuracy: 0.9750\n",
            "Epoch 788/1000\n",
            "38/38 [==============================] - 1s 37ms/step - loss: 0.1387 - accuracy: 0.9633 - val_loss: 0.1506 - val_accuracy: 0.9800\n",
            "Epoch 789/1000\n",
            "38/38 [==============================] - 1s 35ms/step - loss: 0.1337 - accuracy: 0.9671 - val_loss: 0.1409 - val_accuracy: 0.9800\n",
            "Epoch 790/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1354 - accuracy: 0.9679 - val_loss: 0.1377 - val_accuracy: 0.9750\n",
            "Epoch 791/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1645 - accuracy: 0.9596 - val_loss: 0.1182 - val_accuracy: 0.9800\n",
            "Epoch 792/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1567 - accuracy: 0.9604 - val_loss: 0.1183 - val_accuracy: 0.9850\n",
            "Epoch 793/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1448 - accuracy: 0.9588 - val_loss: 0.1326 - val_accuracy: 0.9850\n",
            "Epoch 794/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1247 - accuracy: 0.9621 - val_loss: 0.1491 - val_accuracy: 0.9800\n",
            "Epoch 795/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1308 - accuracy: 0.9650 - val_loss: 0.1777 - val_accuracy: 0.9800\n",
            "Epoch 796/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1355 - accuracy: 0.9625 - val_loss: 0.1919 - val_accuracy: 0.9800\n",
            "Epoch 797/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1427 - accuracy: 0.9617 - val_loss: 0.1957 - val_accuracy: 0.9800\n",
            "Epoch 798/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1470 - accuracy: 0.9604 - val_loss: 0.1565 - val_accuracy: 0.9800\n",
            "Epoch 799/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1342 - accuracy: 0.9638 - val_loss: 0.1709 - val_accuracy: 0.9800\n",
            "Epoch 800/1000\n",
            "38/38 [==============================] - 1s 33ms/step - loss: 0.1645 - accuracy: 0.9592 - val_loss: 0.1550 - val_accuracy: 0.9800\n",
            "Epoch 801/1000\n",
            "38/38 [==============================] - 1s 34ms/step - loss: 0.1817 - accuracy: 0.9525 - val_loss: 0.1813 - val_accuracy: 0.9800\n",
            "Epoch 802/1000\n",
            "38/38 [==============================] - 1s 37ms/step - loss: 0.1424 - accuracy: 0.9646 - val_loss: 0.1287 - val_accuracy: 0.9800\n",
            "Epoch 803/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1365 - accuracy: 0.9650 - val_loss: 0.1461 - val_accuracy: 0.9800\n",
            "Epoch 804/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1221 - accuracy: 0.9663 - val_loss: 0.1420 - val_accuracy: 0.9850\n",
            "Epoch 805/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1352 - accuracy: 0.9654 - val_loss: 0.1493 - val_accuracy: 0.9800\n",
            "Epoch 806/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1452 - accuracy: 0.9658 - val_loss: 0.1440 - val_accuracy: 0.9817\n",
            "Epoch 807/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1350 - accuracy: 0.9642 - val_loss: 0.1442 - val_accuracy: 0.9800\n",
            "Epoch 808/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1361 - accuracy: 0.9608 - val_loss: 0.1303 - val_accuracy: 0.9850\n",
            "Epoch 809/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1636 - accuracy: 0.9604 - val_loss: 0.1568 - val_accuracy: 0.9850\n",
            "Epoch 810/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1525 - accuracy: 0.9550 - val_loss: 0.1675 - val_accuracy: 0.9800\n",
            "Epoch 811/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1241 - accuracy: 0.9658 - val_loss: 0.1996 - val_accuracy: 0.9800\n",
            "Epoch 812/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1421 - accuracy: 0.9604 - val_loss: 0.1258 - val_accuracy: 0.9800\n",
            "Epoch 813/1000\n",
            "38/38 [==============================] - 1s 35ms/step - loss: 0.1453 - accuracy: 0.9575 - val_loss: 0.1122 - val_accuracy: 0.9767\n",
            "Epoch 814/1000\n",
            "38/38 [==============================] - 1s 37ms/step - loss: 0.1158 - accuracy: 0.9712 - val_loss: 0.1251 - val_accuracy: 0.9767\n",
            "Epoch 815/1000\n",
            "38/38 [==============================] - 1s 35ms/step - loss: 0.1344 - accuracy: 0.9617 - val_loss: 0.1383 - val_accuracy: 0.9800\n",
            "Epoch 816/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1380 - accuracy: 0.9621 - val_loss: 0.1585 - val_accuracy: 0.9800\n",
            "Epoch 817/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1082 - accuracy: 0.9700 - val_loss: 0.1688 - val_accuracy: 0.9800\n",
            "Epoch 818/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1452 - accuracy: 0.9592 - val_loss: 0.1770 - val_accuracy: 0.9800\n",
            "Epoch 819/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1042 - accuracy: 0.9683 - val_loss: 0.1767 - val_accuracy: 0.9800\n",
            "Epoch 820/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1308 - accuracy: 0.9667 - val_loss: 0.1684 - val_accuracy: 0.9800\n",
            "Epoch 821/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1224 - accuracy: 0.9683 - val_loss: 0.1603 - val_accuracy: 0.9800\n",
            "Epoch 822/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1368 - accuracy: 0.9654 - val_loss: 0.1689 - val_accuracy: 0.9800\n",
            "Epoch 823/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1328 - accuracy: 0.9646 - val_loss: 0.1325 - val_accuracy: 0.9800\n",
            "Epoch 824/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1453 - accuracy: 0.9600 - val_loss: 0.0850 - val_accuracy: 0.9800\n",
            "Epoch 825/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1301 - accuracy: 0.9663 - val_loss: 0.1181 - val_accuracy: 0.9800\n",
            "Epoch 826/1000\n",
            "38/38 [==============================] - 1s 36ms/step - loss: 0.1298 - accuracy: 0.9646 - val_loss: 0.1424 - val_accuracy: 0.9800\n",
            "Epoch 827/1000\n",
            "38/38 [==============================] - 1s 36ms/step - loss: 0.1477 - accuracy: 0.9629 - val_loss: 0.1731 - val_accuracy: 0.9800\n",
            "Epoch 828/1000\n",
            "38/38 [==============================] - 1s 34ms/step - loss: 0.1342 - accuracy: 0.9692 - val_loss: 0.1782 - val_accuracy: 0.9800\n",
            "Epoch 829/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1566 - accuracy: 0.9646 - val_loss: 0.1870 - val_accuracy: 0.9800\n",
            "Epoch 830/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1273 - accuracy: 0.9692 - val_loss: 0.2174 - val_accuracy: 0.9800\n",
            "Epoch 831/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1577 - accuracy: 0.9533 - val_loss: 0.2101 - val_accuracy: 0.9800\n",
            "Epoch 832/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1229 - accuracy: 0.9683 - val_loss: 0.2094 - val_accuracy: 0.9800\n",
            "Epoch 833/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1238 - accuracy: 0.9663 - val_loss: 0.2392 - val_accuracy: 0.9800\n",
            "Epoch 834/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1524 - accuracy: 0.9579 - val_loss: 0.2437 - val_accuracy: 0.9800\n",
            "Epoch 835/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1306 - accuracy: 0.9658 - val_loss: 0.2108 - val_accuracy: 0.9800\n",
            "Epoch 836/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1251 - accuracy: 0.9708 - val_loss: 0.1988 - val_accuracy: 0.9800\n",
            "Epoch 837/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1276 - accuracy: 0.9688 - val_loss: 0.2032 - val_accuracy: 0.9800\n",
            "Epoch 838/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1102 - accuracy: 0.9700 - val_loss: 0.2045 - val_accuracy: 0.9800\n",
            "Epoch 839/1000\n",
            "38/38 [==============================] - 1s 37ms/step - loss: 0.1241 - accuracy: 0.9683 - val_loss: 0.1950 - val_accuracy: 0.9850\n",
            "Epoch 840/1000\n",
            "38/38 [==============================] - 1s 35ms/step - loss: 0.1034 - accuracy: 0.9750 - val_loss: 0.1770 - val_accuracy: 0.9850\n",
            "Epoch 841/1000\n",
            "38/38 [==============================] - 1s 34ms/step - loss: 0.1160 - accuracy: 0.9654 - val_loss: 0.1334 - val_accuracy: 0.9850\n",
            "Epoch 842/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1479 - accuracy: 0.9633 - val_loss: 0.1469 - val_accuracy: 0.9850\n",
            "Epoch 843/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1291 - accuracy: 0.9679 - val_loss: 0.1365 - val_accuracy: 0.9800\n",
            "Epoch 844/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1268 - accuracy: 0.9663 - val_loss: 0.1322 - val_accuracy: 0.9850\n",
            "Epoch 845/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1268 - accuracy: 0.9650 - val_loss: 0.1367 - val_accuracy: 0.9817\n",
            "Epoch 846/1000\n",
            "38/38 [==============================] - 1s 27ms/step - loss: 0.1352 - accuracy: 0.9658 - val_loss: 0.1210 - val_accuracy: 0.9850\n",
            "Epoch 847/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1291 - accuracy: 0.9667 - val_loss: 0.1481 - val_accuracy: 0.9800\n",
            "Epoch 848/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1055 - accuracy: 0.9692 - val_loss: 0.1529 - val_accuracy: 0.9850\n",
            "Epoch 849/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1301 - accuracy: 0.9692 - val_loss: 0.1390 - val_accuracy: 0.9850\n",
            "Epoch 850/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1537 - accuracy: 0.9583 - val_loss: 0.1238 - val_accuracy: 0.9800\n",
            "Epoch 851/1000\n",
            "38/38 [==============================] - 1s 29ms/step - loss: 0.1260 - accuracy: 0.9663 - val_loss: 0.1086 - val_accuracy: 0.9800\n",
            "Epoch 852/1000\n",
            "38/38 [==============================] - 1s 35ms/step - loss: 0.1124 - accuracy: 0.9696 - val_loss: 0.1178 - val_accuracy: 0.9800\n",
            "Epoch 853/1000\n",
            "38/38 [==============================] - 1s 34ms/step - loss: 0.1064 - accuracy: 0.9712 - val_loss: 0.1483 - val_accuracy: 0.9800\n",
            "Epoch 854/1000\n",
            "38/38 [==============================] - 1s 31ms/step - loss: 0.1189 - accuracy: 0.9742 - val_loss: 0.1576 - val_accuracy: 0.9800\n",
            "Epoch 855/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1278 - accuracy: 0.9658 - val_loss: 0.1623 - val_accuracy: 0.9767\n",
            "Epoch 856/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1282 - accuracy: 0.9654 - val_loss: 0.1427 - val_accuracy: 0.9850\n",
            "Epoch 857/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1268 - accuracy: 0.9679 - val_loss: 0.1817 - val_accuracy: 0.9850\n",
            "Epoch 858/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1150 - accuracy: 0.9708 - val_loss: 0.1665 - val_accuracy: 0.9800\n",
            "Epoch 859/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1272 - accuracy: 0.9658 - val_loss: 0.1376 - val_accuracy: 0.9750\n",
            "Epoch 860/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1380 - accuracy: 0.9646 - val_loss: 0.1614 - val_accuracy: 0.9800\n",
            "Epoch 861/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1298 - accuracy: 0.9621 - val_loss: 0.2003 - val_accuracy: 0.9800\n",
            "Epoch 862/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1590 - accuracy: 0.9546 - val_loss: 0.1531 - val_accuracy: 0.9800\n",
            "Epoch 863/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1299 - accuracy: 0.9663 - val_loss: 0.1570 - val_accuracy: 0.9800\n",
            "Epoch 864/1000\n",
            "38/38 [==============================] - 1s 29ms/step - loss: 0.1345 - accuracy: 0.9663 - val_loss: 0.1769 - val_accuracy: 0.9800\n",
            "Epoch 865/1000\n",
            "38/38 [==============================] - 1s 36ms/step - loss: 0.1148 - accuracy: 0.9675 - val_loss: 0.1717 - val_accuracy: 0.9800\n",
            "Epoch 866/1000\n",
            "38/38 [==============================] - 1s 39ms/step - loss: 0.1114 - accuracy: 0.9712 - val_loss: 0.2056 - val_accuracy: 0.9800\n",
            "Epoch 867/1000\n",
            "38/38 [==============================] - 1s 28ms/step - loss: 0.1637 - accuracy: 0.9567 - val_loss: 0.1684 - val_accuracy: 0.9800\n",
            "Epoch 868/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1461 - accuracy: 0.9646 - val_loss: 0.1327 - val_accuracy: 0.9800\n",
            "Epoch 869/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1237 - accuracy: 0.9675 - val_loss: 0.1200 - val_accuracy: 0.9800\n",
            "Epoch 870/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1418 - accuracy: 0.9596 - val_loss: 0.1262 - val_accuracy: 0.9800\n",
            "Epoch 871/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1161 - accuracy: 0.9675 - val_loss: 0.1592 - val_accuracy: 0.9800\n",
            "Epoch 872/1000\n",
            "38/38 [==============================] - 1s 27ms/step - loss: 0.1220 - accuracy: 0.9683 - val_loss: 0.1529 - val_accuracy: 0.9800\n",
            "Epoch 873/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1446 - accuracy: 0.9646 - val_loss: 0.1660 - val_accuracy: 0.9800\n",
            "Epoch 874/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1168 - accuracy: 0.9700 - val_loss: 0.1424 - val_accuracy: 0.9800\n",
            "Epoch 875/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1540 - accuracy: 0.9550 - val_loss: 0.1247 - val_accuracy: 0.9850\n",
            "Epoch 876/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1252 - accuracy: 0.9688 - val_loss: 0.1216 - val_accuracy: 0.9800\n",
            "Epoch 877/1000\n",
            "38/38 [==============================] - 1s 33ms/step - loss: 0.1013 - accuracy: 0.9692 - val_loss: 0.1057 - val_accuracy: 0.9850\n",
            "Epoch 878/1000\n",
            "38/38 [==============================] - 1s 38ms/step - loss: 0.1323 - accuracy: 0.9683 - val_loss: 0.1214 - val_accuracy: 0.9850\n",
            "Epoch 879/1000\n",
            "38/38 [==============================] - 1s 36ms/step - loss: 0.1377 - accuracy: 0.9692 - val_loss: 0.1350 - val_accuracy: 0.9850\n",
            "Epoch 880/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1270 - accuracy: 0.9688 - val_loss: 0.1441 - val_accuracy: 0.9850\n",
            "Epoch 881/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1030 - accuracy: 0.9704 - val_loss: 0.1705 - val_accuracy: 0.9800\n",
            "Epoch 882/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1244 - accuracy: 0.9679 - val_loss: 0.1519 - val_accuracy: 0.9850\n",
            "Epoch 883/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1301 - accuracy: 0.9671 - val_loss: 0.1589 - val_accuracy: 0.9800\n",
            "Epoch 884/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1344 - accuracy: 0.9608 - val_loss: 0.1671 - val_accuracy: 0.9800\n",
            "Epoch 885/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1426 - accuracy: 0.9633 - val_loss: 0.1541 - val_accuracy: 0.9800\n",
            "Epoch 886/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1514 - accuracy: 0.9608 - val_loss: 0.1458 - val_accuracy: 0.9800\n",
            "Epoch 887/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1080 - accuracy: 0.9704 - val_loss: 0.1463 - val_accuracy: 0.9800\n",
            "Epoch 888/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1291 - accuracy: 0.9663 - val_loss: 0.1572 - val_accuracy: 0.9800\n",
            "Epoch 889/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1231 - accuracy: 0.9675 - val_loss: 0.1832 - val_accuracy: 0.9800\n",
            "Epoch 890/1000\n",
            "38/38 [==============================] - 1s 35ms/step - loss: 0.1281 - accuracy: 0.9654 - val_loss: 0.1515 - val_accuracy: 0.9850\n",
            "Epoch 891/1000\n",
            "38/38 [==============================] - 1s 36ms/step - loss: 0.0987 - accuracy: 0.9717 - val_loss: 0.1868 - val_accuracy: 0.9800\n",
            "Epoch 892/1000\n",
            "38/38 [==============================] - 1s 38ms/step - loss: 0.1350 - accuracy: 0.9654 - val_loss: 0.2175 - val_accuracy: 0.9800\n",
            "Epoch 893/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1285 - accuracy: 0.9658 - val_loss: 0.1766 - val_accuracy: 0.9800\n",
            "Epoch 894/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1150 - accuracy: 0.9658 - val_loss: 0.1581 - val_accuracy: 0.9850\n",
            "Epoch 895/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1405 - accuracy: 0.9613 - val_loss: 0.1501 - val_accuracy: 0.9850\n",
            "Epoch 896/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1145 - accuracy: 0.9721 - val_loss: 0.1115 - val_accuracy: 0.9850\n",
            "Epoch 897/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1417 - accuracy: 0.9625 - val_loss: 0.1219 - val_accuracy: 0.9850\n",
            "Epoch 898/1000\n",
            "38/38 [==============================] - 1s 27ms/step - loss: 0.1261 - accuracy: 0.9654 - val_loss: 0.1203 - val_accuracy: 0.9850\n",
            "Epoch 899/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1185 - accuracy: 0.9679 - val_loss: 0.1179 - val_accuracy: 0.9850\n",
            "Epoch 900/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1405 - accuracy: 0.9633 - val_loss: 0.1233 - val_accuracy: 0.9850\n",
            "Epoch 901/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1266 - accuracy: 0.9683 - val_loss: 0.1304 - val_accuracy: 0.9817\n",
            "Epoch 902/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1035 - accuracy: 0.9717 - val_loss: 0.1222 - val_accuracy: 0.9850\n",
            "Epoch 903/1000\n",
            "38/38 [==============================] - 1s 35ms/step - loss: 0.1218 - accuracy: 0.9671 - val_loss: 0.1289 - val_accuracy: 0.9800\n",
            "Epoch 904/1000\n",
            "38/38 [==============================] - 1s 36ms/step - loss: 0.1174 - accuracy: 0.9688 - val_loss: 0.1383 - val_accuracy: 0.9800\n",
            "Epoch 905/1000\n",
            "38/38 [==============================] - 1s 36ms/step - loss: 0.1195 - accuracy: 0.9658 - val_loss: 0.1267 - val_accuracy: 0.9800\n",
            "Epoch 906/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1055 - accuracy: 0.9688 - val_loss: 0.1192 - val_accuracy: 0.9850\n",
            "Epoch 907/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1262 - accuracy: 0.9683 - val_loss: 0.1167 - val_accuracy: 0.9850\n",
            "Epoch 908/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1290 - accuracy: 0.9667 - val_loss: 0.1197 - val_accuracy: 0.9850\n",
            "Epoch 909/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1133 - accuracy: 0.9737 - val_loss: 0.1063 - val_accuracy: 0.9850\n",
            "Epoch 910/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1257 - accuracy: 0.9704 - val_loss: 0.1151 - val_accuracy: 0.9850\n",
            "Epoch 911/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1254 - accuracy: 0.9629 - val_loss: 0.1203 - val_accuracy: 0.9850\n",
            "Epoch 912/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1118 - accuracy: 0.9708 - val_loss: 0.1253 - val_accuracy: 0.9850\n",
            "Epoch 913/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1542 - accuracy: 0.9629 - val_loss: 0.1351 - val_accuracy: 0.9850\n",
            "Epoch 914/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1280 - accuracy: 0.9667 - val_loss: 0.1562 - val_accuracy: 0.9850\n",
            "Epoch 915/1000\n",
            "38/38 [==============================] - 1s 27ms/step - loss: 0.1133 - accuracy: 0.9642 - val_loss: 0.1311 - val_accuracy: 0.9850\n",
            "Epoch 916/1000\n",
            "38/38 [==============================] - 1s 36ms/step - loss: 0.1497 - accuracy: 0.9663 - val_loss: 0.1500 - val_accuracy: 0.9800\n",
            "Epoch 917/1000\n",
            "38/38 [==============================] - 1s 38ms/step - loss: 0.1080 - accuracy: 0.9667 - val_loss: 0.1773 - val_accuracy: 0.9800\n",
            "Epoch 918/1000\n",
            "38/38 [==============================] - 1s 34ms/step - loss: 0.1110 - accuracy: 0.9733 - val_loss: 0.1940 - val_accuracy: 0.9800\n",
            "Epoch 919/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1200 - accuracy: 0.9679 - val_loss: 0.1634 - val_accuracy: 0.9800\n",
            "Epoch 920/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1081 - accuracy: 0.9708 - val_loss: 0.1672 - val_accuracy: 0.9750\n",
            "Epoch 921/1000\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1223 - accuracy: 0.9642 - val_loss: 0.1681 - val_accuracy: 0.9800\n",
            "Epoch 922/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1343 - accuracy: 0.9617 - val_loss: 0.1918 - val_accuracy: 0.9800\n",
            "Epoch 923/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1013 - accuracy: 0.9692 - val_loss: 0.1720 - val_accuracy: 0.9800\n",
            "Epoch 924/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1292 - accuracy: 0.9650 - val_loss: 0.1652 - val_accuracy: 0.9800\n",
            "Epoch 925/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1149 - accuracy: 0.9613 - val_loss: 0.1736 - val_accuracy: 0.9800\n",
            "Epoch 926/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1111 - accuracy: 0.9708 - val_loss: 0.1880 - val_accuracy: 0.9800\n",
            "Epoch 927/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1077 - accuracy: 0.9721 - val_loss: 0.2132 - val_accuracy: 0.9800\n",
            "Epoch 928/1000\n",
            "38/38 [==============================] - 1s 27ms/step - loss: 0.0990 - accuracy: 0.9750 - val_loss: 0.2150 - val_accuracy: 0.9800\n",
            "Epoch 929/1000\n",
            "38/38 [==============================] - 1s 37ms/step - loss: 0.1286 - accuracy: 0.9683 - val_loss: 0.2071 - val_accuracy: 0.9800\n",
            "Epoch 930/1000\n",
            "38/38 [==============================] - 1s 35ms/step - loss: 0.0987 - accuracy: 0.9675 - val_loss: 0.2235 - val_accuracy: 0.9800\n",
            "Epoch 931/1000\n",
            "38/38 [==============================] - 1s 36ms/step - loss: 0.1108 - accuracy: 0.9721 - val_loss: 0.2263 - val_accuracy: 0.9800\n",
            "Epoch 932/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.0980 - accuracy: 0.9737 - val_loss: 0.2214 - val_accuracy: 0.9850\n",
            "Epoch 933/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1150 - accuracy: 0.9692 - val_loss: 0.2219 - val_accuracy: 0.9850\n",
            "Epoch 934/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1067 - accuracy: 0.9729 - val_loss: 0.1805 - val_accuracy: 0.9850\n",
            "Epoch 935/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1365 - accuracy: 0.9658 - val_loss: 0.1490 - val_accuracy: 0.9850\n",
            "Epoch 936/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1040 - accuracy: 0.9737 - val_loss: 0.1764 - val_accuracy: 0.9850\n",
            "Epoch 937/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1304 - accuracy: 0.9683 - val_loss: 0.1441 - val_accuracy: 0.9800\n",
            "Epoch 938/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1130 - accuracy: 0.9700 - val_loss: 0.1385 - val_accuracy: 0.9850\n",
            "Epoch 939/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1074 - accuracy: 0.9725 - val_loss: 0.1480 - val_accuracy: 0.9850\n",
            "Epoch 940/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1090 - accuracy: 0.9704 - val_loss: 0.1583 - val_accuracy: 0.9850\n",
            "Epoch 941/1000\n",
            "38/38 [==============================] - 1s 28ms/step - loss: 0.1045 - accuracy: 0.9721 - val_loss: 0.1581 - val_accuracy: 0.9850\n",
            "Epoch 942/1000\n",
            "38/38 [==============================] - 1s 37ms/step - loss: 0.1128 - accuracy: 0.9688 - val_loss: 0.1776 - val_accuracy: 0.9800\n",
            "Epoch 943/1000\n",
            "38/38 [==============================] - 1s 35ms/step - loss: 0.1480 - accuracy: 0.9638 - val_loss: 0.1601 - val_accuracy: 0.9800\n",
            "Epoch 944/1000\n",
            "38/38 [==============================] - 1s 34ms/step - loss: 0.1117 - accuracy: 0.9737 - val_loss: 0.1379 - val_accuracy: 0.9800\n",
            "Epoch 945/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1284 - accuracy: 0.9650 - val_loss: 0.1445 - val_accuracy: 0.9850\n",
            "Epoch 946/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1216 - accuracy: 0.9683 - val_loss: 0.1416 - val_accuracy: 0.9850\n",
            "Epoch 947/1000\n",
            "38/38 [==============================] - 1s 27ms/step - loss: 0.1229 - accuracy: 0.9638 - val_loss: 0.1487 - val_accuracy: 0.9850\n",
            "Epoch 948/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1226 - accuracy: 0.9667 - val_loss: 0.1402 - val_accuracy: 0.9850\n",
            "Epoch 949/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1033 - accuracy: 0.9708 - val_loss: 0.1280 - val_accuracy: 0.9850\n",
            "Epoch 950/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1400 - accuracy: 0.9667 - val_loss: 0.1143 - val_accuracy: 0.9850\n",
            "Epoch 951/1000\n",
            "38/38 [==============================] - 1s 27ms/step - loss: 0.1200 - accuracy: 0.9704 - val_loss: 0.1034 - val_accuracy: 0.9850\n",
            "Epoch 952/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1066 - accuracy: 0.9708 - val_loss: 0.1087 - val_accuracy: 0.9783\n",
            "Epoch 953/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1218 - accuracy: 0.9667 - val_loss: 0.1062 - val_accuracy: 0.9800\n",
            "Epoch 954/1000\n",
            "38/38 [==============================] - 1s 32ms/step - loss: 0.1150 - accuracy: 0.9679 - val_loss: 0.1141 - val_accuracy: 0.9850\n",
            "Epoch 955/1000\n",
            "38/38 [==============================] - 1s 34ms/step - loss: 0.1092 - accuracy: 0.9708 - val_loss: 0.1166 - val_accuracy: 0.9850\n",
            "Epoch 956/1000\n",
            "38/38 [==============================] - 1s 37ms/step - loss: 0.0854 - accuracy: 0.9775 - val_loss: 0.1177 - val_accuracy: 0.9850\n",
            "Epoch 957/1000\n",
            "38/38 [==============================] - 1s 30ms/step - loss: 0.1407 - accuracy: 0.9629 - val_loss: 0.1614 - val_accuracy: 0.9800\n",
            "Epoch 958/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1394 - accuracy: 0.9675 - val_loss: 0.1669 - val_accuracy: 0.9800\n",
            "Epoch 959/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1329 - accuracy: 0.9654 - val_loss: 0.1485 - val_accuracy: 0.9800\n",
            "Epoch 960/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1090 - accuracy: 0.9708 - val_loss: 0.1729 - val_accuracy: 0.9800\n",
            "Epoch 961/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.0968 - accuracy: 0.9754 - val_loss: 0.1741 - val_accuracy: 0.9800\n",
            "Epoch 962/1000\n",
            "38/38 [==============================] - 1s 27ms/step - loss: 0.1249 - accuracy: 0.9696 - val_loss: 0.1762 - val_accuracy: 0.9800\n",
            "Epoch 963/1000\n",
            "38/38 [==============================] - 1s 27ms/step - loss: 0.1281 - accuracy: 0.9638 - val_loss: 0.1807 - val_accuracy: 0.9800\n",
            "Epoch 964/1000\n",
            "38/38 [==============================] - 1s 27ms/step - loss: 0.0907 - accuracy: 0.9721 - val_loss: 0.2011 - val_accuracy: 0.9800\n",
            "Epoch 965/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1253 - accuracy: 0.9688 - val_loss: 0.1865 - val_accuracy: 0.9800\n",
            "Epoch 966/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.0921 - accuracy: 0.9717 - val_loss: 0.1694 - val_accuracy: 0.9800\n",
            "Epoch 967/1000\n",
            "38/38 [==============================] - 1s 33ms/step - loss: 0.0897 - accuracy: 0.9758 - val_loss: 0.1850 - val_accuracy: 0.9800\n",
            "Epoch 968/1000\n",
            "38/38 [==============================] - 1s 34ms/step - loss: 0.1284 - accuracy: 0.9671 - val_loss: 0.1869 - val_accuracy: 0.9850\n",
            "Epoch 969/1000\n",
            "38/38 [==============================] - 1s 35ms/step - loss: 0.0992 - accuracy: 0.9750 - val_loss: 0.1871 - val_accuracy: 0.9850\n",
            "Epoch 970/1000\n",
            "38/38 [==============================] - 1s 31ms/step - loss: 0.0987 - accuracy: 0.9754 - val_loss: 0.1668 - val_accuracy: 0.9850\n",
            "Epoch 971/1000\n",
            "38/38 [==============================] - 1s 27ms/step - loss: 0.1125 - accuracy: 0.9700 - val_loss: 0.1762 - val_accuracy: 0.9850\n",
            "Epoch 972/1000\n",
            "38/38 [==============================] - 1s 27ms/step - loss: 0.1132 - accuracy: 0.9654 - val_loss: 0.1873 - val_accuracy: 0.9850\n",
            "Epoch 973/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1222 - accuracy: 0.9675 - val_loss: 0.1882 - val_accuracy: 0.9850\n",
            "Epoch 974/1000\n",
            "38/38 [==============================] - 1s 27ms/step - loss: 0.1238 - accuracy: 0.9675 - val_loss: 0.1674 - val_accuracy: 0.9800\n",
            "Epoch 975/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1261 - accuracy: 0.9708 - val_loss: 0.1577 - val_accuracy: 0.9850\n",
            "Epoch 976/1000\n",
            "38/38 [==============================] - 1s 27ms/step - loss: 0.1182 - accuracy: 0.9633 - val_loss: 0.1532 - val_accuracy: 0.9850\n",
            "Epoch 977/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1360 - accuracy: 0.9696 - val_loss: 0.1503 - val_accuracy: 0.9850\n",
            "Epoch 978/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1493 - accuracy: 0.9621 - val_loss: 0.1214 - val_accuracy: 0.9850\n",
            "Epoch 979/1000\n",
            "38/38 [==============================] - 1s 27ms/step - loss: 0.1411 - accuracy: 0.9621 - val_loss: 0.1289 - val_accuracy: 0.9850\n",
            "Epoch 980/1000\n",
            "38/38 [==============================] - 1s 31ms/step - loss: 0.1131 - accuracy: 0.9688 - val_loss: 0.1230 - val_accuracy: 0.9850\n",
            "Epoch 981/1000\n",
            "38/38 [==============================] - 1s 34ms/step - loss: 0.1135 - accuracy: 0.9688 - val_loss: 0.1378 - val_accuracy: 0.9850\n",
            "Epoch 982/1000\n",
            "38/38 [==============================] - 1s 36ms/step - loss: 0.1206 - accuracy: 0.9671 - val_loss: 0.1371 - val_accuracy: 0.9850\n",
            "Epoch 983/1000\n",
            "38/38 [==============================] - 1s 32ms/step - loss: 0.1523 - accuracy: 0.9608 - val_loss: 0.1279 - val_accuracy: 0.9850\n",
            "Epoch 984/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1281 - accuracy: 0.9679 - val_loss: 0.1234 - val_accuracy: 0.9850\n",
            "Epoch 985/1000\n",
            "38/38 [==============================] - 1s 27ms/step - loss: 0.1423 - accuracy: 0.9688 - val_loss: 0.1302 - val_accuracy: 0.9850\n",
            "Epoch 986/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1265 - accuracy: 0.9663 - val_loss: 0.1239 - val_accuracy: 0.9850\n",
            "Epoch 987/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1224 - accuracy: 0.9696 - val_loss: 0.1536 - val_accuracy: 0.9850\n",
            "Epoch 988/1000\n",
            "38/38 [==============================] - 1s 28ms/step - loss: 0.0943 - accuracy: 0.9750 - val_loss: 0.1618 - val_accuracy: 0.9850\n",
            "Epoch 989/1000\n",
            "38/38 [==============================] - 1s 38ms/step - loss: 0.0925 - accuracy: 0.9779 - val_loss: 0.1511 - val_accuracy: 0.9850\n",
            "Epoch 990/1000\n",
            "38/38 [==============================] - 1s 34ms/step - loss: 0.1331 - accuracy: 0.9667 - val_loss: 0.1937 - val_accuracy: 0.9850\n",
            "Epoch 991/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.0958 - accuracy: 0.9729 - val_loss: 0.1731 - val_accuracy: 0.9850\n",
            "Epoch 992/1000\n",
            "38/38 [==============================] - 1s 33ms/step - loss: 0.1328 - accuracy: 0.9629 - val_loss: 0.1709 - val_accuracy: 0.9850\n",
            "Epoch 993/1000\n",
            "38/38 [==============================] - 1s 36ms/step - loss: 0.1205 - accuracy: 0.9679 - val_loss: 0.1837 - val_accuracy: 0.9850\n",
            "Epoch 994/1000\n",
            "38/38 [==============================] - 1s 34ms/step - loss: 0.1531 - accuracy: 0.9654 - val_loss: 0.1588 - val_accuracy: 0.9850\n",
            "Epoch 995/1000\n",
            "38/38 [==============================] - 1s 31ms/step - loss: 0.1446 - accuracy: 0.9617 - val_loss: 0.1606 - val_accuracy: 0.9850\n",
            "Epoch 996/1000\n",
            "38/38 [==============================] - 1s 27ms/step - loss: 0.1071 - accuracy: 0.9675 - val_loss: 0.1729 - val_accuracy: 0.9800\n",
            "Epoch 997/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1047 - accuracy: 0.9712 - val_loss: 0.1660 - val_accuracy: 0.9750\n",
            "Epoch 998/1000\n",
            "38/38 [==============================] - 1s 27ms/step - loss: 0.1240 - accuracy: 0.9700 - val_loss: 0.1583 - val_accuracy: 0.9750\n",
            "Epoch 999/1000\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.1051 - accuracy: 0.9725 - val_loss: 0.1462 - val_accuracy: 0.9750\n",
            "Epoch 1000/1000\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1201 - accuracy: 0.9696 - val_loss: 0.1377 - val_accuracy: 0.9800\n",
            "19/19 [==============================] - 0s 5ms/step\n",
            "Accuracy: 0.98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training history\n",
        "plt.figure(figsize=(18, 6))\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "UkeL_eGeiciD",
        "outputId": "1654d6b2-839d-4768-8d4a-b5419341a57a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7c581c044a90>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training & validation loss values\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "lAMet3fCk4LZ",
        "outputId": "10bb8b53-afe2-4836-c821-941ac69cc208"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7c581f96c250>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOQAAAHHCAYAAACvGPShAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA/PUlEQVR4nO3dd3xT5f4H8M/J7E5boAsKVMEWEAqiQAERroW2IEsRBFTwIlwERAQHXK4MxwVRxvWyRUD9sWRzkVUqyLBsyt4UWqAto3TPJM/vj7RpT5u0SZrknKTf9+uVV3NGTr4J+XDWc57DMcYYCCGiIBG6AEJIGQokISJCgSRERCiQhIgIBZIQEaFAEiIiFEhCRIQCSYiIUCAJEREKpJPjOA4zZsww+3V37twBx3FYvXq11WsixlEg7WD16tXgOA4cx+HIkSOVpjPGEBwcDI7j8NprrwlQoeUOHjwIjuOwadMmoUtxChRIO3JxccHatWsrjf/zzz9x7949KJVKAaoiYkKBtKOePXti48aNUKvVvPFr165F27ZtERAQIFBlRCwokHY0ePBgPHnyBLGxsfpxRUVF2LRpE4YMGWLwNbm5uZg0aRKCg4OhVCoRGhqK77//HhUv0iksLMTHH3+MevXqwdPTE3369MG9e/cMLvP+/fv4+9//Dn9/fyiVSrRo0QIrV6603gc14Pbt23jzzTfh6+sLNzc3dOjQAb///nul+f773/+iRYsWcHNzg4+PD1588UXeVkV2djYmTJiAxo0bQ6lUws/PD927d8eZM2dsWr+9UCDtqHHjxoiIiMC6dev043bv3o3MzEy89dZbleZnjKFPnz6YP38+oqOjMW/ePISGhuLTTz/FxIkTefO+//77WLBgAXr06IHZs2dDLpejV69elZaZlpaGDh06YP/+/Rg3bhz+85//oEmTJhgxYgQWLFhg9c9c+p4dO3bE3r17MWbMGHzzzTcoKChAnz59sHXrVv18P/74I8aPH4/mzZtjwYIFmDlzJlq3bo3jx4/r5xk9ejSWLFmCN954A4sXL8Ynn3wCV1dXXLlyxSa12x0jNrdq1SoGgJ08eZItXLiQeXp6sry8PMYYY2+++Sbr1q0bY4yxRo0asV69eulft23bNgaAff3117zlDRgwgHEcx27evMkYYywhIYEBYGPGjOHNN2TIEAaATZ8+XT9uxIgRLDAwkD1+/Jg371tvvcVUKpW+rsTERAaArVq1qsrPduDAAQaAbdy40eg8EyZMYADY4cOH9eOys7NZSEgIa9y4MdNoNIwxxvr27ctatGhR5fupVCo2duzYKudxZLSGtLOBAwciPz8fO3fuRHZ2Nnbu3Gl0c3XXrl2QSqUYP348b/ykSZPAGMPu3bv18wGoNN+ECRN4w4wxbN68Gb179wZjDI8fP9Y/oqKikJmZaZNNv127dqFdu3bo3LmzfpyHhwdGjRqFO3fu4PLlywAAb29v3Lt3DydPnjS6LG9vbxw/fhwPHjywep1iQIG0s3r16iEyMhJr167Fli1boNFoMGDAAIPz3r17F0FBQfD09OSNb9asmX566V+JRIJnn32WN19oaChv+NGjR8jIyMDy5ctRr1493uO9994DADx8+NAqn7Pi56hYi6HP8fnnn8PDwwPt2rVD06ZNMXbsWBw9epT3mjlz5uDixYsIDg5Gu3btMGPGDNy+fdvqNQtFJnQBtdGQIUMwcuRIpKamIiYmBt7e3nZ5X61WCwB4++23MWzYMIPztGrVyi61GNKsWTNcu3YNO3fuxJ49e7B582YsXrwY06ZNw8yZMwHotjBefvllbN26Ffv27cN3332Hb7/9Flu2bEFMTIxgtVsLrSEF0L9/f0gkEhw7dszo5ioANGrUCA8ePEB2djZv/NWrV/XTS/9qtVrcunWLN9+1a9d4w6VHYDUaDSIjIw0+/Pz8rPERK32OirUY+hwA4O7ujkGDBmHVqlVISkpCr1699AeBSgUGBmLMmDHYtm0bEhMTUadOHXzzzTdWr1sIFEgBeHh4YMmSJZgxYwZ69+5tdL6ePXtCo9Fg4cKFvPHz588Hx3H6NULp3x9++IE3X8WjplKpFG+88QY2b96MixcvVnq/R48eWfJxqtWzZ0+cOHEC8fHx+nG5ublYvnw5GjdujObNmwMAnjx5wnudQqFA8+bNwRhDcXExNBoNMjMzefP4+fkhKCgIhYWFNqnd3miTVSDGNhnL6927N7p164apU6fizp07CA8Px759+7B9+3ZMmDBBv8/YunVrDB48GIsXL0ZmZiY6duyIuLg43Lx5s9IyZ8+ejQMHDqB9+/YYOXIkmjdvjvT0dJw5cwb79+9Henq6RZ9n8+bN+jVexc85efJkrFu3DjExMRg/fjx8fX3x888/IzExEZs3b4ZEolsv9OjRAwEBAejUqRP8/f1x5coVLFy4EL169YKnpycyMjLQoEEDDBgwAOHh4fDw8MD+/ftx8uRJzJ0716K6RUfYg7y1Q/nTHlWpeNqDMd3pgY8//pgFBQUxuVzOmjZtyr777jum1Wp58+Xn57Px48ezOnXqMHd3d9a7d2+WnJxc6bQHY4ylpaWxsWPHsuDgYCaXy1lAQAB79dVX2fLly/XzmHvaw9ij9FTHrVu32IABA5i3tzdzcXFh7dq1Yzt37uQta9myZaxLly6sTp06TKlUsmeffZZ9+umnLDMzkzHGWGFhIfv0009ZeHg48/T0ZO7u7iw8PJwtXry4yhodCccY9ctKiFjQPiQhIkKBJEREKJCEiAgFkhARoUASIiIUSEJEpNY1DNBqtXjw4AE8PT3BcZzQ5RAHxRhDdnY2goKC9A0brKHWBfLBgwcIDg4WugziJJKTk9GgQQOrLa/WBbL0Uqbk5GR4eXkJXA1xVFlZWQgODq50aVxN1bpAlm6menl5USBJjVl7t4cO6hAiIhRIQkSEAkmIiNS6fUhTaTQaFBcXC12Gw5LL5ZBKpUKX4XAokBUwxpCamoqMjAyhS3F43t7eCAgIoPO9ZqBAVlAaRj8/P7i5udGPyQKMMeTl5el7sAsMDBS4IsdBgSxHo9How1inTh2hy3Forq6uAHTdSvr5+dHmq4nooE45pfuMbm5uAlfiHEq/R9oXNx0F0gDaTLUO+h7NR4EkREQokMSoxo0b2+yOWMQwCqQTKL1durHHjBkzLFruyZMnMWrUKOsWS6pER1nLKbp7EkzrK3QZZktJSdE/37BhA6ZNm8brut/Dw0P/nDEGjUYDmaz6f/p69epZt1BSLVpDljh/9RoU//sAXNY9aNIThS7HLAEBAfqHSqUCx3H64atXr8LT0xO7d+9G27ZtoVQqceTIEdy6dQt9+/aFv78/PDw88NJLL2H//v285VbcZOU4DitWrED//v3h5uaGpk2bYseOHXb+tM6NAlmiiTJD/1yqztc/Z4whr0gtyMOafVhPnjwZs2fPxpUrV9CqVSvk5OSgZ8+eiIuLw9mzZxEdHY3evXsjKSmpyuXMnDkTAwcOxPnz59GzZ08MHTrU4tsPkMpok7WEW0h7HGjzPQJKR2g1gESK/GINmk/bK0hNl7+MgpvCOv9EX375Jbp3764f9vX1RXh4uH74q6++wtatW7Fjxw6MGzfO6HKGDx+OwYMHAwD+/e9/44cffsCJEycQHR1tlTprO1pDltO8dUdooTt3pi52jrsplXrxxRd5wzk5Ofjkk0/QrFkzeHt7w8PDA1euXKl2DVn+/pHu7u7w8vKyyU1eaytaQ5ajclcgDbomXuqCHMiUbnCVS3H5yyhB6nGVW6+5mbu7O2/4k08+QWxsLL7//ns0adIErq6uGDBgAIqKiqpcjlwu5w1zHKe/ESypOQpkBVpO95W45N4H3L3AyVysttkoJkePHsXw4cPRv39/ALo15p07d4QtitAma0USSbnmXnnOe7CiadOm2LJlCxISEnDu3DkMGTKE1nQiQIGsQKP0LhuQON+asdS8efPg4+ODjh07onfv3oiKisILL7wgdFm1Xq27P2RWVhZUKhUyMzMr9TpXUFCAazduIchLgnryAkDhAdRtKlCljq+goACJiYkICQmBi4uL0OVYVVW/o5qgNWQFEg7w5ErOQxblCFsMqXUokBXIpPSVEOHQr8+Ax4w6UCbCoEAawMmpxwAiDAqkAbzN1vynwhVCah0KpAFaWbk15NM7gtVBah8KpAES6gqGCIQCaYC64qlZDfWaRuyDAmmAl1KOh0xVNoJRkzJiHxRIA2RSDsXl293XrsZMREAUSAM4jkMmK3e5kkbc10baqpOr0mVv27bNarWSqjlv6+kaUqPctYjpt4GgNsIVUw1zOrki4kZrSCN83RRCl2Cyqjq5CggIwPr169GsWTO4uLggLCwMixcv1r+2qKgI48aNQ2BgIFxcXNCoUSPMmjULgK6TKwDo378/OI7TDxPboTWkEQq5BCiAbv9RXQAU5dq/CLkbUMPu+NesWYNp06Zh4cKFaNOmDc6ePYuRI0fC3d0dw4YNww8//IAdO3bgt99+Q8OGDZGcnIzk5GQAun5Z/fz8sGrVKkRHR9MNc+yAAmmETFKy8aAuAFbFCFPEPx8ACvfq56vC9OnTMXfuXLz++usAgJCQEFy+fBnLli3DsGHDkJSUhKZNm6Jz587gOA6NGjXSv7a0X9bS+zwS26NAGuEMjQNyc3Nx69YtjBgxAiNHjtSPV6vVUKl0p3WGDx+O7t27IzQ0FNHR0XjttdfQo0cPoUqu9SiQRkhKNxVlLsB7u4HA8KpfYAs1bOSek6O7nvPHH39E+/btedNKNz9feOEFJCYmYvfu3di/fz8GDhyIyMhIbNq0qUbvTSxDgTRC37cOxwFy1xpvOgrB398fQUFBuH37NoYOHWp0Pi8vLwwaNAiDBg3CgAEDEB0djfT0dPj6+kIul0Oj0dix6tqNAmmEM2yyArqexsePHw+VSoXo6GgUFhbi1KlTePr0KSZOnIh58+YhMDAQbdq0gUQiwcaNGxEQEABvb28AuiOtcXFx6NSpE5RKJXx8fIT9QE6OTnsYIeE4qFm5r8dB27O+//77WLFiBVatWoWWLVvilVdewerVqxESEgIA8PT0xJw5c/Diiy/ipZdewp07d7Br1y5ISg5qzZ07F7GxsQgODkabNuI9F+ssqJOrcsp3yqRUKpH24C4CuJLrId39AFV9ASp2XNTJlfloDWkEx3FgMteyEbkPqU0rsTkKZBWKpBUO5BRkCFIHqT0okFXgKraSocuwiI1RIKsgcZZDrcRhUCANKD3OJalhO9LarpYdL7QKCmQ5pbday8vLA6A7F5nNXKt6CalC6fdY8RZ2xDhqGFCOVCqFt7e3/gakWiaDXJOHgtIZCosASYHR1xMdxhjy8vLw8OFDeHt701UiZqBAVlB6VcPDhw9RUKxBZu6jsoluWkCRIUxhDoiuEjEfBbICjuMQGBgIPz8/XH+QgUu75uM12XHdxFdnACGvCVqfo5DL5bRmtAAF0gipVAp/X09cyn0IF6nugl2wfMDJWpwQcaGDOlXwdpVDjnJXOhyaI1wxpFagQFZBIuGQKy3XTjEjSbhiSK1AgayGQlLuXJoXNS4ntiVoIGfNmoWXXnoJnp6e8PPzQ79+/XjdFxqzceNGhIWFwcXFBS1btsSuXbtsVuMWZd+ygdZDbPY+hAACB/LPP//E2LFjcezYMcTGxqK4uBg9evRAbq7xHt7++usvDB48GCNGjMDZs2fRr18/9OvXDxcvXrRJjenKBlir/ptugNqyEhsT1fWQjx49gp+fH/7880906dLF4DyDBg1Cbm4udu7cqR/XoUMHtG7dGkuXLq32Pcy9jq3foqPolbIQI2W7gE4fAd2/NP0DEadVK66HzMzMBAD4+voanSc+Ph6RkZG8cVFRUYiPjzc4f2FhIbKysngPc7jKpdCU9mKuUZv1WkLMJZpAarVaTJgwAZ06dcLzzz9vdL7U1FT4+/vzxvn7+yM1NdXg/LNmzYJKpdI/goODzarLRS6BuvRr0lIgiW2JJpBjx47FxYsXsX79eqsud8qUKcjMzNQ/SnvlNpW7UlZ2nw8KJLExUbTUGTduHHbu3IlDhw6hQYMGVc4bEBCAtLQ03ri0tDSjbSaVSiWUSqXFtXm6yKBmFEhiH4KuIRljGDduHLZu3Yo//vhD3xNaVSIiIhAXF8cbFxsbi4iICJvU6KGUle1DUiCJjQm6hhw7dizWrl2L7du3w9PTU78fqFKp4Oqquw7x3XffRf369fV3ZProo4/wyiuvYO7cuejVqxfWr1+PU6dOYfny5Tap0dNFjiwKJLETQdeQS5YsQWZmJrp27YrAwED9Y8OGDfp5kpKSePc/7NixI9auXYvly5cjPDwcmzZtwrZt26o8EFQTujUkHdQh9iHoGtKUU6AHDx6sNO7NN9/Em2++aYOKKvN0oYM6xH5Ec5RVrDxdZNCWfk23DwpaC3F+FMhq+Hu5oIfklG6gIBPIfSxsQcSpUSCr8ayfB4rKb9mf32B8ZkJqiAJZDU+lDIs0/ctGKD2FK4Y4PQpkNTiOg1peLoSuxtvZElJTFEgT3JcElQ1w9JUR26Fflwn8vFxxQhuqG6BTH8SGKJAmeKGRDzTUnpXYAQXSBO4KKV2CReyCAmkCN2pgTuyEAmkCD6UUOSjpILn8rQUIsTIKpAncFDI8ZD66gfwMQWshzo0CaQJ3pRR1OV1/PzgyT9hiiFMTRY8BYuemkKGz5IzQZZBagNaQJvBQyuDOFQpdBqkFKJAmcFNIoWF0e3NiexRIE/B6niPEhiiQJnAvfx6SEBuiQJqA11IHAMRz9wXiZCiQJnBTlOvGAwC0GuMzE1IDFEgTKGSSCoGk5nPENiiQJtJw5fYhtcXCFUKcGgXSRNryB3VoDUlshAJporXub5cN0D4ksREKpImuB5a7tTmtIYmNUCBN5O0mh7a0tQ4FktgIBdJE7goZJFzJ+cc7R4QthjgtCqSJPFzKXRhz+mfhCiFOjQJpIg9luUBKqBkdsQ0KpIlUrvKygYCWwhVCnBoF0kR1PBS4om1YMtBE2GKI06JAmsjHTYEbrL5uQFMkbDHEaVEgTeTrrkBxaWsdDTWdI7ZBgTSRj7sCrOTrKtZQSx1iGxRIE3koZNAw3ddVVExrSGIbFEgTSSQcOInu61JTIImNUCDNwEl15yKL1dR0jtgGBdIMkpIGARRIYisUSDNIStaQagoksREKpBmkpfuQFEhiIxRIM5SuIbmCpwJXQpwVBdIMIZo7AIDGdzYKWwhxWhRIM7QoOC10CcTJUSAtRZ0lExugQJph7bPflQ0UZgtXCHFaFEgzJNfrggJWcl1kPh3YIdZHgTRDoMoFT+GpG8hPF7YY4pQokGao56FEBnPXDeQ8FLYY4pQokGZwV8rQTJKsG1g7UNhiiFOiQJqhXYiv0CUQJ0eBNIOLnHqbI7ZFgSRERCiQhIgIBZIQEaFAEiIiFEhCRIQCaaY5xbrzj8naegJXQpwRBdJMN0t6L0+Dj8CVEGdEgTRTVKsGAAAZqLNkYn0USDM1r69rreMmq2ZGQixAgTSTXKa7/ErCaA1JrI8CaSa5QgEAaMLuCFsIcUoUSDMpNbllAwVZwhVCnBIF0kwKrmxTNSu/QMBKiDMSNJCHDh1C7969ERQUBI7jsG3btirnP3jwIDiOq/RITU21T8EA5BJO//zULbpImViXoIHMzc1FeHg4Fi1aZNbrrl27hpSUFP3Dz8/PRhVWJpdo9c895doq5iTEfIIevI+JiUFMTIzZr/Pz84O3t7f1CzKBS4PWZc8ldKSVWJdD7kO2bt0agYGB6N69O44ePWrfN6/3nP6ppoj2IYl1OVQgAwMDsXTpUmzevBmbN29GcHAwunbtijNnzhh9TWFhIbKysniPmrolDQEAKDNu1HhZhJTnUO1NQkNDERoaqh/u2LEjbt26hfnz5+PXX381+JpZs2Zh5syZVq3jvjQYz2oSocm4b9XlEuJQa0hD2rVrh5s3bxqdPmXKFGRmZuofycnJNX5PqVzXOCA3v7DGyyKkPIdaQxqSkJCAwMBAo9OVSiWUSqVV39NDpju66p111arLJUTQQObk5PDWbomJiUhISICvry8aNmyIKVOm4P79+/jll18AAAsWLEBISAhatGiBgoICrFixAn/88Qf27dtn17rDM/8AAIQ+3G3X9yXOT9BAnjp1Ct26ddMPT5w4EQAwbNgwrF69GikpKUhKStJPLyoqwqRJk3D//n24ubmhVatW2L9/P28ZhDgyjrHadV+1rKwsqFQqZGZmwsvLy7KFzFCVe55pncKIQ7HK78gAhz+oQ4gzoUASIiIUyBqqZVv8xMYokBbQeAbpn++9lCZgJcTZUCAtUNhvpf75zYd0a3NiPRRIC8hUuoYIeUwJ2mIl1kSBtIBc6QIAUKIIlx/QaQ9iPRRIC3AyXSClHEPsJWpgTqyHAmmJkkACgAuKBCyEOBsKpCVkZY3VlSgWsBDibCiQluA4FDJdh8ktJHeErYU4FQqkhQqhC+Qvim+BjKRq5ibENBRIC2k5adlAyjnhCiFOhQJpIW+UaxDA0ddIrIN+SdZAgSRWQr8ka1BT3zrEOiiQ1hD3pdAVECdBgbSG9FtCV0CcBAWSEBGhQBIiIhRIQkSEAkmIiFAgLdXuH0JXQJwQBdJS9dsKXQFxQhRIS8ld9U+vypsLWAhxJhRIS4X21D/N8GklYCHEmVAgLSWV4UTw3wEAWo1a4GKIs6BA1oBUqrsmUquhXgOIdVgUyOTkZNy7d08/fOLECUyYMAHLly+3WmGOQCrXBTLpcTbyimgtSWrOokAOGTIEBw4cAACkpqaie/fuOHHiBKZOnYovv6w9Da1lUt3d/KTQYvMZ6n2O1JxFgbx48SLatWsHAPjtt9/w/PPP46+//sKaNWuwevVqa9YnalKZbg0p5bSgHpOJNVgUyOLiYv1twvfv348+ffoAAMLCwpCSkmK96kROVrLJKoUGChntjpOas+hX1KJFCyxduhSHDx9GbGwsoqOjAQAPHjxAnTp1rFqgmMk5LQCgv/QoBZJYhUW/om+//RbLli1D165dMXjwYISHhwMAduzYod+UrQ28Uw7rnyuk0irmJMQ0Mkte1LVrVzx+/BhZWVnw8fHRjx81ahTc3NysVpzYKfIe6p/LaQVJrMCin1F+fj4KCwv1Ybx79y4WLFiAa9euwc/Pz6oFill+q3fKBjTUrw6pOYsC2bdvX/zyyy8AgIyMDLRv3x5z585Fv379sGTJEqsWKGZ1uo4pGyjOF64Q4jQsCuSZM2fw8ssvAwA2bdoEf39/3L17F7/88gt++OEHqxYoalI51CVfYfy1BwIXQ5yBRYHMy8uDp6cnAGDfvn14/fXXIZFI0KFDB9y9e9eqBYqdhukO5jy4dAiFao3A1RBHZ1EgmzRpgm3btiE5ORl79+5Fjx49AAAPHz6El5eXVQsUOyWna8e6TLEAR6/VnnOwxDYsCuS0adPwySefoHHjxmjXrh0iIiIA6NaWbdq0sWqBjkTCqD0rqRmLTnsMGDAAnTt3RkpKiv4cJAC8+uqr6N+/v9WKczT+ybuB5z8QugziwDjGatYIs/SqjwYNGlilIFvLysqCSqVCZmamdTavZ6gqDGfWfJlE9Kz+Oyph0SarVqvFl19+CZVKhUaNGqFRo0bw9vbGV199Ba1Wa7XiCKltLNpknTp1Kn766SfMnj0bnTp1AgAcOXIEM2bMQEFBAb755hurFklIbWFRIH/++WesWLFCf5UHALRq1Qr169fHmDFjKJCEWMiiTdb09HSEhYVVGh8WFob09PQaF0VIbWVRIMPDw7Fw4cJK4xcuXIhWragHNkIsZdEm65w5c9CrVy/s379ffw4yPj4eycnJ2LVrl1ULJKQ2sWgN+corr+D69evo378/MjIykJGRgddffx2XLl3Cr7/+au0aCak1anwesrxz587hhRdegEYj3jaddB6SWIOozkMSQmyDAllTfnRfD2I9FMiaGrZT6AqIEzHrKOvrr79e5fSMjIya1OKY3GtPL3vE9swKpEqlqnb6u+++W6OCHJ1ao4VMShsexDJmBXLVqlW2qsNp/O/8A/Rv4xhXvhDxof/Kregx88LyQ4lCl0EcGAXSCrTR3wIAzmqb4EpKlsDVEEdGgbQCicJd9xd0wx1SMxRIa+B0X6MUdHE2qRkKpDVIdF1BSqBFkMpF4GKII6NAWkPJGpIDw4PMAoGLIY6MAmkNJYEs3YekDpOJpSiQ1sBxAMoCWVBM+5LEMoIG8tChQ+jduzeCgoLAcRy2bdtW7WsOHjyIF154AUqlEk2aNBHHLdRL15AlN3A9fOORkNUQByZoIHNzcxEeHo5FixaZNH9iYiJ69eqFbt26ISEhARMmTMD777+PvXv32rjSanBlB3UAYMVhahxALGNRFx7WEhMTg5iYGJPnX7p0KUJCQjB37lwAQLNmzXDkyBHMnz8fUVFRtiqzeky3z/iS5DqWy+diVPIk4WohDs2h9iHj4+MRGRnJGxcVFYX4+HijryksLERWVhbvYXVJx/VPe0hPQ4Fi678HqRUcKpCpqanw9/fnjfP390dWVhby8w3fMHXWrFlQqVT6R3BwsA0q47fQkYKOshLLOFQgLTFlyhRkZmbqH8nJydZ/Ewl/y18OugsWsYyg+5DmCggIQFpaGm9cWloavLy84OrqavA1SqUSSqXStoVx/P/X5LSGJBZyqDVkREQE4uLieONiY2P1fcMKxjOAN0hrSGIpQQOZk5ODhIQEJCQkANCd1khISEBSUhIA3eZm+R4IRo8ejdu3b+Ozzz7D1atXsXjxYvz222/4+OOPhSi/zIt/5w3KOQoksYyggTx16hTatGmjv+vyxIkT0aZNG0ybNg0AkJKSog8nAISEhOD3339HbGwswsPDMXfuXKxYsULYUx4AIOdvLsuhgVpDrXWI+QTdh+zatSuq6qfZUCucrl274uzZszasquZcUYgbD3PQLNB6HeiS2sGh9iEdxVjZdsT857DQZRAHRIG0gZ7SE0KXQBwUBZIQEaFAWourj9AVECdAgbSWzgKfeiFOgQJpLTJ+XzrUnpVYggJpLS3f5A1+LNtU5SkdQgyhQFqLmy9vcJxsO+5nGL4ChRBjKJA2lFdEm63EPBRIGypSU/M5Yh4KpA1Rd5DEXBRIa+q3lDe452KqQIUQR0WBtKamPXiDf916IlAhxFFRIK2p5B4fpS49oFvTEfNQIK2pQiBl1HMAMRMF0poqdHY1SrpToEKIo6JAWhPHX0P2lh4TqBDiqCiQ1iSV8wehQV4RbbYS01EgrYnjgHGn9YNSaLHowE0BCyKOhgJpbZ5lPat7cPk4fOOxgMUQR0OBtDaFh/6pJ/Jx/l6mgMUQR0OBtLaSm7cCgBtXCADYfznN2NyE8FAg7eD9X04JXQJxEBRIQkSEAmkLHH2txDL0y7EFVYNyA9SNBzEdBdIWynV4paS7KRMzUCBtQVLWYmeMbIeAhRBHQ4G0sY9kWwAAtx7lCFwJcQQUSFtQ1a806mxShv3rIA6HAmkLr82vNEom4QzMSAgfBdIWeEdZdSQUSGICCqSdUByJKSiQdqLWUh+tpHoUSDv5eMM5oUsgDoACaUeHrj8SugQichRIO3p3Jd3qnFSNAkmIiFAgCRERCiQhIkKBtDO6qzKpCgXSDppy9/TP6Y5YpCoUSFvpv1z/NFb5WdnzK9ThFTGOAmkrTSINjs4poJ7MiXEUSFtxr8MbfI5LBgAUa6gJHTGOAmknK+TfAwAK1RRIYhwF0k4aSnTN5oookKQKFEg7O3X3KW5Tdx7ECAqkAHr+cFjoEohIUSBt6YVhBkcXFNNmKzGMAmlLvf8jdAXEwVAgbYnjd9zxsuS8QIUQR0GBtKNfFbPhgkKhyyAiRoG0s/PK9ymUxCgKpJ0pOA3CuGTkFVETOlIZBVIADEDzaXvxJIfWlISPAikAbcnX/sGaM8gtpDUlKUOBFABXcs/IE4npaDF9L1Iy8wWuiIgFBVIAcvDXijvPpQhUCREbCqSt+T5baZSC4weSo/sMkBIUSFsbc6zSKLqrMjGGAmlrMgXwxWPeKDcU8IazqRcBUoICaQ9SOW9wseIH3vB/4m5Ao6Xe6AgF0n7+wb/k6mPZRt5wDp3+IKBA2k9gK97gR7KtCOFS0Iy7C4B6EiA6ogjkokWL0LhxY7i4uKB9+/Y4ccL4TWlWr14NjuN4DxcXFztWaz0HlJOwWzkF3shGoVojdDlEBAQP5IYNGzBx4kRMnz4dZ86cQXh4OKKiovDw4UOjr/Hy8kJKSor+cffuXTtWbH31uSd00TIBIIJAzps3DyNHjsR7772H5s2bY+nSpXBzc8PKlSuNvobjOAQEBOgf/v7+dqzY+jhoUVBMa0gicCCLiopw+vRpREaWdSoskUgQGRmJ+Ph4o6/LyclBo0aNEBwcjL59++LSpUtG5y0sLERWVhbvITYSMJy7lyF0GUQEBA3k48ePodFoKq3h/P39kZpq+B4YoaGhWLlyJbZv347/+7//g1arRceOHXHv3j2D88+aNQsqlUr/CA4OtvrnMFmvuQZHu6AIU7detHMxRIwE32Q1V0REBN599120bt0ar7zyCrZs2YJ69eph2bJlBuefMmUKMjMz9Y/k5GQ7V1xOaE+Do/8pX2PnQohYyYR887p160IqlSItjX8DmrS0NAQEBJi0DLlcjjZt2uDmzZsGpyuVSiiVyhrXahVSw3W0ltwGoLtVHUcNW2s1QdeQCoUCbdu2RVxcnH6cVqtFXFwcIiIiTFqGRqPBhQsXEBgYaKsyrUemqHLyzvN01UdtJ/gm68SJE/Hjjz/i559/xpUrV/DBBx8gNzcX7733HgDg3XffxZQpU/Tzf/nll9i3bx9u376NM2fO4O2338bdu3fx/vvvC/URTGdkDVlq6tYLdiqEiJWgm6wAMGjQIDx69AjTpk1DamoqWrdujT179ugP9CQlJUEiKft/4+nTpxg5ciRSU1Ph4+ODtm3b4q+//kLz5s2F+gimq9CmtaKsAjWi5h/C1rEd4aYQ/J+GCIBjtewe21lZWVCpVMjMzISXl5f9C5ihMji6ccFa/fNv+j+Poe0b2asiYgFb/Y4E32QlOl0lCZgsWwsZ1KALP2ov2i4SidWKOQCANOYDCdda2GKIYGgNaW91Q6ucHMKlYurWi8gvoqZ0tREF0t4++KvKyTLogrj44E38ef0RtLT9WqtQIO1NWvVeQmkg//vHTQxbeQJxV41f9UKcDwVSZGQcf1P1t1MCNvUjdkeBFJnSNWSp2MtpRuYkzogCKYSGHY1OckGRHQshYkOnPYQwfCdQlAMovYCZ3rxJHjB8W4HsgmLIpRK4yKV2KJAIhdaQQpBIAReVwS7Lm0mSKo3LK1Kj5Yx9eOnr/faojgiIAikyPlwOpsr+D/XwVD/ur5tPAADZhWrUspaOtQ4FUoRGynZhpeI7/fD7v5zSPy/WUCCdGQVSaK3eMji6peQOPpJuhifyeOOLNNQ7nTOjQAqt3xKjkz6Wb8Zk2TreuJ8OJ9q6IiIgCqTQJFX/EwyQHuINz99/HY9zCrE94b6wnSsX5QGZ94V7fydFpz1E7rS2aaVxHb/eDQYO17qG4rPoMAGqArDwJSDrHjDuNFC3iTA1OCFaQ4pcEfi9DHwt+wnXXYYhXjkO+y4+EKgq6MIIANd3C1eDE6JAikHYa0YndZWew0jpToyW7gDA8LZM1yFYXS4LXtJCoDgfSDwMaAS6CSydhrEqCqQYvLECeHmS0clT5WsxWb4edcHvdf1mWjaw+X3g59ewfs4HuPkwx9aVGkCBtCYKpBjIXYFXp1U7myvHv/Oyu5wBV3cCAPoU7MBH68/apDyrYAzQ0kXX1aFAOhAZ+OcgtcVlDdHduEJcffDU/ndiNnWTdeMwYEEroFCItbjjoECKSZfPqpxcDxm84eMu43jDg6V/YGS5Vj12wUxsqHB5u+5A0PU9tq3HwVEgxaTLp1VO/k35VZXTn+FS8Ic9ehioyYEcDV1eVhUKpJjIFEDkDItfztnrAEv5taK59yK5Z+c1uIOhQIqNqua3y2s1Yy/afhWLrIKSUyEp54D1Q4FH12u8bAD8UyxPbgF7pwLZJvZs8PSOdWpwUhRIsWneFwjuUKNFZBWo8SS3CEvjLiNv5xRgWRfd0dhf+6FIrcX9DMMXQZtMWy6QZ38F4hcCc58zvilbfryL4Z7biQ4FUmykcmDEXmBy5QuVqxPCpaL0vGAjLhWfnewCt1OLy2bIuo+By+LRafYfOH33qeGFmMJYI4SUBMPjtWrDz0klFEixquZOWYZ0lZ7DO9JYAMCfyokG50lIzgAAxG5dBdzYD+SlA1qtbi32vwlA/GKDr+MxFirOQPciV/4HzCt3IyQ6F1klalwuVnIXi172lXw1TmirbnDugTxMzpgJlNy4Ob7O63jcMAa9z67SjYgYU/WbHDd8t2rcOQwEtuKP2/A2f/ja77pQSoz0DcSY+QeKnAitIZ1QI66qAywMKxRzeWMinmzB9uNXTX+Dw98bHr/3n6a9/tx6QGNgLavVAD/+DVgz0PRanAwF0glpqvhnnSxbhw6SK5XGV3nKhDHd0VRTzj8WZFY/T8JaYFYD4PRq3bBWC1zbozsa/OAMcGMvkPu4+uWUl5du3vwiRYF0RMN/r3JyD8lpo9NGy3YaHB/GVXEQ6egC4L8vAHEzqz91smag7goUwPBaEADuHgHU+cD/PtKtFX/pA6wbpFs7lsp9VPX7lHd8GTAnBEhYV/28IkeBdDT9lwOSqnf9B8kOmr3YSfJNZQMla8K0rAJdL3f7Z+jGH5kPLHqp6gUlHwNOrdQ9v21CHVd36vY9dW9cNr4w25SydXaXNDn830emv0ak6KCOmDXvB1zeVjY8NU13sCflvE3fdvnB6wiu64UP1pxBCJeCA+Ye8M15qHvEflH9vKXhrej+Gd1R37pNgehZgIs3sH86IJEDUd/U/MDP0zvAtd1A2+G6q21EggIpZj2+Lgtk67fLjrwGtLTp287dexnBfr4AgM2K6ZYtZON7wMPLZcMSOb9BQakntw2/fs/nur8PLwF3jgA+jYD7JZviodFASJfKrzHW0F1TrFvjuvmWjfu/N4AnN4EzvwBj4qv/PHZCm6xi5h0M/PMB8NY6oFe5I5scV2UvAzWlRBFuPszBC9x1+HKmXS51VVuuyZ9WrdtPLG+44X1XZJrQACLvcVkYASC/XKMGdSH/fQ35qbtuHzO9JPxarS6MAP8/DRGgQIqdwh0I61l5s4qz3T/dK5LzcEMBtihnmDT/GW0TFJbv+6d8SEpJ5ZXHWar80d7slPITyqbfOlDWvvZByYXbl7bp/hprUSQCFEhHZUEj9MOa502ab7xsKz6Q7TB5uVpIoC3/UyrIqDxTNQeizMOA3CfA2TVAUS5/kroI2PEh8Gs/4Ic2lV8HlB0FBsq+x+IC4PdJutZLAqJ9SEfV9XPdBb8ata71iwm0Jv7/21RyHxdZY5NL0YID7//2CxsNzGTFNqwbh5c9r9gQP+u+rsE7ABRXCCsAFGQB28u1RPJuqPt78kfg5ArdY0YmkHQcuH8K6DDGri2HKJCOykUFDPxFtz90fQ8ABqwfwp+n72Lej+8VqelHZ825TyUDh6r6DYhz74mFCw9jq/nNc6uXfIw/nPfE+LyMAbHT+JeAlV4wnVFuX/aPb4BDc3TPPQOB51+3SqmmoE1WRyeR6PYxw3pVniZTAkN+A6QKgy8dXzTO4HgA8IaBtYsRDBw0zPh9K9MyC3CePWPy8mrkfoVGEbwWPAy4d5I/Pf+p7j+18vvkpWEEys5x2gkF0plJ5cBzUYbvH9LpIwx6bwJSJQEGX1qXM6EJXAkt4/AQ3kanr9JEQwMp/lH0sdF5NmkMnMawRMUAnVhe9pyh8qbzk5vAr335+5XlmdNiyAookE6lwr5O6ZrR0D6Qizc6Na2HgLG7DC6pqcT0+3ZowSGXGd8evcHqAwCUMN6ZM++0iTUdnMUfNnT5V+Ih4MzPxpdR8cCRDVEgnUnFUwulm2GGTpG8+J7ur08I8FxMjd5WwanBjPyU5hUPQOl/FKe0zwEAMph7pfns0x8Q45/DNFWW/W7ZQIF0JhIj5/oMXTmhLOlKQyIBhqw3620eMm9sUHfVD7uiEFdYQ4Pzbtd21D9/gLp4uXA+uhQuwPAi/qZlLgw3XxtUaELzO1Mxra6RgbkyTGi8YCUUSGfSsMIpgNIr+A018q7mNnil1qm78YbXqF/Fy4ULcJaV3fGqqY8EEW+Mx/fFb2KFmr+2LWD8A0rJzB9ZcMdBbWve+HPaZyu99x2tPzjOemvOgsyy60SZkYYVWqmBC8Nz7NC1ZgkKpDPpvwwIH1w2XBq6GvSj+vLAsisoJvj9hKnqESiEAoc1Ze1pXVgRer3wDNq+82+cfI5/j5ICGD7CCwB55fY71QZ+iiouF+6oYYdc5Zw6XXaE9bLkOYPzHFca6GDMjgd2KJDOxKMe0H9p2bDSS/e37fDqX9s0Sve3QhvZBoFB+udTBv0NY7s9iyOfd8PR2eWWWay77Xq3MD8se5d/eVYujHdF0q5wERar++DVwu8q3bodAHy4HBRb8VR5Z8kF/fNrRXUrTS9iUtzV1Kn8Qks2cy1EgXRGPb4GXnofqN9WN9y0e/VN7QavAz5LBIIqNDdTegEjDwCjDsK/ji8+jQpDAx83/jzFlcNUanQ3fv8+XUPr6Z/nwA1z1G/hFquP60xX3yOmwi1tIADgrLYJDmtrfmXLPVY5fE+ZJz4q4vcddImFgMvlNywoYlJdczw7oZY6zqjjh/xhjgM+vgjMqKJPVIlUd3mSrMLpC5kSqP9C1e+n5t+VC5OTgbmhgF9zfNz9OUQ290dOgRqHbz7CuG5N0HLGvkqLyII72hQsRR5cUJ97jM9kG/BJ8T/AIMFT5gGfaq462aGJQB+p4cuoMpgHGnD8tdxidR88gQqZRR5YrdA1BCiCrNLF3c8V/oJ5/q1hr7Y6tIYkfHVD+cMyC3q/c/ECPr0FjNgHqYRD62BvdG5aF1NimsFDWbYOUMr4P7/3o17CsS964TYLwujij5ED3Zr43aLJSNA+i/XljuyWrkVLXdI2NlrO85I7lcY9ge4/p6fMQz9OzaT4VR2pHz6uDQPAYeJv56r7xFZDa0jC1+RV/nDFNaapFG4GR3Mch3PTe6BYo0Vdj7JlZ+YVQ+WmO21zbnoPhM8sW4teYM+gX9FX8EQemkmSEBjWAZoiDrizRj+PFhzOaZ9BuER3zeM/iiZgmWJBtWVmoCyQd5kfvlK/gxusPk5qw3CFNTLrI1sDBbI2aRgBJMUDzfoYn6dif6nG+k+tAZVr5fOlpWEsnX796xgkpefBz0uJQ9cf4dUwf5y8k44L6e0Q3qER/HIf49Ds8+gi1R2o0YLDfPUArFbMQSZzw15tO/3yflD3Qw/JaYRJkgEAF8utTTPKrSFz4YoiyPGLJsraH9lkFMjaZNAa4MoO4Pk3TJu/3T9sW08VFDIJmvjpwvJaK92R3i7PlR0Qgntd3Ij6FV32twYAhAV546fkcAwtmoJWbSJw581XMGXqCHSVnMMidT/Mw0A05+5gpOx3zFW/qV9MFsrW5AvV/QzWsvPDztb9cFXgGKvJzf4cT1ZWFlQqFTIzM+Hl5SV0OeJ0eTtwbgPQbxHg6mN8vm1jgIQ1QKu3gNeN9GZuayUHqrTR3yKr1d/h7VZ23vNqahZiL6UhLbsAT3OL8e/XW0LlKkfSkzx0+e4AAOA/b7XGygOXcCMtG3klp2gGvRiMDad0a9NPo0IxtlsTVGSr3xGtIUllzfvqHtXpNVe3+Wuowyk7k8iUvDACQFiAF8ICKoelYR033JlddrnavstpOJdW1vD9s+hQeLjIcOpOOsZ0rdyCyJYokMRyclddD3BC6jgeuH0AaDXI4kV80as57j3NR+9Wgejbuj7qeCjxxWvNq3+hDdAmKyEWsNXviM5DEiIiFEhCRIQCSYiIUCAJEREKJCEiQoEkREQokISIiCgCuWjRIjRu3BguLi5o3749Tpw4UeX8GzduRFhYGFxcXNCyZUvs2mW4K0NCHI3ggdywYQMmTpyI6dOn48yZMwgPD0dUVBQePjTcsdBff/2FwYMHY8SIETh79iz69euHfv364eLFi3aunBDrE7ylTvv27fHSSy9h4cKFAACtVovg4GB8+OGHmDx5cqX5Bw0ahNzcXOzcWXa/wQ4dOqB169ZYunRppfkropY6xBqcsqVOUVERTp8+jcjIsqu0JRIJIiMjER9vuDuG+Ph43vwAEBUVZXT+wsJCZGVl8R6EiJWggXz8+DE0Gg38/f154/39/ZGammrwNampqWbNP2vWLKhUKv0jONhGXdYTYgWC70Pa2pQpU5CZmal/JCcnC10SIUYJevlV3bp1IZVKkZaWxhuflpaGgADDd2UKCAgwa36lUgml0hY3JiTE+gQNpEKhQNu2bREXF4d+/foB0B3UiYuLw7hxhu9dGBERgbi4OEyYMEE/LjY2FhERESa9Z+kxLNqXJDVR+vux+jFRJrD169czpVLJVq9ezS5fvsxGjRrFvL29WWpqKmOMsXfeeYdNnjxZP//Ro0eZTCZj33//Pbty5QqbPn06k8vl7MKFCya9X3JyMoPuToH0oEeNH8nJyVbNg+A9BgwaNAiPHj3CtGnTkJqaitatW2PPnj36AzdJSUmQlLsxTMeOHbF27Vr861//wj//+U80bdoU27Ztw/PPP2/S+wUFBSE5ORmenp7gKtw3MSsrC8HBwUhOTq7Vp0Toeyhj7LtgjCE7OxtBQUFVvNp8gp+HFBM6R6lD30MZe38XTn+UlRBHQoEkREQokOUolUpMnz691p8moe+hjL2/C9qHJEREaA1JiIhQIAkREQokISJCgSRERCiQJcztRsTRzJgxAxzH8R5hYWH66QUFBRg7dizq1KkDDw8PvPHGG5Ua8SclJaFXr15wc3ODn58fPv30U6jVant/FLMdOnQIvXv3RlBQEDiOw7Zt23jTGWOYNm0aAgMD4erqisjISNy4cYM3T3p6OoYOHQovLy94e3tjxIgRyMnh32b9/PnzePnll+Hi4oLg4GDMmTPH/GKt2hDPQa1fv54pFAq2cuVKdunSJTZy5Ejm7e3N0tLShC7NaqZPn85atGjBUlJS9I9Hjx7pp48ePZoFBwezuLg4durUKdahQwfWsWNH/XS1Ws2ef/55FhkZyc6ePct27drF6taty6ZMmSLExzHLrl272NSpU9mWLVsYALZ161be9NmzZzOVSsW2bdvGzp07x/r06cNCQkJYfn6+fp7o6GgWHh7Ojh07xg4fPsyaNGnCBg8erJ+emZnJ/P392dChQ9nFixfZunXrmKurK1u2bJlZtVIgGWPt2rVjY8eO1Q9rNBoWFBTEZs2aJWBV1jV9+nQWHh5ucFpGRgaTy+Vs48aN+nFXrlxhAFh8fDxjTPejlkgk+kb/jDG2ZMkS5uXlxQoLC21auzVVDKRWq2UBAQHsu+++04/LyMhgSqWSrVu3jjHG2OXLlxkAdvLkSf08u3fvZhzHsfv37zPGGFu8eDHz8fHhfReff/45Cw0NNau+Wr/Jakk3Io7qxo0bCAoKwjPPPIOhQ4ciKSkJAHD69GkUFxfzvoOwsDA0bNhQ/x3Ex8ejZcuWvN4aoqKikJWVhUuXLtn3g1hRYmIiUlNTeZ9dpVKhffv2vM/u7e2NF198UT9PZGQkJBIJjh8/rp+nS5cuUCjK7lEZFRWFa9eu4enTpybXU+sDaUk3Io6offv2WL16Nfbs2YMlS5YgMTERL7/8MrKzs5GamgqFQgFvb2/ea8p/B8a6Timd5qhKa6/q3z81NRV+fn686TKZDL6+vlb/fgS//IrYR0xMjP55q1at0L59ezRq1Ai//fYbXF1dBayMlFfr15CWdCPiDLy9vfHcc8/h5s2bCAgIQFFRETIyMnjzlP8OjHWdUjrNUZXWXtW/f0BAQKV+gtVqNdLT063+/dT6QJbvRqRUaTcipnYL4ohycnJw69YtBAYGom3btpDL5bzv4Nq1a0hKStJ/BxEREbhw4QLvhxkbGwsvLy80by7M7b+tISQkBAEBAbzPnpWVhePHj/M+e0ZGBk6fPq2f548//oBWq0X79u318xw6dAjFxcX6eWJjYxEaGgofHx/TC7LkSJWzqa4bEWcwadIkdvDgQZaYmMiOHj3KIiMjWd26ddnDhw8ZY7rTHg0bNmR//PEHO3XqFIuIiGARERH615ee9ujRowdLSEhge/bsYfXq1XOI0x7Z2dns7Nmz7OzZswwAmzdvHjt79iy7e/cuY0x32sPb25tt376dnT9/nvXt29fgaY82bdqw48ePsyNHjrCmTZvyTntkZGQwf39/9s4777CLFy+y9evXMzc3NzrtYan//ve/rGHDhkyhULB27dqxY8eOCV2SVQ0aNIgFBgYyhULB6tevzwYNGsRu3rypn56fn8/GjBnDfHx8mJubG+vfvz9LSUnhLePOnTssJiaGubq6srp167JJkyax4uJie38Usx04cMBgfzjDhg1jjOlOfXzxxRfM39+fKZVK9uqrr7Jr167xlvHkyRM2ePBg5uHhwby8vNh7773HsrOzefOcO3eOde7cmSmVSla/fn02e/Zss2uly68IEZFavw9JiJhQIAkREQokISJCgSRERCiQhIgIBZIQEaFAEiIiFEhiNYauxifmoUA6ieHDh1fqooPjOERHRwtdGjEDXX7lRKKjo7Fq1SreOOp93LHQGtKJKJVKBAQE8B6lVxpwHIclS5YgJiYGrq6ueOaZZ7Bp0ybe6y9cuIC//e1vcHV1RZ06dTBq1KhKHTmtXLkSLVq0gFKpRGBgYKUb6z5+/Bj9+/eHm5sbmjZtih07dtj2QzsZCmQt8sUXX+CNN97AuXPnMHToULz11lu4cuUKACA3NxdRUVHw8fHByZMnsXHjRuzfv58XuCVLlmDs2LEYNWoULly4gB07dqBJkya895g5cyYGDhyI8+fPo2fPnhg6dCjS09Pt+jkdmoUN6InIDBs2jEmlUubu7s57fPPNN4wxXedOo0eP5r2mffv27IMPPmCMMbZ8+XLm4+PDcnJy9NN///13XsdWQUFBbOrUqUZrAMD+9a9/6YdzcnIYALZ7926rfU5nR/uQTqRbt25YsmQJb5yvr6/+ecULriMiIpCQkAAAuHLlCsLDw+Hu7q6f3qlTJ2i1Wly7dg0cx+HBgwd49dVXq6yhVatW+ufu7u7w8vKqdLU9MY4C6UTc3d0rbUJai6n97sjlct4wx3HQarW2KMkp0T5kLXLs2LFKw82aNQMANGvWDOfOnUNubq5++tGjRyGRSBAaGgpPT080btyY19UFsT5aQzqRwsLCSl0OymQy1K1bFwCwceNGvPjii+jcuTPWrFmDEydO4KeffgIADB06FNOnT8ewYcMwY8YMPHr0CB9++CHeeecdfXeGM2bMwOjRo+Hn54eYmBhkZ2fj6NGj+PDDD+37QZ2Z0DuxxDqGDRtmsJuK0p6zAbBFixax7t27M6VSyRo3bsw2bNjAW8b58+dZt27dmIuLC/P19WUjR46s1E3F0qVLWWhoKJPL5SwwMJB9+OGH+mkw0E2/SqViq1atsslndkbUhUctwXEctm7din79+gldCqkC7UMSIiIUSEJEhA7q1BK0Z+IYaA1JiIhQIAkREQokISJCgSRERCiQhIgIBZIQEaFAEiIiFEhCRIQCSYiI/D+iA/c1DDIrFQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix\n",
        "plt.subplot(1, 3, 3)\n",
        "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
        "cm = confusion_matrix(np.argmax(y_test.values, axis=1), y_pred)\n",
        "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.colorbar()\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "6BWnLq0xk2P7",
        "outputId": "a907ce0e-5b27-4c2e-eed9-40eca9086539"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19/19 [==============================] - 0s 4ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}