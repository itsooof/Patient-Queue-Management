{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diastolic Blood Pressure (mmHg)</th>\n",
       "      <th>Systolic Blood Pressure (mmHg)</th>\n",
       "      <th>Blood Sugar Level (mg/dL)</th>\n",
       "      <th>Oxygen Level (%)</th>\n",
       "      <th>Heart Rate (beatspm)</th>\n",
       "      <th>Body Temperature (F)</th>\n",
       "      <th>Breathing Rate (breathspm)</th>\n",
       "      <th>Urinalysis (pH)</th>\n",
       "      <th>Peak Flow</th>\n",
       "      <th>Hydration Level (%)</th>\n",
       "      <th>Seriousness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>74.00</td>\n",
       "      <td>101.56</td>\n",
       "      <td>40.04</td>\n",
       "      <td>95.39</td>\n",
       "      <td>71.17</td>\n",
       "      <td>98.06</td>\n",
       "      <td>17.47</td>\n",
       "      <td>5.40</td>\n",
       "      <td>88.29</td>\n",
       "      <td>56.22</td>\n",
       "      <td>Moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.87</td>\n",
       "      <td>72.77</td>\n",
       "      <td>86.81</td>\n",
       "      <td>40.35</td>\n",
       "      <td>95.70</td>\n",
       "      <td>97.86</td>\n",
       "      <td>14.90</td>\n",
       "      <td>5.72</td>\n",
       "      <td>92.06</td>\n",
       "      <td>64.56</td>\n",
       "      <td>Serious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99.90</td>\n",
       "      <td>112.77</td>\n",
       "      <td>103.41</td>\n",
       "      <td>96.07</td>\n",
       "      <td>48.78</td>\n",
       "      <td>98.59</td>\n",
       "      <td>16.26</td>\n",
       "      <td>11.55</td>\n",
       "      <td>88.77</td>\n",
       "      <td>50.35</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>73.30</td>\n",
       "      <td>64.81</td>\n",
       "      <td>86.56</td>\n",
       "      <td>97.62</td>\n",
       "      <td>72.92</td>\n",
       "      <td>98.42</td>\n",
       "      <td>22.42</td>\n",
       "      <td>6.32</td>\n",
       "      <td>88.73</td>\n",
       "      <td>59.67</td>\n",
       "      <td>Moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72.67</td>\n",
       "      <td>86.94</td>\n",
       "      <td>110.78</td>\n",
       "      <td>37.69</td>\n",
       "      <td>34.51</td>\n",
       "      <td>98.01</td>\n",
       "      <td>9.86</td>\n",
       "      <td>6.94</td>\n",
       "      <td>89.38</td>\n",
       "      <td>62.36</td>\n",
       "      <td>Moderate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Diastolic Blood Pressure (mmHg)  Systolic Blood Pressure (mmHg)  \\\n",
       "0                            74.00                          101.56   \n",
       "1                            67.87                           72.77   \n",
       "2                            99.90                          112.77   \n",
       "3                            73.30                           64.81   \n",
       "4                            72.67                           86.94   \n",
       "\n",
       "   Blood Sugar Level (mg/dL)  Oxygen Level (%)  Heart Rate (beatspm)  \\\n",
       "0                      40.04             95.39                 71.17   \n",
       "1                      86.81             40.35                 95.70   \n",
       "2                     103.41             96.07                 48.78   \n",
       "3                      86.56             97.62                 72.92   \n",
       "4                     110.78             37.69                 34.51   \n",
       "\n",
       "   Body Temperature (F)  Breathing Rate (breathspm)  Urinalysis (pH)  \\\n",
       "0                 98.06                       17.47             5.40   \n",
       "1                 97.86                       14.90             5.72   \n",
       "2                 98.59                       16.26            11.55   \n",
       "3                 98.42                       22.42             6.32   \n",
       "4                 98.01                        9.86             6.94   \n",
       "\n",
       "   Peak Flow  Hydration Level (%) Seriousness  \n",
       "0      88.29                56.22    Moderate  \n",
       "1      92.06                64.56     Serious  \n",
       "2      88.77                50.35        High  \n",
       "3      88.73                59.67    Moderate  \n",
       "4      89.38                62.36    Moderate  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"PQM_FACTORS.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data.drop('Seriousness', axis=1)\n",
    "X = features\n",
    "Y = data[\"Seriousness\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = []\n",
    "model = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Decision Tree Classifier\n",
    "c_DT1 = DecisionTreeClassifier(criterion='gini', random_state=0)\n",
    "c_DT1.fit(X_train, y_train)\n",
    "try_predDT1 = c_DT1.predict(X_test)\n",
    "accuracy.append(accuracy_score(y_test, try_predDT1))\n",
    "model.append(\"Decision Tree Gini\")\n",
    "\n",
    "c_DT2 = DecisionTreeClassifier(criterion='entropy', random_state=0)\n",
    "c_DT2.fit(X_train, y_train)\n",
    "try_predDT2 = c_DT2.predict(X_test)\n",
    "accuracy.append(accuracy_score(y_test, try_predDT2))\n",
    "model.append(\"Decision Tree Entropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. K-Nearest Neighbors Classifier\n",
    "maxi = 0\n",
    "k = 0\n",
    "for i in range(1, 20):\n",
    "    c_KNN = KNeighborsClassifier(n_neighbors=i)\n",
    "    c_KNN.fit(X_train, y_train)\n",
    "    try_predKNN = c_KNN.predict(X_test)\n",
    "    if maxi < accuracy_score(y_test, try_predKNN):\n",
    "        maxi = accuracy_score(y_test, try_predKNN)\n",
    "        k = i\n",
    "\n",
    "c_KNN = KNeighborsClassifier(n_neighbors=k)\n",
    "c_KNN.fit(X_train, y_train)\n",
    "try_predKNN = c_KNN.predict(X_test)\n",
    "accuracy.append(accuracy_score(y_test, try_predKNN))\n",
    "model.append(\"KNN for k=\" + str(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Logistic Regression\n",
    "c_LR = LogisticRegression(max_iter=100000)\n",
    "c_LR.fit(X_train, y_train)\n",
    "try_predLR = c_LR.predict(X_test)\n",
    "accuracy.append(accuracy_score(y_test, try_predLR))\n",
    "model.append(\"Logistic Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Gaussian Naive Bayes\n",
    "gaussian = GaussianNB()\n",
    "gaussian.fit(X_train, y_train)\n",
    "try_predNB = gaussian.predict(X_test)\n",
    "accuracy.append(accuracy_score(y_test, try_predNB))\n",
    "model.append(\"GaussianNB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nhyperparameters = [\\n    [\"linear\",10],\\n    [\"linear\",50],\\n    [\"linear\",100],\\n    [\"linear\",500],\\n    [\"linear\",1000],\\n    [\"poly\",10],\\n    [\"poly\",50],\\n    [\"poly\",100],\\n    [\"poly\",500],\\n    [\"poly\",1000],\\n    [\"rbf\",10],\\n    [\"rbf\",50],\\n    [\"rbf\",100],\\n    [\"rbf\",500],\\n    [\"rbf\",1000],\\n    [\"sigmoid\",10],\\n    [\"sigmoid\",50],\\n    [\"sigmoid\",100],\\n    [\"sigmoid\",500],\\n    [\"sigmoid\",1000]\\n]\\nmaxs = 0\\nkernelval = \"\"\\nCval = 0\\nfor KFFC in hyperparameters:\\n    print(KFFC)\\n    svc = SVC(kernel=KFFC[0], C=KFFC[1])\\n    scaler = StandardScaler()\\n    Xtrain = scaler.fit_transform(X_train)\\n    svc.fit(Xtrain, y_train)\\n    try_predSVM = svc.predict(scaler.transform(X_test))\\n    if maxs < accuracy_score(y_test, try_predSVM):\\n        maxs = accuracy_score(y_test, try_predSVM)\\n        kernelval = KFFC[0]\\n        Cval = KFFC[1]\\n\\nsvc = SVC(kernel=kernelval, C=Cval)\\nscaler = StandardScaler()\\nXtrain = scaler.fit_transform(X_train)\\nsvc.fit(Xtrain, y_train)\\ntry_predSVM = svc.predict(scaler.transform(X_test))\\naccuracy.append(accuracy_score(y_test, try_predSVM))\\nmodel.append(\"SVM for kernel =\" + kernelval + \" C =\" + str(Cval))\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. Support Vector Machine (SVM) Classifier\n",
    "'''\n",
    "hyperparameters = [\n",
    "    [\"linear\",10],\n",
    "    [\"linear\",50],\n",
    "    [\"linear\",100],\n",
    "    [\"linear\",500],\n",
    "    [\"linear\",1000],\n",
    "    [\"poly\",10],\n",
    "    [\"poly\",50],\n",
    "    [\"poly\",100],\n",
    "    [\"poly\",500],\n",
    "    [\"poly\",1000],\n",
    "    [\"rbf\",10],\n",
    "    [\"rbf\",50],\n",
    "    [\"rbf\",100],\n",
    "    [\"rbf\",500],\n",
    "    [\"rbf\",1000],\n",
    "    [\"sigmoid\",10],\n",
    "    [\"sigmoid\",50],\n",
    "    [\"sigmoid\",100],\n",
    "    [\"sigmoid\",500],\n",
    "    [\"sigmoid\",1000]\n",
    "]\n",
    "maxs = 0\n",
    "kernelval = \"\"\n",
    "Cval = 0\n",
    "for KFFC in hyperparameters:\n",
    "    print(KFFC)\n",
    "    svc = SVC(kernel=KFFC[0], C=KFFC[1])\n",
    "    scaler = StandardScaler()\n",
    "    Xtrain = scaler.fit_transform(X_train)\n",
    "    svc.fit(Xtrain, y_train)\n",
    "    try_predSVM = svc.predict(scaler.transform(X_test))\n",
    "    if maxs < accuracy_score(y_test, try_predSVM):\n",
    "        maxs = accuracy_score(y_test, try_predSVM)\n",
    "        kernelval = KFFC[0]\n",
    "        Cval = KFFC[1]\n",
    "\n",
    "svc = SVC(kernel=kernelval, C=Cval)\n",
    "scaler = StandardScaler()\n",
    "Xtrain = scaler.fit_transform(X_train)\n",
    "svc.fit(Xtrain, y_train)\n",
    "try_predSVM = svc.predict(scaler.transform(X_test))\n",
    "accuracy.append(accuracy_score(y_test, try_predSVM))\n",
    "model.append(\"SVM for kernel =\" + kernelval + \" C =\" + str(Cval))\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Random Forest Classifier\n",
    "c_rf = RandomForestClassifier(n_estimators=10, random_state=0)\n",
    "c_rf.fit(X_train, y_train)\n",
    "try_predrf = c_rf.predict(X_test)\n",
    "accuracy.append(accuracy_score(y_test, try_predrf))\n",
    "model.append(\"Random Forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Gradient Boosting Classifier\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=1, random_state=0)\n",
    "gb_clf.fit(X_train, y_train)\n",
    "try_predGB = gb_clf.predict(X_test)\n",
    "accuracy.append(accuracy_score(y_test, try_predGB))\n",
    "model.append(\"Gradient Boosting Classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. MLP Classifier (Neural Network)\n",
    "mlp_clf = MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, random_state=0)\n",
    "mlp_clf.fit(X_train, y_train)\n",
    "try_predMLP = mlp_clf.predict(X_test)\n",
    "accuracy.append(accuracy_score(y_test, try_predMLP))\n",
    "model.append(\"MLP Classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. AdaBoost Classifier\n",
    "ada_clf = AdaBoostClassifier(n_estimators=50, random_state=0)\n",
    "ada_clf.fit(X_train, y_train)\n",
    "try_predAda = ada_clf.predict(X_test)\n",
    "accuracy.append(accuracy_score(y_test, try_predAda))\n",
    "model.append(\"AdaBoost Classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Quadratic Discriminant Analysis\n",
    "qda_clf = QuadraticDiscriminantAnalysis()\n",
    "qda_clf.fit(X_train, y_train)\n",
    "try_predQDA = qda_clf.predict(X_test)\n",
    "accuracy.append(accuracy_score(y_test, try_predQDA))\n",
    "model.append(\"Quadratic Discriminant Analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_f = [i*100 for i in accuracy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.0\n",
      "Decision Tree Gini\n",
      "[98.0, 97.5, 97.5, 14.000000000000002, 13.0, 96.83333333333334, 25.0, 14.499999999999998, 16.166666666666664, 19.333333333333332]\n",
      "['Decision Tree Gini', 'Decision Tree Entropy', 'KNN for k=1', 'Logistic Regression', 'GaussianNB', 'Random Forest', 'Gradient Boosting Classifier', 'MLP Classifier', 'AdaBoost Classifier', 'Quadratic Discriminant Analysis']\n"
     ]
    }
   ],
   "source": [
    "print(max(acc_f))\n",
    "print(model[acc_f.index(max(acc_f))])\n",
    "\n",
    "print(acc_f)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 96.30%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "k = 5\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=0)\n",
    "scores = cross_val_score(c_DT1, X, Y, cv=kf)\n",
    "mean_accuracy = scores.mean()\n",
    "print(\"Mean Accuracy: {:.2f}%\".format(mean_accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['decision_tree_model.pkl']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(c_DT1, 'decision_tree_model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
